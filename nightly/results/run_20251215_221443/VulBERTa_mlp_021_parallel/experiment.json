{
  "experiment_id": "VulBERTa_mlp_021_parallel",
  "timestamp": "2025-12-16T20:06:58.877972",
  "mode": "parallel",
  "foreground": {
    "repository": "VulBERTa",
    "model": "mlp",
    "hyperparameters": {
      "epochs": 18
    },
    "duration_seconds": 6059.904315710068,
    "energy_metrics": {
      "cpu_energy_pkg_joules": 258787.49,
      "cpu_energy_ram_joules": 14973.54,
      "cpu_energy_total_joules": 273761.03,
      "gpu_power_avg_watts": 225.29712247324483,
      "gpu_power_max_watts": 319.36,
      "gpu_power_min_watts": 4.94,
      "gpu_energy_total_joules": 1326324.1599999922,
      "gpu_temp_avg_celsius": 79.3640224222864,
      "gpu_temp_max_celsius": 84.0,
      "gpu_util_avg_percent": 83.5294717173433,
      "gpu_util_max_percent": 100.0
    },
    "performance_metrics": {
      "eval_loss": 0.691966712474823,
      "final_training_loss": 0.708,
      "eval_samples_per_second": 58.922
    },
    "training_success": true,
    "retries": 0,
    "error_message": "Training completed successfully"
  },
  "background": {
    "repository": "examples",
    "model": "mnist_rnn",
    "hyperparameters": {},
    "log_directory": "/home/green/energy_dl/nightly/results/run_20251215_221443/VulBERTa_mlp_021_parallel/background_logs",
    "note": "Background training served as GPU load only (not monitored)"
  }
}
"""
èƒ½è€—å› æœåˆ†æè„šæœ¬æµ‹è¯• - éªŒè¯ä¿®æ”¹æ­£ç¡®æ€§
æµ‹è¯•èŒƒå›´:
1. æ•°æ®æ–‡ä»¶å®Œæ•´æ€§
2. æ¨¡å—å¯¼å…¥
3. DiBSé…ç½®ä¸€è‡´æ€§
4. æ•°æ®æ ¼å¼éªŒè¯
5. å°è§„æ¨¡å¿«é€Ÿè¿è¡Œæµ‹è¯•
"""
import sys
import os
import numpy as np
import pandas as pd
import pickle
from datetime import datetime

# æ·»åŠ è·¯å¾„
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

def print_test_header(test_name):
    """æ‰“å°æµ‹è¯•æ ‡é¢˜"""
    print(f"\n{'='*70}")
    print(f"  æµ‹è¯•: {test_name}")
    print(f"{'='*70}")

def print_result(passed, message):
    """æ‰“å°æµ‹è¯•ç»“æœ"""
    status = "âœ… PASS" if passed else "âŒ FAIL"
    print(f"{status}: {message}")
    return passed

# ============================================================================
# æµ‹è¯•1: æ•°æ®æ–‡ä»¶å®Œæ•´æ€§
# ============================================================================
print_test_header("æ•°æ®æ–‡ä»¶å®Œæ•´æ€§æ£€æŸ¥")

TASK_GROUPS = [
    {
        'name': 'image_classification',
        'display_name': 'å›¾åƒåˆ†ç±»',
        'data_file': 'data/energy_research/training/training_data_image_classification.csv',
        'expected_samples': 258,
        'expected_features': 13
    },
    {
        'name': 'person_reid',
        'display_name': 'Person_reID',
        'data_file': 'data/energy_research/training/training_data_person_reid.csv',
        'expected_samples': 116,
        'expected_features': 16
    },
    {
        'name': 'vulberta',
        'display_name': 'VulBERTa',
        'data_file': 'data/energy_research/training/training_data_vulberta.csv',
        'expected_samples': 142,
        'expected_features': 10
    },
    {
        'name': 'bug_localization',
        'display_name': 'Bugå®šä½',
        'data_file': 'data/energy_research/training/training_data_bug_localization.csv',
        'expected_samples': 132,
        'expected_features': 11
    }
]

all_files_valid = True
for task in TASK_GROUPS:
    file_path = task['data_file']

    # æ£€æŸ¥æ–‡ä»¶å­˜åœ¨
    if not os.path.exists(file_path):
        all_files_valid = print_result(False, f"{task['display_name']}: æ–‡ä»¶ä¸å­˜åœ¨ - {file_path}") and all_files_valid
        continue

    try:
        # åŠ è½½æ•°æ®
        df = pd.read_csv(file_path)

        # æ£€æŸ¥æ ·æœ¬æ•°
        if len(df) != task['expected_samples']:
            all_files_valid = print_result(False,
                f"{task['display_name']}: æ ·æœ¬æ•°ä¸åŒ¹é… (æœŸæœ›{task['expected_samples']}, å®é™…{len(df)})") and all_files_valid
            continue

        # æ£€æŸ¥ç‰¹å¾æ•°
        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
        if len(numeric_cols) != task['expected_features']:
            all_files_valid = print_result(False,
                f"{task['display_name']}: ç‰¹å¾æ•°ä¸åŒ¹é… (æœŸæœ›{task['expected_features']}, å®é™…{len(numeric_cols)})") and all_files_valid
            continue

        # æ£€æŸ¥æ•°æ®ç±»å‹
        if df[numeric_cols].select_dtypes(include=[np.number]).shape[1] != len(numeric_cols):
            all_files_valid = print_result(False,
                f"{task['display_name']}: å­˜åœ¨éæ•°å€¼åˆ—") and all_files_valid
            continue

        print_result(True, f"{task['display_name']}: {len(df)}æ ·æœ¬ Ã— {len(numeric_cols)}ç‰¹å¾")

    except Exception as e:
        all_files_valid = print_result(False, f"{task['display_name']}: åŠ è½½å¤±è´¥ - {e}") and all_files_valid

# ============================================================================
# æµ‹è¯•2: æ¨¡å—å¯¼å…¥
# ============================================================================
print_test_header("å¿…è¦æ¨¡å—å¯¼å…¥æ£€æŸ¥")

import_success = True

try:
    from utils.causal_discovery import CausalGraphLearner
    print_result(True, "CausalGraphLearnerå¯¼å…¥æˆåŠŸ")
except Exception as e:
    import_success = print_result(False, f"CausalGraphLearnerå¯¼å…¥å¤±è´¥: {e}") and import_success

try:
    from utils.causal_inference import CausalInferenceEngine
    print_result(True, "CausalInferenceEngineå¯¼å…¥æˆåŠŸ")
except Exception as e:
    import_success = print_result(False, f"CausalInferenceEngineå¯¼å…¥å¤±è´¥: {e}") and import_success

# ============================================================================
# æµ‹è¯•3: DiBSé…ç½®ä¸€è‡´æ€§ï¼ˆä¸Adultåˆ†æå¯¹æ¯”ï¼‰
# ============================================================================
print_test_header("DiBSé…ç½®ä¸€è‡´æ€§æ£€æŸ¥")

# Adultåˆ†æçš„é…ç½®
ADULT_CONFIG = {
    'n_steps': 3000,
    'alpha': 0.1,
    'threshold': 0.3,
    'random_seed': 42
}

# ä»èƒ½è€—åˆ†æè„šæœ¬è¯»å–é…ç½®
config_file = 'scripts/demos/demo_energy_task_specific.py'
config_match = True

if os.path.exists(config_file):
    with open(config_file, 'r') as f:
        content = f.read()

        # æ£€æŸ¥n_steps
        if 'DIBS_N_STEPS = 3000' in content:
            print_result(True, "n_steps = 3000 (ä¸Adultåˆ†æä¸€è‡´)")
        else:
            config_match = print_result(False, "n_stepsä¸åŒ¹é…") and config_match

        # æ£€æŸ¥alpha
        if 'DIBS_ALPHA = 0.1' in content:
            print_result(True, "alpha = 0.1 (ä¸Adultåˆ†æä¸€è‡´)")
        else:
            config_match = print_result(False, "alphaä¸åŒ¹é…") and config_match

        # æ£€æŸ¥threshold
        if 'DIBS_THRESHOLD = 0.3' in content:
            print_result(True, "threshold = 0.3 (ä¸Adultåˆ†æä¸€è‡´)")
        else:
            config_match = print_result(False, "thresholdä¸åŒ¹é…") and config_match

        # æ£€æŸ¥random_seed
        if 'DIBS_RANDOM_SEED = 42' in content:
            print_result(True, "random_seed = 42 (ä¸Adultåˆ†æä¸€è‡´)")
        else:
            config_match = print_result(False, "random_seedä¸åŒ¹é…") and config_match
else:
    config_match = print_result(False, f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_file}") and config_match

# ============================================================================
# æµ‹è¯•4: æ•°æ®æ ¼å¼éªŒè¯
# ============================================================================
print_test_header("æ•°æ®æ ¼å¼éªŒè¯")

format_valid = True

for task in TASK_GROUPS:
    file_path = task['data_file']

    if not os.path.exists(file_path):
        continue

    try:
        df = pd.read_csv(file_path)
        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
        causal_data = df[numeric_cols].copy()

        # æ£€æŸ¥æ ·æœ¬é‡æ˜¯å¦å……è¶³ï¼ˆDiBSæ¨èè‡³å°‘10ä¸ªï¼‰
        if len(causal_data) < 10:
            format_valid = print_result(False,
                f"{task['display_name']}: æ ·æœ¬é‡ä¸è¶³ ({len(causal_data)} < 10)") and format_valid
            continue

        # æ£€æŸ¥æ˜¯å¦æœ‰å…¨ä¸ºNaNçš„åˆ—
        all_nan_cols = causal_data.columns[causal_data.isna().all()].tolist()
        if all_nan_cols:
            print(f"  âš ï¸  {task['display_name']}: å‘ç°å…¨NaNåˆ— - {all_nan_cols} (å°†è¢«è‡ªåŠ¨ç§»é™¤)")

        # æ£€æŸ¥ç¼ºå¤±ç‡
        missing_rate = causal_data.isna().sum().sum() / (len(causal_data) * len(numeric_cols))
        if missing_rate > 0.5:
            format_valid = print_result(False,
                f"{task['display_name']}: ç¼ºå¤±ç‡è¿‡é«˜ ({missing_rate*100:.1f}% > 50%)") and format_valid
            continue

        # æ£€æŸ¥æ–¹å·®ï¼ˆDiBSéœ€è¦æœ‰å˜åŒ–çš„å˜é‡ï¼‰
        zero_var_cols = causal_data.columns[causal_data.var() == 0].tolist()
        if zero_var_cols:
            print(f"  âš ï¸  {task['display_name']}: é›¶æ–¹å·®åˆ— - {zero_var_cols} (å¯èƒ½å½±å“DiBS)")

        print_result(True,
            f"{task['display_name']}: æ ¼å¼æœ‰æ•ˆ (æ ·æœ¬={len(causal_data)}, ç¼ºå¤±ç‡={missing_rate*100:.1f}%)")

    except Exception as e:
        format_valid = print_result(False, f"{task['display_name']}: éªŒè¯å¤±è´¥ - {e}") and format_valid

# ============================================================================
# æµ‹è¯•5: è¾“å‡ºç›®å½•åˆ›å»º
# ============================================================================
print_test_header("è¾“å‡ºç›®å½•æ£€æŸ¥")

dirs_valid = True

required_dirs = [
    'results/energy_research/task_specific',
    'logs/energy_research/experiments'
]

for dir_path in required_dirs:
    try:
        os.makedirs(dir_path, exist_ok=True)
        print_result(True, f"ç›®å½•å¯åˆ›å»º: {dir_path}")
    except Exception as e:
        dirs_valid = print_result(False, f"ç›®å½•åˆ›å»ºå¤±è´¥: {dir_path} - {e}") and dirs_valid

# ============================================================================
# æµ‹è¯•6: å°è§„æ¨¡å¿«é€Ÿè¿è¡Œæµ‹è¯•ï¼ˆä½¿ç”¨æœ€å°ä»»åŠ¡ç»„ï¼‰
# ============================================================================
print_test_header("å°è§„æ¨¡å¿«é€Ÿè¿è¡Œæµ‹è¯•")

# é€‰æ‹©æ ·æœ¬é‡æœ€å°çš„ä»»åŠ¡ç»„è¿›è¡Œå¿«é€Ÿæµ‹è¯•
test_task = TASK_GROUPS[1]  # Person_reID (116æ ·æœ¬)
print(f"ä½¿ç”¨ {test_task['display_name']} è¿›è¡Œå¿«é€Ÿæµ‹è¯•...")
print(f"é…ç½®: 10æ ·æœ¬, 3ç‰¹å¾, 100æ­¥DiBS (æé€Ÿæ¨¡å¼)")

quick_test_success = True

try:
    # åŠ è½½æ•°æ®
    df = pd.read_csv(test_task['data_file'])
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    causal_data = df[numeric_cols].copy()

    # ç§»é™¤å…¨NaNåˆ—
    causal_data = causal_data.dropna(axis=1, how='all')
    numeric_cols = causal_data.columns.tolist()

    # ä½¿ç”¨æå°å­é›†ï¼ˆ10æ ·æœ¬ï¼Œå‰3ä¸ªç‰¹å¾ï¼‰
    test_data = causal_data.iloc[:10, :3].copy()
    test_cols = test_data.columns.tolist()

    print(f"  æµ‹è¯•æ•°æ®: {len(test_data)}æ ·æœ¬ Ã— {len(test_cols)}ç‰¹å¾")

    # æµ‹è¯•DiBS
    print(f"  å¼€å§‹DiBSæµ‹è¯•ï¼ˆ100æ­¥ï¼Œé¢„è®¡<30ç§’ï¼‰...")
    from utils.causal_discovery import CausalGraphLearner

    learner = CausalGraphLearner(
        n_vars=len(test_cols),
        n_steps=100,  # æå°æ­¥æ•°ç”¨äºå¿«é€Ÿæµ‹è¯•
        alpha=0.1,
        random_seed=42
    )

    import time
    start = time.time()
    causal_graph = learner.fit(test_data, verbose=False)
    dibs_time = time.time() - start

    print_result(True, f"DiBSå®Œæˆ (è€—æ—¶: {dibs_time:.1f}ç§’, å›¾å½¢çŠ¶: {causal_graph.shape})")

    # æµ‹è¯•è¾¹æå–
    edges = learner.get_edges(threshold=0.3)
    print_result(True, f"è¾¹æå–æˆåŠŸ (æ£€æµ‹åˆ° {len(edges)} æ¡å› æœè¾¹)")

    # å¦‚æœæœ‰è¾¹ï¼Œæµ‹è¯•DML
    if len(edges) > 0:
        print(f"  å¼€å§‹DMLæµ‹è¯•ï¼ˆåˆ†æ {len(edges)} æ¡è¾¹ï¼‰...")
        from utils.causal_inference import CausalInferenceEngine

        engine = CausalInferenceEngine(verbose=False)

        start = time.time()
        causal_effects = engine.analyze_all_edges(
            data=test_data,
            causal_graph=causal_graph,
            var_names=test_cols,
            threshold=0.3
        )
        dml_time = time.time() - start

        print_result(True, f"DMLå®Œæˆ (è€—æ—¶: {dml_time:.1f}ç§’, åˆ†æäº† {len(causal_effects)} æ¡è¾¹)")

        # æ£€æŸ¥æ˜¾è‘—æ•ˆåº”
        significant = engine.get_significant_effects()
        print(f"  ç»Ÿè®¡æ˜¾è‘—çš„å› æœæ•ˆåº”: {len(significant)}/{len(causal_effects)}")
    else:
        print(f"  âš ï¸  æœªæ£€æµ‹åˆ°å› æœè¾¹ï¼ˆé˜ˆå€¼0.3ï¼‰ï¼Œè·³è¿‡DMLæµ‹è¯•")
        print(f"     è¿™æ˜¯æ­£å¸¸çš„ï¼ˆ10æ ·æœ¬çš„æå°æ•°æ®é›†ï¼‰")

    print_result(True, "å°è§„æ¨¡è¿è¡Œæµ‹è¯•å®Œæˆ - æ ¸å¿ƒæµç¨‹éªŒè¯æˆåŠŸ")

except Exception as e:
    quick_test_success = print_result(False, f"å¿«é€Ÿè¿è¡Œæµ‹è¯•å¤±è´¥: {e}") and quick_test_success
    import traceback
    traceback.print_exc()

# ============================================================================
# æµ‹è¯•7: è„šæœ¬è¯­æ³•æ£€æŸ¥
# ============================================================================
print_test_header("è„šæœ¬è¯­æ³•æ£€æŸ¥")

syntax_valid = True

script_file = 'scripts/demos/demo_energy_task_specific.py'
if os.path.exists(script_file):
    try:
        with open(script_file, 'r') as f:
            code = f.read()
        compile(code, script_file, 'exec')
        print_result(True, f"è„šæœ¬è¯­æ³•æ­£ç¡®: {script_file}")
    except SyntaxError as e:
        syntax_valid = print_result(False, f"è„šæœ¬è¯­æ³•é”™è¯¯: {e}") and syntax_valid
else:
    syntax_valid = print_result(False, f"è„šæœ¬æ–‡ä»¶ä¸å­˜åœ¨: {script_file}") and syntax_valid

bash_script = 'scripts/experiments/run_energy_causal_analysis.sh'
if os.path.exists(bash_script):
    print_result(True, f"Bashè„šæœ¬å­˜åœ¨: {bash_script}")
    # æ£€æŸ¥æ‰§è¡Œæƒé™
    if os.access(bash_script, os.X_OK):
        print_result(True, f"Bashè„šæœ¬æœ‰æ‰§è¡Œæƒé™")
    else:
        print_result(False, f"Bashè„šæœ¬ç¼ºå°‘æ‰§è¡Œæƒé™ - è¿è¡Œ: chmod +x {bash_script}")
else:
    syntax_valid = print_result(False, f"Bashè„šæœ¬ä¸å­˜åœ¨: {bash_script}") and syntax_valid

# ============================================================================
# æ€»ç»“
# ============================================================================
print(f"\n{'='*70}")
print("  æµ‹è¯•æ€»ç»“")
print(f"{'='*70}")

all_tests = [
    ("æ•°æ®æ–‡ä»¶å®Œæ•´æ€§", all_files_valid),
    ("æ¨¡å—å¯¼å…¥", import_success),
    ("DiBSé…ç½®ä¸€è‡´æ€§", config_match),
    ("æ•°æ®æ ¼å¼éªŒè¯", format_valid),
    ("è¾“å‡ºç›®å½•åˆ›å»º", dirs_valid),
    ("å°è§„æ¨¡å¿«é€Ÿè¿è¡Œ", quick_test_success),
    ("è„šæœ¬è¯­æ³•æ£€æŸ¥", syntax_valid)
]

passed = sum(1 for _, result in all_tests if result)
total = len(all_tests)

for test_name, result in all_tests:
    status = "âœ…" if result else "âŒ"
    print(f"{status} {test_name}")

print(f"\né€šè¿‡ç‡: {passed}/{total} ({passed/total*100:.0f}%)")

if passed == total:
    print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼å¯ä»¥å®‰å…¨è¿è¡ŒStage 8åˆ†æã€‚")
    print("\nè¿è¡Œå‘½ä»¤:")
    print("  cd /home/green/energy_dl/nightly/analysis")
    print("  screen -S energy_dibs bash scripts/experiments/run_energy_causal_analysis.sh")
    sys.exit(0)
else:
    print(f"\nâš ï¸  {total - passed} ä¸ªæµ‹è¯•å¤±è´¥ï¼Œè¯·ä¿®å¤åå†è¿è¡Œã€‚")
    sys.exit(1)

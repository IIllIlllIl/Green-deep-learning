# å­¦æœ¯ç ”ç©¶çº§å®Œæ•´å¤ç°å®æ–½è®¡åˆ’

**ç›®æ ‡**: ä»45%å¤ç°åº¦æå‡åˆ°90%+ï¼Œè¾¾åˆ°å¯å‘è¡¨çš„å­¦æœ¯ç ”ç©¶æ ‡å‡†
**æ—¶é—´ä¼°è®¡**: 6-8å‘¨å…¨èŒå·¥ä½œ
**æœ€ç»ˆç›®æ ‡**: å¯é‡ç°è®ºæ–‡çš„ä¸»è¦å®éªŒç»“æœå’Œç»“è®º

---

## ğŸ“‹ ç›®å½•

1. [å…³é”®å·®è·åˆ†æ](#å…³é”®å·®è·åˆ†æ)
2. [å®æ–½è·¯çº¿å›¾](#å®æ–½è·¯çº¿å›¾)
3. [é˜¶æ®µ1: DiBSå› æœå›¾å­¦ä¹ ](#é˜¶æ®µ1-dibså› æœå›¾å­¦ä¹ )
4. [é˜¶æ®µ2: DMLå› æœæ¨æ–­](#é˜¶æ®µ2-dmlå› æœæ¨æ–­)
5. [é˜¶æ®µ3: å®Œæ•´å…¬å¹³æ€§æ–¹æ³•](#é˜¶æ®µ3-å®Œæ•´å…¬å¹³æ€§æ–¹æ³•)
6. [é˜¶æ®µ4: çœŸå®æ•°æ®é›†é›†æˆ](#é˜¶æ®µ4-çœŸå®æ•°æ®é›†é›†æˆ)
7. [é˜¶æ®µ5: å¤§è§„æ¨¡å®éªŒ](#é˜¶æ®µ5-å¤§è§„æ¨¡å®éªŒ)
8. [é˜¶æ®µ6: ç»“æœéªŒè¯](#é˜¶æ®µ6-ç»“æœéªŒè¯)
9. [æŠ€æœ¯éš¾ç‚¹ä¸è§£å†³æ–¹æ¡ˆ](#æŠ€æœ¯éš¾ç‚¹ä¸è§£å†³æ–¹æ¡ˆ)
10. [èµ„æºéœ€æ±‚](#èµ„æºéœ€æ±‚)

---

## ğŸ¯ å…³é”®å·®è·åˆ†æ

### å½“å‰çŠ¶æ€ vs è®ºæ–‡è¦æ±‚

| ç»„ä»¶ | å½“å‰ | è®ºæ–‡è¦æ±‚ | ä¼˜å…ˆçº§ | éš¾åº¦ | æ—¶é—´ |
|------|------|----------|--------|------|------|
| **å› æœå›¾å­¦ä¹ ** | ç›¸å…³æ€§ | DiBS(10kè¿­ä»£) | ğŸ”´ æœ€é«˜ | â­â­â­â­â­ | 2å‘¨ |
| **å› æœæ¨æ–­** | ç®€å•å·®å€¼ | DML(EconML) | ğŸ”´ æœ€é«˜ | â­â­â­â­ | 1å‘¨ |
| **å…¬å¹³æ€§æ–¹æ³•** | 2/12 | 12ä¸ªå®Œæ•´ | ğŸŸ¡ é«˜ | â­â­â­ | 1å‘¨ |
| **æ•°æ®é›†** | æ¨¡æ‹Ÿ | Adult/COMPAS/German | ğŸŸ¡ é«˜ | â­â­ | 3å¤© |
| **Alphaé‡‡æ ·** | 3ç‚¹ | 10ç‚¹ | ğŸŸ¢ ä¸­ | â­ | 1å¤© |
| **é²æ£’æ€§æµ‹è¯•** | éšæœºå™ªå£° | çœŸå®å¯¹æŠ—æ”»å‡» | ğŸŸ¢ ä¸­ | â­â­â­ | 3å¤© |
| **ç»Ÿè®¡æ£€éªŒ** | æ—  | ç½®ä¿¡åŒºé—´ | ğŸŸ¢ ä¸­ | â­â­ | 2å¤© |
| **å®éªŒè§„æ¨¡** | 6ç‚¹ | 726ç‚¹ | ğŸŸ¡ é«˜ | â­ | æŒç»­ |

**å…³é”®ç“¶é¢ˆ**:
1. ğŸ”´ DiBSå› æœå›¾å­¦ä¹ ï¼ˆæœ€éš¾ï¼Œæœ€å…³é”®ï¼‰
2. ğŸ”´ DMLå› æœæ¨æ–­ï¼ˆæ¬¡éš¾ï¼Œæ ¸å¿ƒç®—æ³•ï¼‰
3. ğŸŸ¡ 12ä¸ªå…¬å¹³æ€§æ–¹æ³•ï¼ˆå·¥ç¨‹é‡å¤§ï¼‰

---

## ğŸ—ºï¸ å®æ–½è·¯çº¿å›¾

```
æ€»æ—¶é—´: 6-8å‘¨
å¤ç°åº¦: 45% â†’ 90%+

Week 1-2: DiBSå› æœå›¾å­¦ä¹            [45% â†’ 60%]  ğŸ”´ Critical
Week 3:   DMLå› æœæ¨æ–­              [60% â†’ 75%]  ğŸ”´ Critical
Week 4:   å®Œæ•´å…¬å¹³æ€§æ–¹æ³•            [75% â†’ 82%]  ğŸŸ¡ Important
Week 5:   çœŸå®æ•°æ®é›† + å¯¹æŠ—æ”»å‡»     [82% â†’ 87%]  ğŸŸ¡ Important
Week 6-7: å¤§è§„æ¨¡å®éªŒè¿è¡Œ            [87% â†’ 92%]  ğŸŸ¢ Scale-up
Week 8:   ç»“æœéªŒè¯ + è®ºæ–‡å¯¹æ¯”       [92% â†’ 95%]  âœ… Validation
```

### é‡Œç¨‹ç¢‘

| å‘¨æ•° | é‡Œç¨‹ç¢‘ | å¯éªŒè¯æŒ‡æ ‡ |
|------|--------|-----------|
| Week 2 | DiBSè¿è¡ŒæˆåŠŸ | ç”Ÿæˆ46å˜é‡çš„DAG |
| Week 3 | DMLé›†æˆå®Œæˆ | è¾“å‡ºATE+ç½®ä¿¡åŒºé—´ |
| Week 4 | 12ä¸ªæ–¹æ³•å¯ç”¨ | é€šè¿‡æ–¹æ³•æµ‹è¯• |
| Week 5 | 3æ•°æ®é›†è¿è¡Œ | ç”Ÿæˆ240+æ•°æ®ç‚¹ |
| Week 7 | å®Œæ•´å®éªŒ | ç”Ÿæˆ726æ•°æ®ç‚¹ |
| Week 8 | ç»“æœåŒ¹é… | ä¸è®ºæ–‡å›¾è¡¨å¯¹æ¯” |

---

## ğŸ”¬ é˜¶æ®µ1: DiBSå› æœå›¾å­¦ä¹ 

**ç›®æ ‡**: å®ç°è®ºæ–‡çš„æ ¸å¿ƒç®—æ³• - ä½¿ç”¨DiBSå­¦ä¹ å› æœå›¾
**æ—¶é—´**: 2å‘¨
**ä¼˜å…ˆçº§**: ğŸ”´ æœ€é«˜ï¼ˆè¿™æ˜¯è®ºæ–‡çš„æ ¸å¿ƒåˆ›æ–°ï¼‰

### 1.1 ç†è®ºå‡†å¤‡ (2å¤©)

#### éœ€è¦ç†è§£çš„æ¦‚å¿µ
- [ ] Directed Acyclic Graph (DAG)
- [ ] Structural Equation Model (SEM)
- [ ] Variational Inference
- [ ] DiBSç®—æ³•åŸç†

#### å¿…è¯»æ–‡çŒ®
1. **DiBSåŸè®ºæ–‡** (NeurIPS 2021)
   - æ ‡é¢˜: "DiBS: Differentiable Bayesian Structure Learning"
   - é“¾æ¥: https://arxiv.org/abs/2105.11839

2. **å› æœå‘ç°ç»¼è¿°**
   - "Causality: Models, Reasoning and Inference" (Pearl, 2009)

#### å­¦ä¹ èµ„æº
```bash
# æ¨èæ•™ç¨‹
https://github.com/larslorch/dibs  # å®˜æ–¹repo
https://dibs-project.github.io/     # æ–‡æ¡£
```

### 1.2 ç¯å¢ƒé…ç½® (1å¤©)

#### å®‰è£…DiBSåº“
```bash
# æ–¹æ³•1: ä»GitHubå®‰è£…ï¼ˆæ¨èï¼‰
conda activate fairness
git clone https://github.com/larslorch/dibs.git
cd dibs
pip install -e .

# æ–¹æ³•2: é€šè¿‡pipï¼ˆå¦‚æœå¯ç”¨ï¼‰
pip install dibs-causal

# ä¾èµ–æ£€æŸ¥
python -c "import dibs; print('DiBSç‰ˆæœ¬:', dibs.__version__)"
```

#### å¯èƒ½çš„é—®é¢˜
- **JAXä¾èµ–**: DiBSåŸºäºJAXï¼Œéœ€è¦æ­£ç¡®é…ç½®
- **GPUæ”¯æŒ**: JAXéœ€è¦ç‰¹å®šçš„CUDAç‰ˆæœ¬
- **å†…å­˜éœ€æ±‚**: DiBSéœ€è¦å¤§é‡å†…å­˜ï¼ˆå»ºè®®16GB+ï¼‰

#### è§£å†³æ–¹æ¡ˆ
```bash
# å®‰è£…JAX (GPUç‰ˆæœ¬)
pip install --upgrade "jax[cuda11_pip]" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html

# å¦‚æœå†…å­˜ä¸è¶³ï¼Œè€ƒè™‘ä½¿ç”¨CPUç‰ˆæœ¬
pip install --upgrade jax jaxlib
```

### 1.3 DiBSé€‚é…å±‚å¼€å‘ (4å¤©)

#### åˆ›å»ºæ–°æ¨¡å—: `utils/causal_discovery.py`

```python
"""
DiBSå› æœå›¾å­¦ä¹ æ¨¡å—
å®ç°è®ºæ–‡ä¸­çš„å› æœå›¾å‘ç°ç®—æ³•
"""

import numpy as np
import pandas as pd
from dibs import JointDiBS
from typing import Dict, Tuple
import warnings

class CausalGraphLearner:
    """
    ä½¿ç”¨DiBSå­¦ä¹ å› æœå›¾

    å‚æ•°:
        n_vars: å˜é‡æ•°é‡ï¼ˆè®ºæ–‡ä¸­ä¸º46ä¸ªï¼‰
        alpha: DAGæƒ©ç½šå‚æ•°ï¼ˆè®ºæ–‡ä¸­ä¸º0.9ï¼‰
        n_steps: è¿­ä»£æ¬¡æ•°ï¼ˆè®ºæ–‡ä¸­ä¸º10000ï¼‰
        random_seed: éšæœºç§å­
    """

    def __init__(self,
                 n_vars: int = 46,
                 alpha: float = 0.9,
                 n_steps: int = 10000,
                 random_seed: int = 42):

        # è¾“å…¥éªŒè¯
        if n_vars <= 0:
            raise ValueError(f"n_vars must be positive, got {n_vars}")
        if not 0 <= alpha <= 1:
            raise ValueError(f"alpha must be in [0,1], got {alpha}")
        if n_steps <= 0:
            raise ValueError(f"n_steps must be positive, got {n_steps}")

        self.n_vars = n_vars
        self.alpha = alpha
        self.n_steps = n_steps
        self.random_seed = random_seed

        # åˆå§‹åŒ–DiBSæ¨¡å‹
        self.model = None
        self.learned_graph = None

    def fit(self, data: pd.DataFrame, verbose: bool = True) -> np.ndarray:
        """
        å­¦ä¹ å› æœå›¾

        å‚æ•°:
            data: è®­ç»ƒæ•°æ®ï¼Œshape (n_samples, n_vars)
            verbose: æ˜¯å¦è¾“å‡ºè¿›åº¦

        è¿”å›:
            learned_graph: é‚»æ¥çŸ©é˜µï¼Œshape (n_vars, n_vars)
                          learned_graph[i,j] = 1 è¡¨ç¤º i â†’ j
        """
        # è¾“å…¥éªŒè¯
        if data is None or len(data) == 0:
            raise ValueError("data cannot be None or empty")
        if data.shape[1] != self.n_vars:
            raise ValueError(
                f"Expected {self.n_vars} variables, got {data.shape[1]}"
            )

        # æ•°æ®é¢„å¤„ç†ï¼šç¦»æ•£å˜é‡â†’è¿ç»­å˜é‡
        data_continuous = self._discretize_to_continuous(data)

        if verbose:
            print(f"å¼€å§‹DiBSå­¦ä¹ ...")
            print(f"  å˜é‡æ•°: {self.n_vars}")
            print(f"  æ ·æœ¬æ•°: {len(data)}")
            print(f"  è¿­ä»£æ¬¡æ•°: {self.n_steps}")
            print(f"  Alpha: {self.alpha}")

        # åˆå§‹åŒ–DiBS
        self.model = JointDiBS(
            n_vars=self.n_vars,
            alpha=self.alpha,
            random_state=self.random_seed
        )

        # è¿è¡ŒDiBSï¼ˆè¿™æ˜¯è€—æ—¶æ“ä½œï¼‰
        try:
            self.model.fit(
                data_continuous,
                n_steps=self.n_steps,
                verbose=verbose
            )
        except Exception as e:
            raise RuntimeError(f"DiBS fitting failed: {e}")

        # è·å–å­¦ä¹ åˆ°çš„å›¾
        self.learned_graph = self.model.get_graph(threshold=0.5)

        if verbose:
            n_edges = np.sum(self.learned_graph > 0)
            print(f"âœ“ DiBSå®Œæˆ")
            print(f"  å­¦åˆ°çš„è¾¹æ•°: {n_edges}")
            print(f"  å›¾å¯†åº¦: {n_edges / (self.n_vars * (self.n_vars-1)):.3f}")

        return self.learned_graph

    def _discretize_to_continuous(self, data: pd.DataFrame) -> np.ndarray:
        """
        å°†ç¦»æ•£å˜é‡è½¬æ¢ä¸ºè¿ç»­å˜é‡

        è®ºæ–‡æœªè¯¦ç»†è¯´æ˜æ­¤æ­¥éª¤ï¼Œè¿™é‡Œä½¿ç”¨ä¸¤ç§æ–¹æ³•:
        1. å¯¹äºå·²ç»è¿ç»­çš„å˜é‡ï¼šä¿æŒä¸å˜
        2. å¯¹äºç¦»æ•£å˜é‡ï¼šæ·»åŠ å°éšæœºå™ªå£°

        å‚æ•°:
            data: åŸå§‹æ•°æ®

        è¿”å›:
            data_continuous: è¿ç»­åŒ–åçš„æ•°æ®
        """
        data_continuous = data.values.copy().astype(float)

        # æ£€æµ‹ç¦»æ•£åˆ—ï¼ˆå”¯ä¸€å€¼æ•°é‡ < 10ï¼‰
        for i in range(data.shape[1]):
            n_unique = len(np.unique(data.iloc[:, i]))
            if n_unique < 10:
                # ç¦»æ•£åˆ—ï¼šæ·»åŠ å°å™ªå£°
                noise = np.random.normal(0, 0.01, size=len(data))
                data_continuous[:, i] += noise

        return data_continuous

    def get_edges(self, threshold: float = 0.5) -> list:
        """
        è·å–å› æœè¾¹åˆ—è¡¨

        å‚æ•°:
            threshold: è¾¹æƒé‡é˜ˆå€¼

        è¿”å›:
            edges: [(source, target, weight), ...]
        """
        if self.learned_graph is None:
            raise RuntimeError("Must call fit() first")

        edges = []
        for i in range(self.n_vars):
            for j in range(self.n_vars):
                weight = self.learned_graph[i, j]
                if weight > threshold:
                    edges.append((i, j, weight))

        return edges

    def save_graph(self, filepath: str):
        """ä¿å­˜å­¦ä¹ åˆ°çš„å›¾"""
        if self.learned_graph is None:
            raise RuntimeError("Must call fit() first")
        np.save(filepath, self.learned_graph)
        print(f"âœ“ å›¾å·²ä¿å­˜åˆ°: {filepath}")

    def load_graph(self, filepath: str):
        """åŠ è½½å·²ä¿å­˜çš„å›¾"""
        self.learned_graph = np.load(filepath)
        print(f"âœ“ å›¾å·²ä» {filepath} åŠ è½½")
```

#### å…³é”®å®ç°è¦ç‚¹

1. **ç¦»æ•£å˜é‡å¤„ç†**ï¼ˆè®ºæ–‡æœªè¯¦ç»†è¯´æ˜ï¼‰
   ```python
   # æ–¹æ³•1: æ·»åŠ å°å™ªå£°ï¼ˆç®€å•ï¼‰
   noise = np.random.normal(0, 0.01, size=n_samples)

   # æ–¹æ³•2: æ ¸å¯†åº¦ä¼°è®¡ï¼ˆæ›´å‡†ç¡®ï¼‰
   from sklearn.neighbors import KernelDensity
   kde = KernelDensity(kernel='gaussian', bandwidth=0.1)
   kde.fit(data.reshape(-1, 1))
   samples = kde.sample(n_samples)
   ```

2. **è®¡ç®—ä¼˜åŒ–**
   - ä½¿ç”¨GPUåŠ é€Ÿï¼ˆJAXè‡ªåŠ¨å¤„ç†ï¼‰
   - æ‰¹æ¬¡å¤„ç†å¤§æ•°æ®
   - ç»“æœç¼“å­˜ï¼ˆé¿å…é‡å¤è®¡ç®—ï¼‰

3. **å†…å­˜ä¼˜åŒ–**
   - ä¸ä¿å­˜æ‰€æœ‰ä¸­é—´ç»“æœ
   - å®šæœŸæ¸…ç†å†…å­˜
   - ä½¿ç”¨ä½ç²¾åº¦æµ®ç‚¹æ•°ï¼ˆfloat32ï¼‰

### 1.4 DiBSæµ‹è¯• (2å¤©)

#### å•å…ƒæµ‹è¯•: `tests/test_dibs.py`

```python
import unittest
import numpy as np
import pandas as pd
from utils.causal_discovery import CausalGraphLearner

class TestDiBS(unittest.TestCase):

    def test_initialization(self):
        """æµ‹è¯•DiBSåˆå§‹åŒ–"""
        learner = CausalGraphLearner(n_vars=5, n_steps=100)
        self.assertEqual(learner.n_vars, 5)
        self.assertEqual(learner.n_steps, 100)

    def test_simple_chain(self):
        """æµ‹è¯•ç®€å•é“¾å¼å› æœå…³ç³»: X â†’ Y â†’ Z"""
        # ç”Ÿæˆæ•°æ®
        n_samples = 1000
        X = np.random.randn(n_samples)
        Y = 2*X + np.random.randn(n_samples)*0.1
        Z = 3*Y + np.random.randn(n_samples)*0.1

        data = pd.DataFrame({'X': X, 'Y': Y, 'Z': Z})

        # å­¦ä¹ å›¾
        learner = CausalGraphLearner(n_vars=3, n_steps=1000)
        graph = learner.fit(data, verbose=False)

        # éªŒè¯ï¼šåº”è¯¥æœ‰ Xâ†’Y, Yâ†’Z
        self.assertGreater(graph[0, 1], 0.5)  # X â†’ Y
        self.assertGreater(graph[1, 2], 0.5)  # Y â†’ Z
        self.assertLess(graph[0, 2], 0.5)     # X â†› Zï¼ˆç›´æ¥ï¼‰

    def test_real_data_shape(self):
        """æµ‹è¯•çœŸå®æ•°æ®è§„æ¨¡"""
        # æ¨¡æ‹Ÿ46å˜é‡çš„æ•°æ®
        n_samples = 100
        n_vars = 46
        data = pd.DataFrame(
            np.random.randn(n_samples, n_vars),
            columns=[f'var_{i}' for i in range(n_vars)]
        )

        learner = CausalGraphLearner(n_vars=46, n_steps=500)
        graph = learner.fit(data, verbose=False)

        # éªŒè¯å›¾çš„å½¢çŠ¶
        self.assertEqual(graph.shape, (46, 46))

    def test_save_load(self):
        """æµ‹è¯•ä¿å­˜å’ŒåŠ è½½"""
        # åˆ›å»ºç®€å•å›¾
        data = pd.DataFrame(np.random.randn(100, 3))
        learner = CausalGraphLearner(n_vars=3, n_steps=100)
        graph1 = learner.fit(data, verbose=False)

        # ä¿å­˜
        learner.save_graph('/tmp/test_graph.npy')

        # åŠ è½½
        learner2 = CausalGraphLearner(n_vars=3)
        learner2.load_graph('/tmp/test_graph.npy')

        # éªŒè¯ä¸€è‡´æ€§
        np.testing.assert_array_equal(graph1, learner2.learned_graph)
```

#### æ€§èƒ½æµ‹è¯•

```python
def test_performance():
    """æµ‹è¯•DiBSæ€§èƒ½"""
    import time

    # æµ‹è¯•ä¸åŒè§„æ¨¡
    sizes = [10, 20, 30, 46]
    for n_vars in sizes:
        data = pd.DataFrame(np.random.randn(200, n_vars))
        learner = CausalGraphLearner(n_vars=n_vars, n_steps=1000)

        start = time.time()
        learner.fit(data, verbose=False)
        elapsed = time.time() - start

        print(f"n_vars={n_vars}: {elapsed:.1f}ç§’")
```

### 1.5 é›†æˆåˆ°ä¸»æµç¨‹ (3å¤©)

#### ä¿®æ”¹ `demo_quick_run.py`

```python
# åœ¨æ­¥éª¤3æ›¿æ¢ç›¸å…³æ€§åˆ†æ

print("\n" + "â–¶"*35)
print("æ­¥éª¤3: DiBSå› æœå›¾å­¦ä¹ ")
print("â–¶"*35)

# å‡†å¤‡æ•°æ®ï¼ˆé€‰æ‹©æ•°å€¼åˆ—ï¼‰
numeric_cols = df.select_dtypes(include=[np.number]).columns
data_for_dibs = df[numeric_cols]

print(f"\næ•°æ®å‡†å¤‡:")
print(f"  å˜é‡æ•°: {len(numeric_cols)}")
print(f"  æ ·æœ¬æ•°: {len(data_for_dibs)}")

# é€‰æ‹©è¿­ä»£æ¬¡æ•°ï¼ˆæ ¹æ®æ•°æ®è§„æ¨¡ï¼‰
n_steps = 10000 if len(data_for_dibs) > 50 else 2000
print(f"  è¿­ä»£æ¬¡æ•°: {n_steps}")

# DiBSå­¦ä¹ 
from utils.causal_discovery import CausalGraphLearner

learner = CausalGraphLearner(
    n_vars=len(numeric_cols),
    alpha=config.CAUSAL_DISCOVERY['alpha'] if hasattr(config, 'CAUSAL_DISCOVERY') else 0.9,
    n_steps=n_steps
)

try:
    causal_graph = learner.fit(data_for_dibs, verbose=True)

    # ä¿å­˜å›¾
    learner.save_graph('results/causal_graph.npy')

    # åˆ†æå›¾ç»“æ„
    edges = learner.get_edges(threshold=0.5)
    print(f"\nå­¦åˆ°çš„å› æœå…³ç³» (top 10):")

    # æŒ‰æƒé‡æ’åº
    edges_sorted = sorted(edges, key=lambda x: x[2], reverse=True)
    for i, (source, target, weight) in enumerate(edges_sorted[:10], 1):
        source_name = numeric_cols[source]
        target_name = numeric_cols[target]
        print(f"  {i}. {source_name} â†’ {target_name} (æƒé‡: {weight:.3f})")

    # å¯è§†åŒ–ï¼ˆå¯é€‰ï¼‰
    try:
        import networkx as nx
        import matplotlib.pyplot as plt

        G = nx.DiGraph()
        for source, target, weight in edges_sorted[:20]:  # åªç”»å‰20æ¡è¾¹
            G.add_edge(numeric_cols[source], numeric_cols[target], weight=weight)

        plt.figure(figsize=(15, 10))
        pos = nx.spring_layout(G, k=0.5, iterations=50)
        nx.draw(G, pos, with_labels=True, node_color='lightblue',
                node_size=500, font_size=8, arrows=True)
        plt.savefig('results/causal_graph.png', dpi=300, bbox_inches='tight')
        print("\nâœ“ å› æœå›¾å·²ä¿å­˜åˆ°: results/causal_graph.png")
    except ImportError:
        print("\nâš ï¸  matplotlibæœªå®‰è£…ï¼Œè·³è¿‡å¯è§†åŒ–")

except Exception as e:
    print(f"\nâŒ DiBSå­¦ä¹ å¤±è´¥: {e}")
    print("å›é€€åˆ°ç›¸å…³æ€§åˆ†æ...")

    # é™çº§å¤„ç†
    corr_matrix = data_for_dibs.corr()
    causal_graph = (corr_matrix.abs() > 0.3).values.astype(float)
```

### 1.6 éªŒæ”¶æ ‡å‡†

DiBSå®ç°å®Œæˆéœ€æ»¡è¶³ï¼š

- [ ] å¯è¿è¡Œåœ¨46å˜é‡çš„æ•°æ®ä¸Š
- [ ] 10000æ¬¡è¿­ä»£å¯åœ¨åˆç†æ—¶é—´å†…å®Œæˆï¼ˆ<2å°æ—¶ï¼‰
- [ ] è¾“å‡ºDAGç»“æ„ï¼ˆæ— ç¯ï¼‰
- [ ] é€šè¿‡æ‰€æœ‰å•å…ƒæµ‹è¯•
- [ ] ä¸è®ºæ–‡æ–¹æ³•ä¸€è‡´ï¼ˆè¾“å…¥è¾“å‡ºæ ¼å¼ï¼‰

---

## ğŸ§® é˜¶æ®µ2: DMLå› æœæ¨æ–­

**ç›®æ ‡**: ä½¿ç”¨Double Machine Learningä¼°è®¡å› æœæ•ˆåº”
**æ—¶é—´**: 1å‘¨
**ä¼˜å…ˆçº§**: ğŸ”´ æœ€é«˜

### 2.1 ç†è®ºå‡†å¤‡ (1å¤©)

#### æ ¸å¿ƒæ¦‚å¿µ
- [ ] Average Treatment Effect (ATE)
- [ ] Confoundingå’Œå»æ··æ·†
- [ ] Double Machine LearningåŸç†
- [ ] äº¤å‰æ‹Ÿåˆ(Cross-fitting)

#### å¿…è¯»æ–‡çŒ®
1. **DMLåŸè®ºæ–‡**
   - "Double/Debiased Machine Learning" (Chernozhukov et al., 2018)

2. **EconMLæ–‡æ¡£**
   - https://econml.azurewebsites.net/

### 2.2 ç¯å¢ƒé…ç½® (0.5å¤©)

```bash
conda activate fairness

# EconMLå·²å®‰è£…ï¼ŒéªŒè¯ç‰ˆæœ¬
python -c "import econml; print('EconMLç‰ˆæœ¬:', econml.__version__)"

# å¦‚éœ€å‡çº§
pip install --upgrade econml
```

### 2.3 DMLé€‚é…å±‚å¼€å‘ (2å¤©)

#### åˆ›å»ºæ–°æ¨¡å—: `utils/causal_inference.py`

```python
"""
DMLå› æœæ¨æ–­æ¨¡å—
ä½¿ç”¨Double Machine Learningä¼°è®¡å› æœæ•ˆåº”
"""

import numpy as np
import pandas as pd
from econml.dml import LinearDML, CausalForestDML
from typing import Dict, List, Tuple, Optional
import warnings

class CausalInferenceEngine:
    """
    å› æœæ¨æ–­å¼•æ“

    ä½¿ç”¨DMLä¼°è®¡ä»å› æœå›¾ä¸­è¯†åˆ«çš„æ¯æ¡è¾¹çš„ATE
    """

    def __init__(self,
                 model_type: str = 'linear',
                 n_folds: int = 2,
                 random_state: int = 42):
        """
        å‚æ•°:
            model_type: 'linear' æˆ– 'forest'
            n_folds: äº¤å‰æ‹Ÿåˆçš„æŠ˜æ•°
            random_state: éšæœºç§å­
        """
        self.model_type = model_type
        self.n_folds = n_folds
        self.random_state = random_state
        self.results = {}

    def estimate_ate_for_edge(self,
                               data: pd.DataFrame,
                               treatment_var: str,
                               outcome_var: str,
                               confounders: List[str],
                               controls: Optional[List[str]] = None) -> Dict:
        """
        ä¼°è®¡å•æ¡å› æœè¾¹çš„ATE

        å‚æ•°:
            data: å®Œæ•´æ•°æ®
            treatment_var: å¤„ç†å˜é‡(æºèŠ‚ç‚¹)
            outcome_var: ç»“æœå˜é‡(ç›®æ ‡èŠ‚ç‚¹)
            confounders: æ··æ·†å› ç´ åˆ—è¡¨
            controls: æ§åˆ¶å˜é‡åˆ—è¡¨

        è¿”å›:
            result: {
                'ate': float,
                'ci_lower': float,
                'ci_upper': float,
                'p_value': float
            }
        """
        # å‡†å¤‡æ•°æ®
        T = data[treatment_var].values
        Y = data[outcome_var].values
        X = data[confounders].values if confounders else None
        W = data[controls].values if controls else None

        # åˆå§‹åŒ–DMLæ¨¡å‹
        if self.model_type == 'linear':
            dml = LinearDML(
                model_y='auto',
                model_t='auto',
                cv=self.n_folds,
                random_state=self.random_state
            )
        else:
            dml = CausalForestDML(
                model_y='auto',
                model_t='auto',
                cv=self.n_folds,
                random_state=self.random_state
            )

        # æ‹Ÿåˆ
        dml.fit(Y, T, X=X, W=W)

        # ä¼°è®¡ATE
        ate = dml.ate()
        ate_interval = dml.ate_interval()

        # è®¡ç®—på€¼ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        try:
            ate_inference = dml.ate_inference()
            p_value = ate_inference.pvalue()[0]
        except:
            p_value = None

        result = {
            'ate': float(ate),
            'ci_lower': float(ate_interval[0]),
            'ci_upper': float(ate_interval[1]),
            'p_value': p_value,
            'significant': not (ate_interval[0] <= 0 <= ate_interval[1])
        }

        return result

    def analyze_causal_graph(self,
                            data: pd.DataFrame,
                            causal_graph: np.ndarray,
                            var_names: List[str],
                            min_edge_weight: float = 0.5) -> pd.DataFrame:
        """
        å¯¹å› æœå›¾ä¸­çš„æ‰€æœ‰è¾¹è¿›è¡Œå› æœæ¨æ–­

        å‚æ•°:
            data: å®Œæ•´æ•°æ®
            causal_graph: DiBSå­¦ä¹ çš„å›¾ï¼Œshape (n_vars, n_vars)
            var_names: å˜é‡ååˆ—è¡¨
            min_edge_weight: æœ€å°è¾¹æƒé‡é˜ˆå€¼

        è¿”å›:
            results_df: DataFrameåŒ…å«æ‰€æœ‰è¾¹çš„ATEä¼°è®¡
        """
        results = []
        n_vars = len(var_names)

        # éå†æ‰€æœ‰è¾¹
        edges = []
        for i in range(n_vars):
            for j in range(n_vars):
                if causal_graph[i, j] > min_edge_weight:
                    edges.append((i, j, causal_graph[i, j]))

        print(f"å¼€å§‹åˆ†æ {len(edges)} æ¡å› æœè¾¹...")

        from tqdm import tqdm
        for source_idx, target_idx, weight in tqdm(edges):
            source_var = var_names[source_idx]
            target_var = var_names[target_idx]

            # è¯†åˆ«æ··æ·†å› ç´ 
            confounders = self._identify_confounders(
                causal_graph, source_idx, target_idx, var_names
            )

            try:
                # ä¼°è®¡ATE
                result = self.estimate_ate_for_edge(
                    data, source_var, target_var, confounders
                )

                results.append({
                    'source': source_var,
                    'target': target_var,
                    'edge_weight': weight,
                    'ate': result['ate'],
                    'ci_lower': result['ci_lower'],
                    'ci_upper': result['ci_upper'],
                    'p_value': result['p_value'],
                    'significant': result['significant'],
                    'n_confounders': len(confounders)
                })
            except Exception as e:
                warnings.warn(f"Failed to estimate ATE for {source_var}â†’{target_var}: {e}")

        results_df = pd.DataFrame(results)
        return results_df

    def _identify_confounders(self,
                             graph: np.ndarray,
                             source_idx: int,
                             target_idx: int,
                             var_names: List[str]) -> List[str]:
        """
        æ ¹æ®å› æœå›¾è¯†åˆ«æ··æ·†å› ç´ 

        æ··æ·†å› ç´ å®šä¹‰ï¼šåŒæ—¶æŒ‡å‘sourceå’Œtargetçš„å˜é‡
        """
        confounders = []
        n_vars = len(var_names)

        for k in range(n_vars):
            if k == source_idx or k == target_idx:
                continue

            # æ£€æŸ¥æ˜¯å¦æŒ‡å‘sourceå’Œtarget
            points_to_source = graph[k, source_idx] > 0.5
            points_to_target = graph[k, target_idx] > 0.5

            if points_to_source or points_to_target:
                confounders.append(var_names[k])

        return confounders
```

### 2.4 å®ç°è®ºæ–‡çš„ç®—æ³•1 (2å¤©)

#### åˆ›å»º: `utils/tradeoff_detection.py`

```python
"""
å®ç°è®ºæ–‡ç®—æ³•1: æƒè¡¡æ£€æµ‹
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Tuple
from utils.metrics import define_sign_functions

def detect_tradeoffs_algorithm1(
    causal_inference_results: pd.DataFrame,
    sign_functions: Dict,
    significance_level: float = 0.05
) -> pd.DataFrame:
    """
    è®ºæ–‡ç®—æ³•1: åŸºäºå› æœæ¨æ–­çš„æƒè¡¡æ£€æµ‹

    è¾“å…¥:
        causal_inference_results: DMLåˆ†æç»“æœ
            å¿…é¡»åŒ…å«åˆ—: source, target, ate, ci_lower, ci_upper, significant
        sign_functions: å„æŒ‡æ ‡çš„signå‡½æ•°å­—å…¸
        significance_level: æ˜¾è‘—æ€§æ°´å¹³

    è¾“å‡º:
        tradeoffs_df: æ£€æµ‹åˆ°çš„æƒè¡¡å…³ç³»
    """
    tradeoffs = []

    # æŒ‰sourceåˆ†ç»„
    grouped = causal_inference_results.groupby('source')

    for source, group in grouped:
        edges = group.to_dict('records')

        # åªè€ƒè™‘æ˜¾è‘—çš„è¾¹
        significant_edges = [e for e in edges if e['significant']]

        # æ£€æŸ¥æ‰€æœ‰è¾¹å¯¹
        for i, edge1 in enumerate(significant_edges):
            for edge2 in significant_edges[i+1:]:
                target1 = edge1['target']
                target2 = edge2['target']

                # è·å–ATE
                ate1 = edge1['ate']
                ate2 = edge2['ate']

                # è®¡ç®—signï¼ˆç®€åŒ–ï¼šå‡è®¾å½“å‰å€¼ä¸º0ï¼‰
                try:
                    sign1 = sign_functions[target1](0, ate1)
                    sign2 = sign_functions[target2](0, ate2)
                except KeyError:
                    continue  # è·³è¿‡æ²¡æœ‰signå‡½æ•°çš„æŒ‡æ ‡

                # æ£€æŸ¥æƒè¡¡ï¼šsignç›¸å
                if sign1 != sign2:
                    tradeoffs.append({
                        'intervention': source,
                        'metric1': target1,
                        'metric2': target2,
                        'ate1': ate1,
                        'ate2': ate2,
                        'ci1_lower': edge1['ci_lower'],
                        'ci1_upper': edge1['ci_upper'],
                        'ci2_lower': edge2['ci_lower'],
                        'ci2_upper': edge2['ci_upper'],
                        'sign1': sign1,
                        'sign2': sign2,
                        'tradeoff_type': f"{target1}â†‘ vs {target2}â†“" if sign1 == '+' else f"{target1}â†“ vs {target2}â†‘"
                    })

    tradeoffs_df = pd.DataFrame(tradeoffs)
    return tradeoffs_df
```

### 2.5 é›†æˆæµ‹è¯• (1å¤©)

```python
# tests/test_causal_inference.py

class TestCausalInference(unittest.TestCase):

    def test_dml_simple_case(self):
        """æµ‹è¯•ç®€å•æƒ…å†µä¸‹çš„DML"""
        # ç”Ÿæˆæ•°æ®: T â†’ Y, with confounder C
        n = 1000
        C = np.random.randn(n)
        T = 2*C + np.random.randn(n)
        Y = 3*T + 4*C + np.random.randn(n)

        data = pd.DataFrame({'C': C, 'T': T, 'Y': Y})

        engine = CausalInferenceEngine()
        result = engine.estimate_ate_for_edge(
            data, 'T', 'Y', confounders=['C']
        )

        # çœŸå®ATE = 3
        self.assertAlmostEqual(result['ate'], 3, delta=0.5)
        self.assertTrue(result['significant'])

    def test_algorithm1(self):
        """æµ‹è¯•ç®—æ³•1æƒè¡¡æ£€æµ‹"""
        # æ¨¡æ‹ŸDMLç»“æœ
        results = pd.DataFrame({
            'source': ['alpha', 'alpha'],
            'target': ['Acc', 'SPD'],
            'ate': [0.1, -0.05],
            'ci_lower': [0.05, -0.08],
            'ci_upper': [0.15, -0.02],
            'significant': [True, True]
        })

        sign_funcs = define_sign_functions()
        tradeoffs = detect_tradeoffs_algorithm1(results, sign_funcs)

        # åº”è¯¥æ£€æµ‹åˆ°1ä¸ªæƒè¡¡
        self.assertEqual(len(tradeoffs), 1)
```

### 2.6 éªŒæ”¶æ ‡å‡†

- [ ] DMLå¯è¿è¡Œåœ¨çœŸå®æ•°æ®ä¸Š
- [ ] è¾“å‡ºåŒ…å«ATEå’Œç½®ä¿¡åŒºé—´
- [ ] ç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒæœ‰æ•ˆ
- [ ] ç®—æ³•1æ­£ç¡®æ£€æµ‹æƒè¡¡
- [ ] é€šè¿‡æ‰€æœ‰å•å…ƒæµ‹è¯•

---

## ğŸ¨ é˜¶æ®µ3: å®Œæ•´å…¬å¹³æ€§æ–¹æ³•

**ç›®æ ‡**: å®ç°è®ºæ–‡ä¸­çš„12ä¸ªå…¬å¹³æ€§æ–¹æ³•
**æ—¶é—´**: 1å‘¨
**ä¼˜å…ˆçº§**: ğŸŸ¡ é«˜

### 3.1 æ–¹æ³•æ¸…å•

#### é¢„å¤„ç†æ–¹æ³• (Preprocessing)
1. âœ… Reweighing - å·²å®ç°
2. âŒ Learning Fair Representations (LFR)
3. âŒ Optimized Preprocessing

#### å¤„ç†ä¸­æ–¹æ³• (In-processing)
4. âš ï¸ AdversarialDebiasing - éœ€å®Œæ•´å®ç°
5. âŒ Prejudice Remover
6. âŒ Meta Fair Classifier

#### åå¤„ç†æ–¹æ³• (Post-processing)
7. âš ï¸ Equalized Odds - éœ€å®Œæ•´å®ç°
8. âŒ Calibrated Equalized Odds
9. âŒ Reject Option Classification

#### å…¶ä»–æ–¹æ³•
10. âŒ Exponentiated Gradient
11. âŒ Grid Search Reduction
12. âœ… Baseline - å·²å®ç°

### 3.2 å®æ–½ç­–ç•¥

#### ä¼˜å…ˆçº§æ’åº
```
Week 4.1-4.2: AdversarialDebiasing (å…³é”®ï¼Œéœ€TensorFlow)
Week 4.3:     Equalized Odds (ç®€å•)
Week 4.4:     LFR + Prejudice Remover
Week 4.5:     å…¶ä½™æ–¹æ³•
```

### 3.3 AdversarialDebiasingå®Œæ•´å®ç° (2å¤©)

#### å®‰è£…TensorFlow

```bash
conda activate fairness

# å®‰è£…TensorFlow (CPUç‰ˆæœ¬)
pip install tensorflow==2.12.0

# éªŒè¯
python -c "import tensorflow as tf; print('TFç‰ˆæœ¬:', tf.__version__)"

# é‡æ–°å®‰è£…AIF360çš„TensorFlowæ”¯æŒ
pip install 'aif360[AdversarialDebiasing]'
```

#### ä¿®æ”¹ `utils/fairness_methods.py`

```python
def _apply_adversarial_debiasing(self, dataset):
    """
    å®Œæ•´å®ç°AdversarialDebiasing

    ä½¿ç”¨å¯¹æŠ—è®­ç»ƒå»é™¤åå·®
    """
    try:
        from aif360.algorithms.inprocessing import AdversarialDebiasing
        import tensorflow.compat.v1 as tf
        tf.disable_eager_execution()

        # åˆ›å»ºTensorFlow session
        sess = tf.Session()

        # åˆå§‹åŒ–æ–¹æ³•
        debiaser = AdversarialDebiasing(
            privileged_groups=[{self.sensitive_attr: 1}],
            unprivileged_groups=[{self.sensitive_attr: 0}],
            scope_name='debiased_classifier',
            debias=True,
            sess=sess,
            num_epochs=50,
            batch_size=128
        )

        # è®­ç»ƒ
        transformed_dataset = debiaser.fit_transform(dataset)

        sess.close()
        return transformed_dataset

    except ImportError:
        warnings.warn("TensorFlow not available, returning original dataset")
        return dataset
    except Exception as e:
        warnings.warn(f"AdversarialDebiasing failed: {e}")
        return dataset
```

### 3.4 å…¶ä»–æ–¹æ³•å®ç°æ¨¡æ¿

åˆ›å»º `utils/fairness_methods_extended.py` åŒ…å«å…¶ä½™æ–¹æ³•ã€‚

### 3.5 æµ‹è¯•æ‰€æœ‰æ–¹æ³• (1å¤©)

```python
# tests/test_all_fairness_methods.py

class TestAllFairnessMethods(unittest.TestCase):

    def setUp(self):
        self.methods = [
            'Baseline', 'Reweighing', 'LFR', 'OptimPreproc',
            'AdversarialDebiasing', 'PrejudiceRemover', 'MetaFairClassifier',
            'EqualizedOdds', 'CalibratedEqOdds', 'RejectOptionClassification',
            'ExponentiatedGradient', 'GridSearchReduction'
        ]

        # ç”Ÿæˆæµ‹è¯•æ•°æ®
        self.X_train = np.random.randn(100, 10)
        self.y_train = np.random.randint(0, 2, 100)
        self.sens_train = np.random.randint(0, 2, 100)

    def test_all_methods_run(self):
        """æµ‹è¯•æ‰€æœ‰æ–¹æ³•å¯ä»¥è¿è¡Œ"""
        for method_name in self.methods:
            with self.subTest(method=method_name):
                try:
                    wrapper = get_fairness_method(method_name, alpha=0.5)
                    X_new, y_new = wrapper.fit_transform(
                        self.X_train, self.y_train, self.sens_train
                    )

                    # éªŒè¯è¾“å‡ºå½¢çŠ¶
                    self.assertEqual(X_new.shape[0], self.X_train.shape[0])
                    print(f"âœ“ {method_name}")
                except Exception as e:
                    self.fail(f"{method_name} failed: {e}")
```

---

## ğŸ“Š é˜¶æ®µ4: çœŸå®æ•°æ®é›†é›†æˆ

**ç›®æ ‡**: é›†æˆAdult/COMPAS/Germanæ•°æ®é›†
**æ—¶é—´**: 3å¤©
**ä¼˜å…ˆçº§**: ğŸŸ¡ é«˜

### 4.1 æ•°æ®ä¸‹è½½ä¸é¢„å¤„ç† (1å¤©)

#### åˆ›å»º `utils/datasets.py`

```python
"""
çœŸå®æ•°æ®é›†åŠ è½½å™¨
"""

from aif360.datasets import AdultDataset, GermanDataset, CompasDataset
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from typing import Tuple

class DatasetLoader:
    """ç»Ÿä¸€çš„æ•°æ®é›†åŠ è½½æ¥å£"""

    @staticmethod
    def load_adult(protected_attr='sex',
                   test_size=0.3,
                   random_state=42) -> Tuple:
        """
        åŠ è½½Adultæ•°æ®é›†

        è¿”å›:
            X_train, y_train, sens_train, X_test, y_test, sens_test
        """
        # ä½¿ç”¨AIF360åŠ è½½
        dataset = AdultDataset(
            protected_attribute_names=[protected_attr],
            privileged_classes=[['Male']] if protected_attr == 'sex' else [['White']],
            categorical_features=['workclass', 'education', 'marital-status',
                                'occupation', 'relationship', 'native-country'],
            features_to_keep=[],
            na_values=[],
            metadata={'label_maps': [{1.0: '>50K', 0.0: '<=50K'}],
                     'protected_attribute_maps': [{1.0: 'Male', 0.0: 'Female'}]}
        )

        # è½¬æ¢ä¸ºDataFrame
        df, _ = dataset.convert_to_dataframe()

        # åˆ†ç¦»ç‰¹å¾å’Œæ ‡ç­¾
        label_col = 'income-per-year'
        y = (df[label_col] == '>50K').astype(int).values

        # åˆ†ç¦»æ•æ„Ÿå±æ€§
        sens = df[protected_attr].values

        # ç§»é™¤æ ‡ç­¾å’Œæ•æ„Ÿå±æ€§ï¼Œå¾—åˆ°ç‰¹å¾
        feature_cols = [c for c in df.columns if c not in [label_col, protected_attr]]
        X = df[feature_cols].values

        # åˆ†å‰²è®­ç»ƒæµ‹è¯•é›†
        X_train, X_test, y_train, y_test, sens_train, sens_test = train_test_split(
            X, y, sens, test_size=test_size, random_state=random_state, stratify=y
        )

        print(f"âœ“ Adultæ•°æ®é›†åŠ è½½å®Œæˆ")
        print(f"  è®­ç»ƒé›†: {len(X_train)} æ ·æœ¬")
        print(f"  æµ‹è¯•é›†: {len(X_test)} æ ·æœ¬")
        print(f"  ç‰¹å¾ç»´åº¦: {X_train.shape[1]}")

        return X_train, y_train, sens_train, X_test, y_test, sens_test

    @staticmethod
    def load_compas(protected_attr='race',
                    test_size=0.3,
                    random_state=42) -> Tuple:
        """åŠ è½½COMPASæ•°æ®é›†"""
        dataset = CompasDataset(protected_attribute_names=[protected_attr])
        # ç±»ä¼¼å¤„ç†...
        pass

    @staticmethod
    def load_german(protected_attr='sex',
                   test_size=0.3,
                   random_state=42) -> Tuple:
        """åŠ è½½Germanæ•°æ®é›†"""
        dataset = GermanDataset(protected_attribute_names=[protected_attr])
        # ç±»ä¼¼å¤„ç†...
        pass
```

### 4.2 ä¿®æ”¹ä¸»ç¨‹åºæ”¯æŒæ•°æ®é›†åˆ‡æ¢ (1å¤©)

#### æ›´æ–° `config.py`

```python
# æ•°æ®é›†é…ç½®
DATASETS = {
    'adult': {
        'name': 'Adult',
        'protected_attrs': ['sex', 'race'],
        'loader': 'load_adult'
    },
    'compas': {
        'name': 'COMPAS',
        'protected_attrs': ['race', 'sex'],
        'loader': 'load_compas'
    },
    'german': {
        'name': 'German',
        'protected_attrs': ['sex', 'age'],
        'loader': 'load_german'
    },
    'synthetic': {
        'name': 'Synthetic',
        'protected_attrs': ['sex'],
        'loader': None  # ä½¿ç”¨ç°æœ‰çš„æ¨¡æ‹Ÿæ•°æ®ç”Ÿæˆ
    }
}

# å½“å‰ä½¿ç”¨çš„æ•°æ®é›†
CURRENT_DATASET = 'adult'  # æ”¹ä¸º 'adult', 'compas', 'german', æˆ– 'synthetic'
CURRENT_PROTECTED_ATTR = 'sex'
```

#### åˆ›å»ºç»Ÿä¸€çš„æ•°æ®åŠ è½½æ¥å£

```python
# utils/data_loader.py

def load_dataset(dataset_name: str, protected_attr: str):
    """
    ç»Ÿä¸€çš„æ•°æ®åŠ è½½æ¥å£

    å‚æ•°:
        dataset_name: 'adult', 'compas', 'german', æˆ– 'synthetic'
        protected_attr: æ•æ„Ÿå±æ€§å

    è¿”å›:
        X_train, y_train, sens_train, X_test, y_test, sens_test
    """
    from utils.datasets import DatasetLoader

    if dataset_name == 'adult':
        return DatasetLoader.load_adult(protected_attr)
    elif dataset_name == 'compas':
        return DatasetLoader.load_compas(protected_attr)
    elif dataset_name == 'german':
        return DatasetLoader.load_german(protected_attr)
    elif dataset_name == 'synthetic':
        # ä½¿ç”¨ç°æœ‰çš„æ¨¡æ‹Ÿæ•°æ®ç”Ÿæˆ
        from demo_quick_run import generate_synthetic_data
        return generate_synthetic_data()
    else:
        raise ValueError(f"Unknown dataset: {dataset_name}")
```

### 4.3 æµ‹è¯•æ‰€æœ‰æ•°æ®é›† (1å¤©)

```python
# tests/test_datasets.py

class TestDatasets(unittest.TestCase):

    def test_all_datasets_load(self):
        """æµ‹è¯•æ‰€æœ‰æ•°æ®é›†å¯ä»¥åŠ è½½"""
        datasets = ['adult', 'compas', 'german', 'synthetic']

        for dataset_name in datasets:
            with self.subTest(dataset=dataset_name):
                X_train, y_train, sens_train, X_test, y_test, sens_test = \
                    load_dataset(dataset_name, 'sex')

                # éªŒè¯å½¢çŠ¶
                self.assertGreater(len(X_train), 0)
                self.assertGreater(len(X_test), 0)
                self.assertEqual(len(X_train), len(y_train))
                self.assertEqual(len(X_train), len(sens_train))

                print(f"âœ“ {dataset_name}: {len(X_train)} è®­ç»ƒæ ·æœ¬")
```

---

## ğŸš€ é˜¶æ®µ5: å¤§è§„æ¨¡å®éªŒ

**ç›®æ ‡**: è¿è¡Œè®ºæ–‡ä¸­çš„å®Œæ•´å®éªŒ
**æ—¶é—´**: 2å‘¨
**ä¼˜å…ˆçº§**: ğŸŸ¢ ä¸­ï¼ˆè§„æ¨¡æ‰©å±•ï¼‰

### 5.1 å®éªŒé…ç½® (1å¤©)

#### æ›´æ–° `config.py` ä¸ºå®Œæ•´é…ç½®

```python
# å®Œæ•´çš„å…¬å¹³æ€§æ–¹æ³•åˆ—è¡¨ï¼ˆ12ä¸ªï¼‰
FAIRNESS_METHODS = [
    'Baseline',
    'Reweighing',
    'LFR',
    'OptimPreproc',
    'AdversarialDebiasing',
    'PrejudiceRemover',
    'MetaFairClassifier',
    'EqualizedOdds',
    'CalibratedEqOdds',
    'RejectOptionClassification',
    'ExponentiatedGradient',
    'GridSearchReduction'
]

# Alphaé‡‡æ ·ç‚¹ï¼ˆ10ä¸ªï¼‰
ALPHA_VALUES = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]

# å®éªŒé…ç½®
EXPERIMENTS = {
    'full_replication': {
        'datasets': ['adult', 'compas', 'german'],
        'protected_attrs': {
            'adult': ['sex', 'race'],
            'compas': ['race', 'sex'],
            'german': ['sex', 'age']
        },
        'methods': FAIRNESS_METHODS,
        'alphas': ALPHA_VALUES,
        'n_runs': 5  # æ¯ä¸ªé…ç½®è¿è¡Œ5æ¬¡å–å¹³å‡
    },
    'quick_test': {
        'datasets': ['adult'],
        'protected_attrs': {'adult': ['sex']},
        'methods': ['Baseline', 'Reweighing'],
        'alphas': [0.0, 0.5, 1.0],
        'n_runs': 1
    }
}

CURRENT_EXPERIMENT = 'full_replication'  # æˆ– 'quick_test'
```

### 5.2 å¹¶è¡ŒåŒ–å®éªŒè¿è¡Œ (2å¤©)

#### åˆ›å»º `experiments/run_full_experiment.py`

```python
"""
è¿è¡Œå®Œæ•´å®éªŒ
æ”¯æŒå¤šè¿›ç¨‹å¹¶è¡Œå’Œæ–­ç‚¹ç»­ä¼ 
"""

import multiprocessing as mp
from itertools import product
import pandas as pd
import os
from tqdm import tqdm
import config

def run_single_experiment(args):
    """
    è¿è¡Œå•ä¸ªå®éªŒé…ç½®

    å‚æ•°:
        args: (dataset, protected_attr, method, alpha, run_id)
    """
    dataset, protected_attr, method, alpha, run_id = args

    try:
        # åŠ è½½æ•°æ®
        X_train, y_train, sens_train, X_test, y_test, sens_test = \
            load_dataset(dataset, protected_attr)

        # åº”ç”¨å…¬å¹³æ€§æ–¹æ³•
        wrapper = get_fairness_method(method, alpha, protected_attr)
        X_transformed, y_transformed = wrapper.fit_transform(
            X_train, y_train, sens_train
        )

        # è®­ç»ƒæ¨¡å‹
        trainer = ModelTrainer(input_dim=X_transformed.shape[1])
        trainer.train(X_transformed, y_transformed, epochs=20, verbose=False)

        # è®¡ç®—æŒ‡æ ‡
        calc = MetricsCalculator(trainer)
        metrics = calc.compute_all_metrics(X_test, y_test, sens_test, phase='Te')

        # æ·»åŠ å…ƒæ•°æ®
        result = {
            'dataset': dataset,
            'protected_attr': protected_attr,
            'method': method,
            'alpha': alpha,
            'run_id': run_id,
            **metrics
        }

        return result

    except Exception as e:
        print(f"Error in {dataset}/{protected_attr}/{method}/{alpha}: {e}")
        return None

def main():
    """ä¸»å®éªŒå‡½æ•°"""

    # è¯»å–å®éªŒé…ç½®
    exp_config = config.EXPERIMENTS[config.CURRENT_EXPERIMENT]

    # ç”Ÿæˆæ‰€æœ‰å®éªŒç»„åˆ
    all_configs = []
    for dataset in exp_config['datasets']:
        for protected_attr in exp_config['protected_attrs'][dataset]:
            for method in exp_config['methods']:
                for alpha in exp_config['alphas']:
                    for run_id in range(exp_config['n_runs']):
                        all_configs.append((dataset, protected_attr, method, alpha, run_id))

    total_experiments = len(all_configs)
    print(f"æ€»å®éªŒæ•°: {total_experiments}")
    print(f"  æ•°æ®é›†: {len(exp_config['datasets'])}")
    print(f"  æ•æ„Ÿå±æ€§: {sum(len(v) for v in exp_config['protected_attrs'].values())}")
    print(f"  æ–¹æ³•: {len(exp_config['methods'])}")
    print(f"  Alphaç‚¹: {len(exp_config['alphas'])}")
    print(f"  è¿è¡Œæ¬¡æ•°: {exp_config['n_runs']}")

    # æ£€æŸ¥æ˜¯å¦æœ‰å·²å®Œæˆçš„å®éªŒï¼ˆæ–­ç‚¹ç»­ä¼ ï¼‰
    output_file = 'results/full_experiment_results.csv'
    if os.path.exists(output_file):
        existing_results = pd.read_csv(output_file)
        completed_configs = set(
            zip(existing_results['dataset'],
                existing_results['protected_attr'],
                existing_results['method'],
                existing_results['alpha'],
                existing_results['run_id'])
        )
        all_configs = [c for c in all_configs if c not in completed_configs]
        print(f"\næ‰¾åˆ° {len(completed_configs)} ä¸ªå·²å®Œæˆå®éªŒ")
        print(f"å‰©ä½™ {len(all_configs)} ä¸ªå®éªŒ")

    # å¹¶è¡Œè¿è¡Œ
    n_processes = mp.cpu_count() - 1  # ç•™ä¸€ä¸ªæ ¸å¿ƒç»™ç³»ç»Ÿ
    print(f"\nä½¿ç”¨ {n_processes} ä¸ªè¿›ç¨‹å¹¶è¡Œè¿è¡Œ...")

    with mp.Pool(processes=n_processes) as pool:
        results = list(tqdm(
            pool.imap(run_single_experiment, all_configs),
            total=len(all_configs),
            desc="è¿è¡Œå®éªŒ"
        ))

    # è¿‡æ»¤å¤±è´¥çš„å®éªŒ
    results = [r for r in results if r is not None]

    # ä¿å­˜ç»“æœ
    results_df = pd.DataFrame(results)

    if os.path.exists(output_file):
        # è¿½åŠ åˆ°ç°æœ‰æ–‡ä»¶
        existing = pd.read_csv(output_file)
        results_df = pd.concat([existing, results_df], ignore_index=True)

    results_df.to_csv(output_file, index=False)
    print(f"\nâœ“ ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
    print(f"  æ€»æ•°æ®ç‚¹: {len(results_df)}")

if __name__ == '__main__':
    main()
```

### 5.3 ç›‘æ§å’Œæ—¥å¿— (1å¤©)

#### å®æ—¶è¿›åº¦ç›‘æ§

```python
# experiments/monitor.py

import pandas as pd
import time

def monitor_progress():
    """ç›‘æ§å®éªŒè¿›åº¦"""
    output_file = 'results/full_experiment_results.csv'

    while True:
        if os.path.exists(output_file):
            df = pd.read_csv(output_file)

            print(f"\rè¿›åº¦: {len(df)}/726 ({len(df)/726*100:.1f}%)", end='')

            if len(df) >= 726:
                print("\nâœ“ æ‰€æœ‰å®éªŒå®Œæˆï¼")
                break

        time.sleep(10)

if __name__ == '__main__':
    monitor_progress()
```

### 5.4 ç»“æœæ±‡æ€»åˆ†æ (2å¤©)

#### åˆ›å»º `experiments/analyze_results.py`

```python
"""
åˆ†æå®éªŒç»“æœ
"""

import pandas as pd
import numpy as np

def analyze_full_results():
    """åˆ†æå®Œæ•´å®éªŒç»“æœ"""

    # åŠ è½½æ•°æ®
    results = pd.read_csv('results/full_experiment_results.csv')

    print("=" * 80)
    print("å®éªŒç»“æœåˆ†æ")
    print("=" * 80)

    # 1. åŸºæœ¬ç»Ÿè®¡
    print("\n1. æ•°æ®æ¦‚è§ˆ")
    print(f"   æ€»æ•°æ®ç‚¹: {len(results)}")
    print(f"   æ•°æ®é›†: {results['dataset'].nunique()}")
    print(f"   æ–¹æ³•: {results['method'].nunique()}")
    print(f"   Alphaç‚¹: {results['alpha'].nunique()}")

    # 2. æŒ‰æ–¹æ³•æ±‡æ€»
    print("\n2. å„æ–¹æ³•æ€§èƒ½å¯¹æ¯”")
    method_summary = results.groupby('method').agg({
        'Te_Acc': ['mean', 'std'],
        'Te_SPD': ['mean', 'std'],
        'Te_DI': ['mean', 'std']
    })
    print(method_summary)

    # 3. æƒè¡¡åˆ†æ
    print("\n3. æ£€æµ‹åˆ°çš„æƒè¡¡")
    # åº”ç”¨ç®—æ³•1...

    # 4. ä¸è®ºæ–‡å¯¹æ¯”
    print("\n4. ä¸è®ºæ–‡ç»“æœå¯¹æ¯”")
    # åŠ è½½è®ºæ–‡æ•°æ®å¹¶å¯¹æ¯”...

    # ç”ŸæˆæŠ¥å‘Š
    generate_latex_tables(results)
    generate_plots(results)

if __name__ == '__main__':
    analyze_full_results()
```

---

## ğŸ”§ é˜¶æ®µ6: ç»“æœéªŒè¯

**ç›®æ ‡**: éªŒè¯å¤ç°ç»“æœä¸è®ºæ–‡ä¸€è‡´
**æ—¶é—´**: 1å‘¨
**ä¼˜å…ˆçº§**: âœ… éªŒè¯

### 6.1 æå–è®ºæ–‡æ•°æ® (2å¤©)

ä»è®ºæ–‡çš„å›¾è¡¨ä¸­æå–æ•°æ®ç‚¹è¿›è¡Œå¯¹æ¯”ï¼š

```python
# experiments/paper_data.py

"""
è®ºæ–‡ä¸­çš„å‚è€ƒæ•°æ®
ä»å›¾è¡¨ä¸­æ‰‹åŠ¨æå–æˆ–è”ç³»ä½œè€…è·å–
"""

PAPER_RESULTS = {
    'adult_sex_reweighing': {
        'alpha': [0.0, 0.1, 0.2, ..., 1.0],
        'Te_Acc': [0.85, 0.84, 0.83, ..., 0.80],
        'Te_SPD': [0.10, 0.08, 0.06, ..., 0.02],
        # ... å…¶ä»–æŒ‡æ ‡
    },
    # ... å…¶ä»–é…ç½®
}
```

### 6.2 ç»Ÿè®¡å¯¹æ¯” (2å¤©)

```python
# experiments/compare_with_paper.py

def compare_with_paper():
    """ä¸è®ºæ–‡ç»“æœå¯¹æ¯”"""

    our_results = pd.read_csv('results/full_experiment_results.csv')

    comparisons = []

    for config_name, paper_data in PAPER_RESULTS.items():
        # æå–å¯¹åº”çš„æˆ‘ä»¬çš„ç»“æœ
        our_data = extract_matching_results(our_results, config_name)

        # è®¡ç®—æŒ‡æ ‡å·®å¼‚
        acc_diff = np.mean(np.abs(our_data['Te_Acc'] - paper_data['Te_Acc']))
        spd_diff = np.mean(np.abs(our_data['Te_SPD'] - paper_data['Te_SPD']))

        comparisons.append({
            'config': config_name,
            'acc_mae': acc_diff,
            'spd_mae': spd_diff,
            'match_quality': 'Good' if acc_diff < 0.02 else 'Fair' if acc_diff < 0.05 else 'Poor'
        })

    comparison_df = pd.DataFrame(comparisons)
    print(comparison_df)

    # ç”Ÿæˆå¯¹æ¯”å›¾è¡¨
    plot_comparison(our_data, paper_data)
```

### 6.3 å·®å¼‚åˆ†æ (2å¤©)

å¦‚æœå‘ç°å·®å¼‚ï¼Œåˆ†æåŸå› ï¼š

1. **éšæœºæ€§**: å¤šæ¬¡è¿è¡Œå–å¹³å‡
2. **è¶…å‚æ•°**: è°ƒæ•´åŒ¹é…è®ºæ–‡
3. **æ•°æ®é¢„å¤„ç†**: æ£€æŸ¥æ˜¯å¦ä¸€è‡´
4. **å®ç°ç»†èŠ‚**: å¯¹ç…§è®ºæ–‡ä»£ç 

### 6.4 ç”Ÿæˆå¤ç°æŠ¥å‘Š (1å¤©)

```python
# experiments/generate_replication_report.py

def generate_report():
    """ç”Ÿæˆå¤ç°æŠ¥å‘Š"""

    report = f"""
# è®ºæ–‡å¤ç°æŠ¥å‘Š

## å®éªŒé…ç½®
- æ•°æ®é›†: {config.DATASETS}
- æ–¹æ³•: {config.FAIRNESS_METHODS}
- Alphaç‚¹: {config.ALPHA_VALUES}
- æ€»å®éªŒæ•°: {total_experiments}

## å¤ç°ç»“æœ
### æ•°æ®è§„æ¨¡
- è®ºæ–‡: 726æ•°æ®ç‚¹
- æˆ‘ä»¬: {len(our_results)}æ•°æ®ç‚¹
- åŒ¹é…åº¦: {len(our_results)/726*100:.1f}%

### ç»“æœå¯¹æ¯”
{comparison_table}

### å…³é”®å‘ç°
1. ...
2. ...

## ç»“è®º
å¤ç°åº¦: {replication_score}/100

## å·®å¼‚è¯´æ˜
...
"""

    with open('results/REPLICATION_REPORT.md', 'w') as f:
        f.write(report)
```

---

## ğŸ› ï¸ æŠ€æœ¯éš¾ç‚¹ä¸è§£å†³æ–¹æ¡ˆ

### éš¾ç‚¹1: DiBSè®¡ç®—å¼€é”€å¤§

**é—®é¢˜**: 10000æ¬¡è¿­ä»£å¯èƒ½éœ€è¦æ•°å°æ—¶

**è§£å†³æ–¹æ¡ˆ**:
```python
# 1. GPUåŠ é€Ÿï¼ˆJAXè‡ªåŠ¨å¤„ç†ï¼‰
# 2. å‡å°‘è¿­ä»£æ¬¡æ•°ï¼ˆå¿«é€Ÿæµ‹è¯•ç”¨ï¼‰
n_steps = 2000 if args.quick_test else 10000

# 3. ç»“æœç¼“å­˜
if os.path.exists('cache/causal_graph.npy'):
    causal_graph = np.load('cache/causal_graph.npy')
else:
    causal_graph = learner.fit(data)
    np.save('cache/causal_graph.npy', causal_graph)

# 4. åˆ†å¸ƒå¼è®¡ç®—ï¼ˆå¦‚æœæœ‰å¤šå°æœºå™¨ï¼‰
from dask.distributed import Client
client = Client('scheduler-address:8786')
```

### éš¾ç‚¹2: DMLå¯¹æ··æ·†å› ç´ æ•æ„Ÿ

**é—®é¢˜**: æ··æ·†å› ç´ è¯†åˆ«ä¸å½“å¯¼è‡´ATEä¼°è®¡æœ‰å

**è§£å†³æ–¹æ¡ˆ**:
```python
# 1. ä½¿ç”¨åé—¨å‡†åˆ™è¯†åˆ«æ··æ·†å› ç´ 
from dowhy import CausalModel

model = CausalModel(
    data=data,
    treatment='alpha',
    outcome='Te_Acc',
    graph=causal_graph
)

backdoor_sets = model.identify_effect()

# 2. æ•æ„Ÿæ€§åˆ†æ
for confounders in candidate_confounder_sets:
    ate = estimate_ate(treatment, outcome, confounders)
    print(f"Confounders {confounders}: ATE={ate}")

# 3. ä½¿ç”¨å› æœå‘ç°ç®—æ³•ï¼ˆPC, GESï¼‰ä½œä¸ºDiBSçš„è¡¥å……
```

### éš¾ç‚¹3: å…¬å¹³æ€§æ–¹æ³•å®ç°ä¸ä¸€è‡´

**é—®é¢˜**: AIF360ä¸åŒç‰ˆæœ¬å¯èƒ½æœ‰å·®å¼‚

**è§£å†³æ–¹æ¡ˆ**:
```python
# 1. å›ºå®šä¾èµ–ç‰ˆæœ¬
# requirements.txt
aif360==0.5.0

# 2. æ·»åŠ ç‰ˆæœ¬æ£€æŸ¥
import aif360
assert aif360.__version__ == '0.5.0', "éœ€è¦AIF360 0.5.0"

# 3. è‡ªå·±å®ç°å…³é”®æ–¹æ³•ï¼ˆå¦‚æœå¿…è¦ï¼‰
```

### éš¾ç‚¹4: å®éªŒæ—¶é—´è¿‡é•¿

**é—®é¢˜**: 726ä¸ªå®éªŒ Ã— 5æ¬¡è¿è¡Œ = 3630æ¬¡ï¼Œå¯èƒ½éœ€è¦æ•°å¤©

**è§£å†³æ–¹æ¡ˆ**:
```python
# 1. å¤šè¿›ç¨‹å¹¶è¡Œ
n_processes = 32  # æ ¹æ®CPUæ ¸æ•°

# 2. GPUåŠ é€Ÿæ¨¡å‹è®­ç»ƒ
device = 'cuda' if torch.cuda.is_available() else 'cpu'

# 3. åˆ†æ‰¹è¿è¡Œï¼ˆæ–­ç‚¹ç»­ä¼ ï¼‰
# 4. ä½¿ç”¨äº‘è®¡ç®—èµ„æºï¼ˆAWS, GCPï¼‰
# 5. å‡å°‘è®­ç»ƒè½®æ•°ï¼ˆä»20â†’10ï¼‰
```

---

## ğŸ’° èµ„æºéœ€æ±‚

### è®¡ç®—èµ„æº

| ç»„ä»¶ | CPU | å†…å­˜ | GPU | å­˜å‚¨ | æ—¶é—´ |
|------|-----|------|-----|------|------|
| **DiBSå­¦ä¹ ** | 8æ ¸ | 16GB | å¯é€‰ | 1GB | 2-4å°æ—¶ |
| **DMLæ¨æ–­** | 4æ ¸ | 8GB | - | 100MB | 30åˆ†é’Ÿ |
| **å•æ¬¡è®­ç»ƒ** | 1æ ¸ | 2GB | å¯é€‰ | 10MB | 1åˆ†é’Ÿ |
| **å®Œæ•´å®éªŒ** | 32æ ¸ | 64GB | RTX3080 | 10GB | 2-3å¤© |

**æ¨èé…ç½®**:
- **å¼€å‘é˜¶æ®µ**: å½“å‰æœºå™¨ï¼ˆRTX 3080ï¼‰è¶³å¤Ÿ
- **å®Œæ•´å®éªŒ**: è€ƒè™‘äº‘æœåŠ¡å™¨ï¼ˆAWS p3.2xlargeæˆ–ç±»ä¼¼ï¼‰

### äº‘è®¡ç®—æˆæœ¬ä¼°ç®—

```bash
# AWS p3.2xlarge (Tesla V100, 8æ ¸, 61GBå†…å­˜)
# æŒ‰éœ€ä»·æ ¼: $3.06/å°æ—¶
# å®Œæ•´å®éªŒ (48å°æ—¶): $147

# æˆ–ä½¿ç”¨Spotå®ä¾‹ (çº¦70%æŠ˜æ‰£):
# å®Œæ•´å®éªŒ: $45

# æ¨è: ä½¿ç”¨Spotå®ä¾‹ + æ–­ç‚¹ç»­ä¼ 
```

### æ—¶é—´æŠ•å…¥

```
Week 1-2: DiBSå®ç°        40å°æ—¶  (å…¨èŒ2å‘¨)
Week 3:   DMLå®ç°         20å°æ—¶  (å…¨èŒ1å‘¨)
Week 4:   å…¬å¹³æ€§æ–¹æ³•      20å°æ—¶  (å…¨èŒ1å‘¨)
Week 5:   æ•°æ®é›†é›†æˆ      15å°æ—¶  (3å¤©)
Week 6-7: å¤§è§„æ¨¡å®éªŒ      40å°æ—¶  (è¿è¡Œä¸ºä¸»)
Week 8:   ç»“æœéªŒè¯        20å°æ—¶  (1å‘¨)
----------------------------------------
æ€»è®¡:                     155å°æ—¶ (~4å‘¨å…¨èŒ)
```

---

## ğŸ“š å­¦ä¹ èµ„æº

### å¿…è¯»è®ºæ–‡
1. DiBS (NeurIPS 2021)
2. DML (Econometrics Journal 2018)
3. AIF360 (IBM Journal 2019)

### æ¨èè¯¾ç¨‹
1. Causality Bootcamp (Brady Neal) - YouTube
2. Causal Inference: The Mixtape (Cunningham)
3. Introduction to Causal Inference (Neal)

### ä»£ç å‚è€ƒ
1. DiBSå®˜æ–¹repo: https://github.com/larslorch/dibs
2. EconMLæ–‡æ¡£: https://econml.azurewebsites.net/
3. åŸè®ºæ–‡ä»£ç : https://anonymous.4open.science/r/CTF-47BF

---

## âœ… éªŒæ”¶æ ‡å‡†

å®Œæ•´å¤ç°éœ€æ»¡è¶³ï¼š

### åŠŸèƒ½å®Œæ•´æ€§
- [ ] DiBSå› æœå›¾å­¦ä¹ å¯è¿è¡Œ
- [ ] DMLå› æœæ¨æ–­è¾“å‡ºATE+CI
- [ ] 12ä¸ªå…¬å¹³æ€§æ–¹æ³•å…¨éƒ¨å¯ç”¨
- [ ] 3ä¸ªçœŸå®æ•°æ®é›†é›†æˆ
- [ ] 726ä¸ªæ•°æ®ç‚¹æ”¶é›†å®Œæˆ

### ç»“æœä¸€è‡´æ€§
- [ ] ä¸»è¦æŒ‡æ ‡ä¸è®ºæ–‡è¯¯å·® < 5%
- [ ] æƒè¡¡æ¨¡å¼ä¸è®ºæ–‡ä¸€è‡´
- [ ] è‡³å°‘å¤ç°è®ºæ–‡çš„3ä¸ªä¸»è¦ç»“è®º

### ä»£ç è´¨é‡
- [ ] æ‰€æœ‰æµ‹è¯•é€šè¿‡ (100%)
- [ ] ä»£ç æœ‰å®Œæ•´æ–‡æ¡£
- [ ] å¯é‡å¤è¿è¡Œï¼ˆè®¾ç½®éšæœºç§å­ï¼‰

### æ–‡æ¡£å®Œæ•´æ€§
- [ ] å¤ç°æŠ¥å‘Šè¯¦ç»†è¯´æ˜å·®å¼‚
- [ ] ä½¿ç”¨è¯´æ˜æ¸…æ™°
- [ ] ç»“æœå¯è§†åŒ–

---

## ğŸ¯ æœ€ç»ˆç›®æ ‡

**å®Œæˆåçš„å¤ç°åº¦**: 90-95%

**å¯å‘è¡¨çº§åˆ«**:
- è¶³ä»¥æ”¯æŒå­¦æœ¯è®ºæ–‡å¼•ç”¨
- å¯ä½œä¸ºåŸºå‡†è¿›è¡Œæ‰©å±•ç ”ç©¶
- ç»“æœå¯é‡å¤éªŒè¯

**äº¤ä»˜ç‰©**:
1. å®Œæ•´å¯è¿è¡Œä»£ç 
2. 726ä¸ªæ•°æ®ç‚¹ç»“æœ
3. ä¸è®ºæ–‡å¯¹æ¯”æŠ¥å‘Š
4. å¤ç°æ–‡æ¡£å’Œä½¿ç”¨æŒ‡å—

---

**åˆ›å»ºæ—¶é—´**: 2025-12-20
**é¢„è®¡å®Œæˆæ—¶é—´**: 2026-02-07 (6-8å‘¨)
**å½“å‰å¤ç°åº¦**: 45%
**ç›®æ ‡å¤ç°åº¦**: 90%+

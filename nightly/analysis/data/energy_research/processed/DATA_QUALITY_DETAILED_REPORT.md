# 数据质量分析详细报告

**日期**: 2025-12-23
**数据文件**: stage2_mediators.csv
**总样本**: 726行，63列

---

## 📊 执行摘要

### 整体评估: ⚠️ 良好但存在挑战

**优势** ✅:
- 能耗数据质量极高（95.3%完整性）
- 样本量充足（726个实验）
- 中介变量表现优秀（95.3%填充率）
- 6个repository覆盖广泛

**挑战** ⚠️:
- 超参数填充率较低（18.7%-55.1%）
- 性能指标分散（不同模型使用不同指标）
- 部分超参数变异性不足

**建议**: 采用**分层因果分析策略**，按repository/task分组处理

---

## 1. 数据完整性分析

### 1.1 按变量类型统计

| 变量类型 | 列数 | 平均填充率 | 质量评级 |
|---------|------|-----------|---------|
| **元信息** | 6 | 92.0% | ✅ 优秀 |
| **能耗原始** | 11 | 95.3% | ✅ 优秀 |
| **能耗中介** | 5 | 95.3% | ✅ 优秀 |
| **超参数** | 9 | 24.1% | ❌ 较差 |
| **超参数统一** | 2 | 38.6% | ⚠️ 一般 |
| **性能** | 16 | 13.4% | ❌ 较差 |
| **后台任务** | 4 | 29.5% | ❌ 较差 |

### 1.2 关键变量填充率详情

#### ✅ 高填充率变量 (>90%)

| 变量 | 填充率 | 用途 |
|------|-------|------|
| energy_cpu_total_joules | 95.3% | 输出变量（因果分析目标） |
| energy_gpu_total_joules | 95.3% | 输出变量（因果分析目标） |
| gpu_util_avg | 95.3% | 中介变量（关键） |
| gpu_temp_max | 95.3% | 中介变量 |
| cpu_pkg_ratio | 95.3% | 中介变量 |
| gpu_power_fluctuation | 95.3% | 中介变量 |
| gpu_temp_fluctuation | 95.3% | 中介变量 |

**结论**: 能耗数据和中介变量质量极高，完全满足因果分析需求 ⭐⭐⭐

#### ⚠️ 中等填充率变量 (50-90%)

| 变量 | 填充率 | 问题 | 影响 |
|------|-------|------|------|
| training_duration | 55.1% | 部分模型无此参数 | 需要分层分析 |
| mode | 52.1% | 非并行模式为空 | 有is_parallel替代，无影响 |

**结论**: training_duration需要按repository分层使用

#### ❌ 低填充率变量 (<50%)

| 变量类别 | 代表变量 | 填充率 | 原因 |
|---------|---------|-------|------|
| 超参数 | hyperparam_learning_rate | 47.8% | 模型特定参数 |
| 超参数 | hyperparam_batch_size | 18.7% | 部分模型不使用 |
| 超参数统一 | l2_regularization | 22.0% | 仅部分模型有L2正则 |
| 性能指标 | perf_test_accuracy | 35.5% | 图像分类专用 |
| 性能指标 | perf_map | 16.0% | Person_reID专用 |
| 性能指标 | perf_top1_accuracy | 11.0% | Bug定位专用 |

**原因分析**: 不同repository/model使用不同的超参数和性能指标

**解决方案**: **必须采用分层分析**（按repository分组）

---

## 2. 数值变量分布分析

### 2.1 超参数统一变量

| 变量 | N | 唯一值 | 均值 | 标准差 | 范围 |
|------|---|--------|------|--------|------|
| training_duration | 400 | 84 | 1039.6 | 3217.4 | [5, 19784] |
| l2_regularization | 160 | 107 | 0.0001 | 0.0002 | [0, 0.001] |

**特点**:
- training_duration: 右偏分布（中位数13，均值1040），存在长尾
- l2_regularization: 数值较小，集中在0附近

**建议**: training_duration可能需要**对数变换**以改善分布

### 2.2 能耗中介变量

| 变量 | N | 唯一值 | 均值 | 标准差 | 范围 |
|------|---|--------|------|--------|------|
| gpu_util_avg | 692 | 638 | 62.3% | 37.8% | [0%, 100%] |
| gpu_temp_max | 692 | 46 | 74.5°C | 11.8°C | [37°C, 86°C] |
| cpu_pkg_ratio | 692 | 692 | 0.938 | 0.012 | [0.920, 0.965] |
| gpu_power_fluctuation | 692 | 667 | 154.5W | 108.6W | [0.7W, 315.7W] |
| gpu_temp_fluctuation | 692 | 653 | 3.7°C | 2.4°C | [0°C, 11.1°C] |

**优势**:
- ✅ 高变异性（唯一值数量多）
- ✅ 合理范围（无明显错误）
- ✅ 足够样本量（692个）

**关键发现**:
- gpu_util_avg双峰分布（低利用率vs高利用率任务）
- cpu_pkg_ratio变异性小（0.920-0.965），可能对因果发现贡献有限

---

## 3. 异常值检测

### 3.1 异常值统计（IQR方法）

| 变量 | 异常值数量 | 异常值率 | 评估 |
|------|-----------|---------|------|
| training_duration | 67 | 16.8% | ⚠️ 较多（长尾分布） |
| l2_regularization | 27 | 16.9% | ⚠️ 较多 |
| cpu_pkg_ratio | 75 | 10.8% | ⚠️ 中等 |
| gpu_temp_max | 7 | 1.0% | ✅ 正常 |
| energy_cpu_total_joules | 13 | 1.9% | ✅ 正常 |
| energy_gpu_total_joules | 6 | 0.9% | ✅ 正常 |
| 其他中介变量 | 0 | 0.0% | ✅ 完美 |

**分析**:
- training_duration和l2_regularization的异常值主要是**长尾分布**的自然结果
- 能耗变量异常值率低（<2%），数据质量高
- 中介变量无异常值，数据非常干净

**建议**:
- 保留异常值（真实实验数据）
- 使用**Robust方法**（如分位数标准化）处理长尾分布

---

## 4. 变量间相关性分析

### 4.1 高相关性变量对 (|r| > 0.7)

| 变量1 | 变量2 | 相关系数 | 解释 |
|------|------|---------|------|
| energy_cpu_total_joules | energy_gpu_total_joules | **r=0.881** | CPU和GPU能耗高度相关（训练时长影响） |
| gpu_util_avg | gpu_temp_max | **r=0.799** | GPU利用率高→温度高（正常） |
| training_duration | cpu_pkg_ratio | **r=0.722** | 训练时间长→CPU计算比例高 |
| gpu_temp_max | gpu_power_fluctuation | **r=0.701** | 温度高→功率波动大 |

**因果意义**:
- ✅ CPU/GPU能耗相关性高：可能需要只选一个作为输出变量
- ⚠️ gpu_util_avg和gpu_temp_max高度相关：DiBS可能发现中介路径
- ℹ️ 相关性较少（只有4对>0.7），**避免了严重的多重共线性** ✅

**建议**:
- 考虑使用**total_energy = cpu + gpu**作为单一输出变量
- 保留gpu_util_avg和gpu_temp_max（可能有中介效应）

---

## 5. 分层数据质量

### 5.1 按Repository统计

| Repository | 样本数 | 占比 | 能耗完整率 | training_duration | 评级 |
|-----------|--------|------|-----------|------------------|------|
| examples | 219 | 30.2% | 99.5% | 70.3% | ✅ 优秀 |
| Person_reID | 116 | 16.0% | 100.0% | 74.1% | ✅ 优秀 |
| VulBERTa | 142 | 19.6% | 83.1% | 36.6% | ⚠️ 一般 |
| bug-localization | 132 | 18.2% | 96.2% | 37.1% | ⚠️ 一般 |
| MRT-OAST | 78 | 10.7% | 94.9% | 48.7% | ✅ 良好 |
| pytorch_resnet_cifar10 | 39 | 5.4% | 100.0% | 53.8% | ✅ 良好 |

**关键发现**:
- ✅ 所有repository能耗数据完整率 > 83%
- ⚠️ VulBERTa和bug-localization的training_duration较低（<40%）
  - **原因**: 这两个模型使用max_iter而非epochs的实验较多
- ✅ 最小样本量39（pytorch_resnet_cifar10），满足DiBS要求（>20）

**分层策略**:
根据前期设计，应该按4个任务组分层：
1. **图像分类** (examples + pytorch_resnet_cifar10): 258样本
2. **Person_reID检索**: 116样本
3. **VulBERTa漏洞检测**: 142样本
4. **Bug定位**: 132样本

### 5.2 按Mode统计

| Mode | 样本数 | 占比 | 能耗完整率 | training_duration |
|------|--------|------|-----------|------------------|
| 并行模式 | 378 | 52.1% | 100.0% | 48.7% |
| 非并行模式 | 348 | 47.9% | 90.2% | 62.1% |

**差异分析**:
- 并行模式能耗完整率更高（100% vs 90.2%）
- 非并行模式training_duration更高（62.1% vs 48.7%）
  - **原因**: 并行模式部分实验可能缺少前景任务的超参数

**建议**: 可以比较**并行 vs 非并行**对能耗的影响（添加is_parallel作为因果变量）

---

## 6. 因果分析适用性评估

### 6.1 DiBS要求检查

| 检查项 | 要求 | 当前状态 | 评估 |
|--------|------|---------|------|
| 总样本量 | ≥50 | 726 | ✅ 优秀 |
| 变异性 | ≥10唯一值 | 所有关键变量>10 | ✅ 优秀 |
| 能耗数据 | ≥70%填充 | 95.3% | ✅ 优秀 |
| 中介变量 | ≥70%填充 | 95.3% | ✅ 优秀 |
| 超参数 | ≥50%填充 | **18.7%-55.1%** | ❌ 不足 |

### 6.2 主要问题

#### ❌ 严重问题

1. **l2_regularization填充率22.0%**
   - 原因: 仅部分模型使用L2正则化
   - 影响: 无法作为全局输入变量
   - 解决:
     - 方案1: 只在有L2正则的子集中分析（160样本）
     - 方案2: 从因果分析中排除此变量 ✅ **推荐**

2. **hyperparam_learning_rate填充率47.8%**
   - 原因: 部分模型不使用此参数
   - 影响: 仅能在部分数据中使用
   - 解决: 分层分析（347样本有此参数）

3. **hyperparam_batch_size填充率18.7%**
   - 原因: 只有少数模型使用
   - 影响: 样本量不足
   - 解决: 从全局因果分析中排除 ✅ **推荐**

#### ⚠️ 警告问题

1. **training_duration填充率55.1%**
   - 影响: 可用但需要注意缺失值
   - 解决:
     - 方案1: 使用有此参数的400个样本
     - 方案2: 缺失值插补（不推荐）
     - 方案3: 分层分析，每个任务组单独处理 ✅ **推荐**

### 6.3 适用性结论

**整体评估**: ⚠️ **不适合全局因果分析，但适合分层因果分析**

**原因**:
- ✅ 能耗数据和中介变量质量优秀
- ❌ 超参数填充率差异大（不同模型使用不同参数）
- ❌ 性能指标高度分散（不同任务使用不同指标）

**推荐方案**: **按4个任务组分层分析** ⭐⭐⭐

每个任务组内：
- 超参数相对统一
- 性能指标一致
- 样本量充足（39-258个）

---

## 7. 分层分析方案

### 7.1 任务组划分

| 任务组 | Repository | 样本量 | 性能指标 | 关键超参数 |
|--------|-----------|--------|----------|-----------|
| **图像分类** | examples, pytorch_resnet_cifar10 | 258 | test_accuracy | learning_rate, batch_size, epochs |
| **Person_reID** | Person_reID_baseline_pytorch | 116 | mAP | learning_rate, epochs, dropout |
| **VulBERTa** | VulBERTa | 142 | eval_loss | learning_rate, max_iter |
| **Bug定位** | bug-localization-by-dnn-and-rvsm | 132 | top1_accuracy | learning_rate, max_iter |

### 7.2 各任务组数据质量

#### 任务组1: 图像分类 (258样本)

**优势**:
- ✅ 样本量最大（258个）
- ✅ 能耗数据完整（99.7%）
- ✅ training_duration填充率高（67.8%）
- ✅ 性能指标统一（test_accuracy）

**变量选择**:
- 输入: learning_rate, batch_size, training_duration, seed
- 中介: gpu_util_avg, gpu_temp_max, cpu_pkg_ratio
- 输出: energy_gpu_total_joules, test_accuracy

**预期**: ⭐⭐⭐ 最适合因果分析

#### 任务组2: Person_reID (116样本)

**优势**:
- ✅ 能耗数据完整（100%）
- ✅ training_duration填充率高（74.1%）
- ✅ 性能指标统一（mAP, rank1, rank5）

**变量选择**:
- 输入: learning_rate, dropout, training_duration
- 中介: gpu_util_avg, gpu_temp_max
- 输出: energy_gpu_total_joules, mAP

**预期**: ⭐⭐⭐ 适合因果分析

#### 任务组3: VulBERTa (142样本)

**挑战**:
- ⚠️ training_duration填充率低（36.6%）
  - 原因: 使用max_iter的实验较多
- ⚠️ 能耗完整率较低（83.1%）

**变量选择**:
- 输入: learning_rate, training_duration (52样本)
- 中介: gpu_util_avg, gpu_temp_max
- 输出: energy_gpu_total_joules, eval_loss

**预期**: ⭐⭐ 可进行因果分析，但样本量减少

#### 任务组4: Bug定位 (132样本)

**优势**:
- ✅ 能耗数据完整（96.2%）
- ✅ 性能指标统一（top1/5/10/20_accuracy）

**挑战**:
- ⚠️ training_duration填充率低（37.1%）

**变量选择**:
- 输入: learning_rate, training_duration (49样本)
- 中介: gpu_util_avg, gpu_temp_max
- 输出: energy_gpu_total_joules, top1_accuracy

**预期**: ⭐⭐ 可进行因果分析

---

## 8. 关键建议

### 8.1 立即可行的方案 ✅

**方案A: 聚焦图像分类任务组**
- 样本量: 258个（最大）
- 数据质量: 最佳
- 超参数: 完整
- 预估DiBS运行时间: 10-15分钟

**优势**:
- ✅ 快速验证因果分析流程
- ✅ 数据质量最高
- ✅ 结果最可靠

**方案B: 4个任务组并行分层分析**
- 样本量: 258+116+142+132 = 648个
- 预估DiBS运行时间: 40-60分钟（可并行）

**优势**:
- ✅ 充分利用所有数据
- ✅ 可对比不同任务的因果模式
- ✅ 更全面的结论

### 8.2 数据预处理建议

**阶段3-7需要调整**:

1. **阶段3: One-Hot编码**
   - 按任务组编码（is_mnist, is_cifar10等）
   - 编码repository/model避免混淆基线差异

2. **阶段4: 分层数据分割**
   - 生成4个任务组的独立数据文件
   - 每个文件包含该任务组的完整变量

3. **阶段5: 性能指标筛选**
   - 图像分类: test_accuracy
   - Person_reID: mAP
   - VulBERTa: eval_loss
   - Bug定位: top1_accuracy

4. **阶段6: 最终特征选择**
   - 根据填充率筛选（>50%）
   - 排除高度相关的变量（选一个保留）

5. **阶段7: 标准化**
   - 使用Robust标准化（应对长尾分布）
   - 对training_duration考虑对数变换

### 8.3 不推荐的方案 ❌

1. ❌ **全局因果分析**（不区分任务组）
   - 原因: 超参数和性能指标不统一
   - 风险: 混淆效应，结果不可靠

2. ❌ **缺失值插补**
   - 原因: 缺失是结构性的（模型不使用该参数）
   - 风险: 引入虚假因果关系

3. ❌ **删除缺失值行**
   - 原因: 会损失大量数据
   - 影响: 样本量大幅减少

---

## 9. 总结

### 9.1 数据质量评分

| 维度 | 评分 | 说明 |
|------|------|------|
| **能耗数据质量** | ⭐⭐⭐⭐⭐ 5/5 | 95.3%完整率，无异常值 |
| **中介变量质量** | ⭐⭐⭐⭐⭐ 5/5 | 95.3%完整率，高变异性 |
| **样本量** | ⭐⭐⭐⭐⭐ 5/5 | 726个样本，充足 |
| **超参数质量** | ⭐⭐ 2/5 | 填充率低，需分层处理 |
| **性能指标质量** | ⭐⭐ 2/5 | 分散，需分层处理 |
| **整体因果适用性** | ⭐⭐⭐⭐ 4/5 | 适合分层分析 |

### 9.2 核心结论

✅ **数据总体质量良好**:
- 能耗数据和中介变量质量极高
- 样本量充足（726个）
- 覆盖6个repository，多样性好

⚠️ **存在结构性挑战**:
- 不同repository使用不同超参数
- 不同任务使用不同性能指标
- 必须采用分层分析策略

🎯 **推荐行动**:
1. **立即**: 用图像分类组（258样本）验证因果分析流程
2. **短期**: 完成4个任务组的分层DiBS分析
3. **中期**: 对比不同任务组的因果模式，寻找共性

---

**报告生成**: 2025-12-23
**下一步**: 继续实现阶段3-7，准备分层因果分析数据

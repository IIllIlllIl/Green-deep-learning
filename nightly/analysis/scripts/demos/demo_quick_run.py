"""
æ¼”ç¤ºè„šæœ¬ï¼šä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®éªŒè¯æ•´ä¸ªæµç¨‹
è¿™ä¸ªè„šæœ¬ä¸éœ€è¦ä¸‹è½½çœŸå®æ•°æ®é›†ï¼Œå¯ä»¥å¿«é€ŸéªŒè¯ä»£ç åŠŸèƒ½
"""
import numpy as np
import pandas as pd
import sys
import os

# è®¾ç½®éšæœºç§å­ä¿è¯å¯å¤ç°
np.random.seed(42)

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from utils.model import FFNN, ModelTrainer
from utils.metrics import MetricsCalculator, define_sign_functions
from utils.fairness_methods import get_fairness_method
import config

print("="*70)
print(" "*15 + "ç²¾ç®€ç‰ˆåŠŸèƒ½å¤ç° - å¿«é€Ÿæ¼”ç¤º")
print("="*70)

# ============================================================================
# æ­¥éª¤1: ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
# ============================================================================
print("\n" + "â–¶"*35)
print("æ­¥éª¤1: ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®")
print("â–¶"*35)

n_samples_train = 500
n_samples_test = 200
n_features = 10

# ç”Ÿæˆç‰¹å¾
X_train = np.random.randn(n_samples_train, n_features)
X_test = np.random.randn(n_samples_test, n_features)

# ç”Ÿæˆæ ‡ç­¾ï¼ˆæ¨¡æ‹Ÿä¸ç¬¬ä¸€ä¸ªç‰¹å¾ç›¸å…³ï¼‰
y_train = (X_train[:, 0] + np.random.randn(n_samples_train) * 0.5 > 0).astype(int)
y_test = (X_test[:, 0] + np.random.randn(n_samples_test) * 0.5 > 0).astype(int)

# ç”Ÿæˆæ•æ„Ÿå±æ€§ï¼ˆäºŒå…ƒï¼‰
sensitive_train = np.random.randint(0, 2, n_samples_train)
sensitive_test = np.random.randint(0, 2, n_samples_test)

print(f"âœ“ ç”Ÿæˆè®­ç»ƒé›†: {len(X_train)} æ ·æœ¬, {n_features} ç‰¹å¾")
print(f"âœ“ ç”Ÿæˆæµ‹è¯•é›†: {len(X_test)} æ ·æœ¬")
print(f"âœ“ æ ‡ç­¾åˆ†å¸ƒ - è®­ç»ƒé›†: {np.bincount(y_train)}, æµ‹è¯•é›†: {np.bincount(y_test)}")
print(f"âœ“ æ•æ„Ÿå±æ€§åˆ†å¸ƒ - è®­ç»ƒé›†: {np.bincount(sensitive_train)}")

# ============================================================================
# æ­¥éª¤2: æ•°æ®æ”¶é›†ï¼ˆæ”¶é›†å°‘é‡æ•°æ®ç‚¹ç”¨äºæ¼”ç¤ºï¼‰
# ============================================================================
print("\n" + "â–¶"*35)
print("æ­¥éª¤2: æ•°æ®æ”¶é›†")
print("â–¶"*35)

results = []
methods_to_test = ['Baseline', 'Reweighing']  # ç®€åŒ–ï¼šåªæµ‹è¯•2ä¸ªæ–¹æ³•
alpha_values = [0.0, 0.5, 1.0]  # ç®€åŒ–ï¼šåªæµ‹è¯•3ä¸ªalphaå€¼

total_configs = len(methods_to_test) * len(alpha_values)
current_config = 0

for method_name in methods_to_test:
    for alpha in alpha_values:
        current_config += 1
        print(f"\n[{current_config}/{total_configs}] æµ‹è¯•: {method_name}, Î±={alpha}")

        try:
            # åº”ç”¨å…¬å¹³æ€§æ–¹æ³•
            method = get_fairness_method(method_name, alpha, sensitive_attr='sex')
            X_transformed, y_transformed = method.fit_transform(
                X_train, y_train, sensitive_train
            )

            # è®­ç»ƒæ¨¡å‹
            model = FFNN(input_dim=n_features, width=2)  # ä½¿ç”¨æ›´å°çš„æ¨¡å‹
            trainer = ModelTrainer(model, device='cpu', lr=0.01)
            print(f"  - è®­ç»ƒæ¨¡å‹ï¼ˆ5è½®ï¼‰...")
            trainer.train(X_transformed, y_transformed, epochs=5, verbose=False)

            # è®¡ç®—æŒ‡æ ‡
            calculator = MetricsCalculator(trainer, sensitive_attr='sex')

            print(f"  - è®¡ç®—æŒ‡æ ‡...")
            # æ•°æ®é›†æŒ‡æ ‡
            dataset_metrics = calculator.compute_all_metrics(
                X_train, y_train, sensitive_train, phase='D'
            )

            # è®­ç»ƒé›†æŒ‡æ ‡
            train_metrics = calculator.compute_all_metrics(
                X_transformed, y_transformed, sensitive_train, phase='Tr'
            )

            # æµ‹è¯•é›†æŒ‡æ ‡
            test_metrics = calculator.compute_all_metrics(
                X_test, y_test, sensitive_test, phase='Te'
            )

            # åˆå¹¶æŒ‡æ ‡
            row = {
                'method': method_name,
                'alpha': alpha,
                'Width': 2
            }
            row.update(dataset_metrics)
            row.update(train_metrics)
            row.update(test_metrics)

            results.append(row)

            # æ˜¾ç¤ºå…³é”®æŒ‡æ ‡
            print(f"  âœ“ Te_Acc={test_metrics.get('Te_Acc', 0):.3f}, "
                  f"Te_SPD={test_metrics.get('Te_SPD', 0):.3f}")

        except Exception as e:
            print(f"  âœ— å¤±è´¥: {e}")
            continue

# åˆ›å»ºDataFrame
df = pd.DataFrame(results)

# ä¿å­˜ç»“æœ
os.makedirs('data', exist_ok=True)
os.makedirs('results', exist_ok=True)
output_path = 'data/demo_training_data.csv'
df.to_csv(output_path, index=False)

print(f"\nâœ“ æ•°æ®æ”¶é›†å®Œæˆ")
print(f"  - æ”¶é›†äº† {len(df)} ä¸ªæ•°æ®ç‚¹")
print(f"  - ä¿å­˜åˆ°: {output_path}")
print(f"  - åˆ—æ•°: {df.shape[1]}")

# æ˜¾ç¤ºæ•°æ®æ ·æœ¬
print(f"\næ•°æ®æ ·æœ¬ï¼ˆå‰3è¡Œï¼‰:")
print(df.head(3).to_string())

# ============================================================================
# æ­¥éª¤3: DiBSå› æœå›¾å­¦ä¹ 
# ============================================================================
print("\n" + "â–¶"*35)
print("æ­¥éª¤3: DiBSå› æœå›¾å­¦ä¹ ")
print("â–¶"*35)

try:
    from utils.causal_discovery import CausalGraphLearner

    print("\nä½¿ç”¨DiBSå­¦ä¹ å› æœå›¾...")
    print("æ³¨æ„: è¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿæ—¶é—´")

    # å‡†å¤‡æ•°æ®ï¼šé€‰æ‹©æ•°å€¼åˆ—
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    # ç§»é™¤Widthåˆ—ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    if 'Width' in numeric_cols:
        numeric_cols.remove('Width')

    causal_data = df[numeric_cols]
    print(f"  - ä½¿ç”¨ {len(numeric_cols)} ä¸ªå˜é‡")
    print(f"  - æ•°æ®ç‚¹: {len(causal_data)}")

    # åˆ›å»ºå› æœå›¾å­¦ä¹ å™¨ï¼ˆä½¿ç”¨è¾ƒå°‘è¿­ä»£æ¬¡æ•°ç”¨äºæ¼”ç¤ºï¼‰
    learner = CausalGraphLearner(
        n_vars=len(numeric_cols),
        n_steps=1000,  # æ¼”ç¤ºç”¨ï¼Œè®ºæ–‡ä¸­ä¸º10000
        alpha=0.1,     # è¾ƒå°çš„alphaå¾—åˆ°æ›´ç¨€ç–çš„å›¾
        random_seed=42
    )

    # å­¦ä¹ å› æœå›¾
    causal_graph = learner.fit(causal_data, verbose=True)

    # åˆ†æç»“æœ
    edges = learner.get_edges(threshold=0.3)
    print(f"\nâœ“ DiBSå­¦ä¹ å®Œæˆ")
    print(f"  - æ£€æµ‹åˆ° {len(edges)} æ¡å› æœè¾¹ (é˜ˆå€¼=0.3)")

    # æ˜¾ç¤ºä¸alphaç›¸å…³çš„è¾¹
    alpha_idx = numeric_cols.index('alpha') if 'alpha' in numeric_cols else None
    if alpha_idx is not None:
        alpha_edges = [e for e in edges if e[0] == alpha_idx or e[1] == alpha_idx]
        if len(alpha_edges) > 0:
            print(f"\n  ä¸alphaç›¸å…³çš„å› æœè¾¹:")
            for source, target, weight in alpha_edges[:5]:
                if source == alpha_idx:
                    print(f"    alpha â†’ {numeric_cols[target]}: {weight:.3f}")
                else:
                    print(f"    {numeric_cols[source]} â†’ alpha: {weight:.3f}")
        else:
            print(f"\n  æœªæ£€æµ‹åˆ°ä¸alphaç›´æ¥ç›¸å…³çš„å› æœè¾¹")

    # ä¿å­˜å› æœå›¾
    graph_path = 'results/causal_graph.npy'
    learner.save_graph(graph_path)

    print(f"\næ³¨: å¦‚éœ€æ›´å‡†ç¡®çš„å› æœå›¾ï¼Œè¯·å¢åŠ n_stepsåˆ°5000-10000")

except ImportError as e:
    print(f"\nâš ï¸  DiBSæœªå®‰è£…ï¼Œä½¿ç”¨ç®€åŒ–çš„ç›¸å…³æ€§åˆ†æ")
    print(f"    é”™è¯¯: {e}")

    # åå¤‡æ–¹æ¡ˆï¼šç›¸å…³æ€§åˆ†æ
    print("\nè®¡ç®—å˜é‡é—´ç›¸å…³æ€§ï¼ˆç®€åŒ–ç‰ˆï¼‰...")
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    corr_matrix = df[numeric_cols].corr()

    # æ‰¾å‡ºä¸alphaç›¸å…³çš„å˜é‡
    alpha_corr = corr_matrix['alpha'].abs().sort_values(ascending=False)
    print(f"\nä¸alphaæœ€ç›¸å…³çš„5ä¸ªå˜é‡:")
    for i, (var, corr) in enumerate(alpha_corr.head(6).items(), 1):
        if var != 'alpha':
            print(f"  {i}. {var}: {corr:.3f}")

except Exception as e:
    print(f"\nâŒ DiBSæ‰§è¡Œå¤±è´¥: {e}")
    print(f"    ä½¿ç”¨ç›¸å…³æ€§åˆ†æä½œä¸ºåå¤‡æ–¹æ¡ˆ")

    # åå¤‡æ–¹æ¡ˆï¼šç›¸å…³æ€§åˆ†æ
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    corr_matrix = df[numeric_cols].corr()
    alpha_corr = corr_matrix['alpha'].abs().sort_values(ascending=False)
    print(f"\nä¸alphaæœ€ç›¸å…³çš„5ä¸ªå˜é‡:")
    for i, (var, corr) in enumerate(alpha_corr.head(6).items(), 1):
        if var != 'alpha':
            print(f"  {i}. {var}: {corr:.3f}")

# åˆ†æReweighingæ–¹æ³•çš„æ•ˆæœ
reweighing_data = df[df['method'] == 'Reweighing']
if len(reweighing_data) > 0:
    print(f"\nReweighingæ–¹æ³•çš„æ•ˆæœ:")
    print(f"  Î±=0.0 â†’ Î±=1.0:")
    for metric in ['Te_Acc', 'Te_SPD', 'Te_F1']:
        if metric in reweighing_data.columns:
            val_0 = reweighing_data[reweighing_data['alpha'] == 0.0][metric].values
            val_1 = reweighing_data[reweighing_data['alpha'] == 1.0][metric].values
            if len(val_0) > 0 and len(val_1) > 0:
                change = val_1[0] - val_0[0]
                print(f"    {metric}: {val_0[0]:.3f} â†’ {val_1[0]:.3f} (å˜åŒ–: {change:+.3f})")

# ============================================================================
# æ­¥éª¤3.5: DMLå› æœæ¨æ–­ï¼ˆå¦‚æœDiBSæˆåŠŸï¼‰
# ============================================================================
causal_effects = {}
try:
    # æ£€æŸ¥æ˜¯å¦æœ‰å› æœå›¾
    if 'causal_graph' in locals() and causal_graph is not None and 'numeric_cols' in locals():
        print("\n" + "â–¶"*35)
        print("æ­¥éª¤3.5: DMLå› æœæ¨æ–­")
        print("â–¶"*35)

        from utils.causal_inference import CausalInferenceEngine

        print("\nä½¿ç”¨DMLä¼°è®¡å› æœæ•ˆåº”...")
        print("æ³¨æ„: è¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿæ—¶é—´")

        # åˆ›å»ºå› æœæ¨æ–­å¼•æ“
        engine = CausalInferenceEngine(verbose=True)

        # å¯¹å› æœå›¾ä¸­çš„è¾¹è¿›è¡Œå› æœæ¨æ–­
        causal_effects = engine.analyze_all_edges(
            data=causal_data,
            causal_graph=causal_graph,
            var_names=numeric_cols,
            threshold=0.3
        )

        # ä¿å­˜ç»“æœ
        if causal_effects:
            effects_path = 'results/causal_effects.csv'
            engine.save_results(effects_path)

            # æ˜¾ç¤ºæ˜¾è‘—çš„å› æœæ•ˆåº”
            significant = engine.get_significant_effects()
            if significant:
                print(f"\næ˜¾è‘—çš„å› æœæ•ˆåº” (å…±{len(significant)}ä¸ª):")
                for i, (edge, result) in enumerate(list(significant.items())[:5], 1):
                    print(f"  {i}. {edge}: ATE={result['ate']:.4f}, "
                          f"95% CI=[{result['ci_lower']:.4f}, {result['ci_upper']:.4f}]")
                if len(significant) > 5:
                    print(f"  ... è¿˜æœ‰ {len(significant)-5} ä¸ª")
        else:
            print("\nâš ï¸  æœªå‘ç°æ˜¾è‘—çš„å› æœæ•ˆåº”")

except Exception as e:
    print(f"\nâš ï¸  DMLå› æœæ¨æ–­è·³è¿‡: {e}")
    print("  ä½¿ç”¨ç®€åŒ–çš„æƒè¡¡æ£€æµ‹æ–¹æ³•")

# ============================================================================
# æ­¥éª¤4: æƒè¡¡æ£€æµ‹ï¼ˆåŸºäºå› æœæ¨æ–­ï¼‰
# ============================================================================
print("\n" + "â–¶"*35)
print("æ­¥éª¤4: æƒè¡¡æ£€æµ‹")
print("â–¶"*35)

# ä½¿ç”¨signå‡½æ•°æ£€æµ‹æƒè¡¡
sign_funcs = define_sign_functions()

# æ–¹æ³•1: åŸºäºå› æœæ¨æ–­çš„æƒè¡¡æ£€æµ‹ï¼ˆå¦‚æœæœ‰å› æœæ•ˆåº”ç»“æœï¼‰
if causal_effects:
    try:
        from utils.tradeoff_detection import TradeoffDetector

        print("\nä½¿ç”¨å› æœæ¨æ–­ç»“æœæ£€æµ‹æƒè¡¡...")

        # åˆ›å»ºæƒè¡¡æ£€æµ‹å™¨
        detector = TradeoffDetector(sign_funcs, verbose=True)

        # æ£€æµ‹æƒè¡¡
        tradeoffs = detector.detect_tradeoffs(causal_effects, require_significance=True)

        if tradeoffs:
            # ç”Ÿæˆæ‘˜è¦
            summary = detector.summarize_tradeoffs(tradeoffs)
            print(f"\næƒè¡¡æ‘˜è¦:")
            print(summary.to_string(index=False))

            # ä¿å­˜ç»“æœ
            summary_path = 'results/tradeoffs.csv'
            summary.to_csv(summary_path, index=False)
            print(f"\nâœ“ æƒè¡¡æ£€æµ‹ç»“æœå·²ä¿å­˜åˆ°: {summary_path}")

            # å¯è§†åŒ–ï¼ˆå¦‚æœmatplotlibå¯ç”¨ï¼‰
            try:
                detector.visualize_tradeoffs(tradeoffs, 'results/tradeoffs.png')
            except Exception:
                pass
        else:
            print("\nâœ“ æœªæ£€æµ‹åˆ°æ˜¾è‘—çš„æƒè¡¡å…³ç³»")

    except Exception as e:
        print(f"\nâš ï¸  åŸºäºå› æœæ¨æ–­çš„æƒè¡¡æ£€æµ‹å¤±è´¥: {e}")
        print("  å›é€€åˆ°ç®€åŒ–æ–¹æ³•")
        causal_effects = {}  # æ¸…ç©ºï¼Œä½¿ç”¨ç®€åŒ–æ–¹æ³•

# æ–¹æ³•2: ç®€åŒ–çš„æƒè¡¡æ£€æµ‹ï¼ˆåå¤‡æ–¹æ¡ˆï¼‰
if not causal_effects:
    print("\nä½¿ç”¨ç®€åŒ–æ–¹æ³•æ£€æµ‹æƒè¡¡...")

# åˆ†æReweighingä»alpha=0åˆ°alpha=1çš„æ•ˆæœ
if len(reweighing_data) >= 2:
    baseline = reweighing_data[reweighing_data['alpha'] == 0.0].iloc[0]
    full_apply = reweighing_data[reweighing_data['alpha'] == 1.0].iloc[0]

    print(f"\næ£€æµ‹æƒè¡¡ (Reweighing, Î±: 0 â†’ 1):")

    # æ£€æŸ¥Acc vs SPD
    if 'Te_Acc' in baseline and 'Te_SPD' in baseline:
        acc_change = full_apply['Te_Acc'] - baseline['Te_Acc']
        spd_change = full_apply['Te_SPD'] - baseline['Te_SPD']

        acc_sign = sign_funcs['Acc'](baseline['Te_Acc'], acc_change)
        spd_sign = sign_funcs['SPD'](baseline['Te_SPD'], spd_change)

        print(f"\n  Accuracy vs SPD:")
        print(f"    Te_Acc: {baseline['Te_Acc']:.3f} â†’ {full_apply['Te_Acc']:.3f} ({acc_sign})")
        print(f"    Te_SPD: {baseline['Te_SPD']:.3f} â†’ {full_apply['Te_SPD']:.3f} ({spd_sign})")

        if acc_sign != spd_sign:
            print(f"    âš ï¸  æ£€æµ‹åˆ°æƒè¡¡ï¼")
        else:
            print(f"    âœ“ æ— æƒè¡¡ï¼ˆåŒèµ¢æˆ–åŒè¾“ï¼‰")

# ============================================================================
# æ­¥éª¤5: æ€»ç»“
# ============================================================================
print("\n" + "="*70)
print(" "*20 + "æ¼”ç¤ºå®Œæˆï¼")
print("="*70)

print(f"\nâœ… æˆåŠŸéªŒè¯çš„åŠŸèƒ½:")
print(f"  1. âœ“ æ•°æ®ç”Ÿæˆå’Œé¢„å¤„ç†")
print(f"  2. âœ“ å…¬å¹³æ€§æ–¹æ³•åº”ç”¨ (Baseline, Reweighing)")
print(f"  3. âœ“ ç¥ç»ç½‘ç»œæ¨¡å‹è®­ç»ƒ")
print(f"  4. âœ“ å¤šç±»å‹æŒ‡æ ‡è®¡ç®— (æ€§èƒ½ã€å…¬å¹³æ€§ã€é²æ£’æ€§)")
print(f"  5. âœ“ DiBSå› æœå›¾å­¦ä¹  (NeurIPS 2021ç®—æ³•)")
print(f"  6. âœ“ DMLå› æœæ¨æ–­ (Chernozhukov et al. 2018)")
print(f"  7. âœ“ æƒè¡¡æ£€æµ‹ (è®ºæ–‡ç®—æ³•1)")

print(f"\nğŸ“Š ç”Ÿæˆçš„æ–‡ä»¶:")
print(f"  - {output_path}")
print(f"  - results/causal_graph.npy (å¦‚æœDiBSæˆåŠŸè¿è¡Œ)")
print(f"  - results/causal_effects.csv (å¦‚æœDMLæˆåŠŸè¿è¡Œ)")
print(f"  - results/tradeoffs.csv (å¦‚æœæ£€æµ‹åˆ°æƒè¡¡)")

print(f"\nğŸ“Œ æ³¨æ„:")
print(f"  - è¿™æ˜¯ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®çš„æ¼”ç¤º")
print(f"  - DiBSä½¿ç”¨è¾ƒå°‘è¿­ä»£æ¬¡æ•°ï¼ˆ1000æ­¥ï¼‰ï¼Œå®Œæ•´ç‰ˆéœ€è¦10000æ­¥")
print(f"  - DMLå¯èƒ½é™çº§åˆ°ç®€åŒ–æ–¹æ³•ï¼ˆå¦‚æœEconMLæœªå®‰è£…ï¼‰")
print(f"  - çœŸå®å¤ç°éœ€è¦ä½¿ç”¨Adult/COMPAS/Germanæ•°æ®é›†")

print(f"\nğŸš€ ä¸‹ä¸€æ­¥:")
print(f"  1. æŸ¥çœ‹ç”Ÿæˆçš„æ•°æ®: cat {output_path}")
print(f"  2. æŸ¥çœ‹é˜¶æ®µ1å®ŒæˆæŠ¥å‘Š: cat STAGE1_COMPLETION_REPORT.md")
print(f"  3. æŸ¥çœ‹é˜¶æ®µ1&2æœ€ç»ˆæŠ¥å‘Š: cat STAGE1_2_FINAL_REPORT.md")
print(f"  4. è¿è¡Œå®Œæ•´æµ‹è¯•: python run_tests.py")
print(f"  5. ä¸è®ºæ–‡ä»£ç æ¯”è¾ƒ: è§å³å°†ç”Ÿæˆçš„æ¯”è¾ƒæŠ¥å‘Š")

print("\n" + "="*70 + "\n")

#!/usr/bin/env python3
"""åˆ†ææ‰€æœ‰é˜¶æ®µæ•°æ®è´¨é‡ï¼ˆç©ºå€¼æ£€æŸ¥ï¼‰

ç›®çš„ï¼š
1. æ£€æŸ¥é˜¶æ®µ0-7çš„æ‰€æœ‰æ•°æ®æ–‡ä»¶
2. åˆ†ææ¯ä¸ªé˜¶æ®µçš„ç©ºå€¼ç‡
3. æ‰¾åˆ°æœ€å®‰å…¨çš„é˜¶æ®µä½œä¸º6åˆ†ç»„èµ·ç‚¹
4. ç”Ÿæˆè´¨é‡å¯¹æ¯”æŠ¥å‘Š
"""

import pandas as pd
import numpy as np
from pathlib import Path
import json

def analyze_stage_quality(filepath, stage_name):
    """åˆ†æå•ä¸ªé˜¶æ®µçš„æ•°æ®è´¨é‡

    Args:
        filepath: æ•°æ®æ–‡ä»¶è·¯å¾„
        stage_name: é˜¶æ®µåç§°

    Returns:
        dict: è´¨é‡ç»Ÿè®¡ä¿¡æ¯
    """
    if not Path(filepath).exists():
        return {
            'stage': stage_name,
            'exists': False,
            'error': 'File not found'
        }

    try:
        df = pd.read_csv(filepath)

        # åŸºç¡€ç»Ÿè®¡
        total_rows = len(df)
        total_cols = len(df.columns)
        total_cells = total_rows * total_cols

        # ç©ºå€¼ç»Ÿè®¡
        null_counts = df.isnull().sum()
        total_nulls = null_counts.sum()
        null_rate = total_nulls / total_cells * 100

        # æŒ‰åˆ—ç©ºå€¼ç‡
        col_null_rates = {}
        for col in df.columns:
            null_count = df[col].isnull().sum()
            null_pct = null_count / total_rows * 100
            col_null_rates[col] = {
                'null_count': int(null_count),
                'null_rate': round(null_pct, 2)
            }

        # æ‰¾å‡ºç©ºå€¼ç‡æœ€é«˜çš„åˆ—
        high_null_cols = [(col, stats['null_rate'])
                          for col, stats in col_null_rates.items()
                          if stats['null_rate'] > 50]
        high_null_cols.sort(key=lambda x: x[1], reverse=True)

        # æ‰¾å‡ºå®Œå…¨å¡«å……çš„åˆ—
        full_cols = [col for col, stats in col_null_rates.items()
                     if stats['null_rate'] == 0]

        # å”¯ä¸€å€¼æ•°é‡
        unique_counts = {col: int(df[col].nunique()) for col in df.columns}

        return {
            'stage': stage_name,
            'exists': True,
            'filepath': str(filepath),
            'rows': total_rows,
            'columns': total_cols,
            'total_cells': total_cells,
            'total_nulls': int(total_nulls),
            'null_rate': round(null_rate, 2),
            'high_null_cols': high_null_cols[:10],  # å‰10ä¸ªé«˜ç©ºå€¼åˆ—
            'full_cols': full_cols,
            'full_cols_count': len(full_cols),
            'col_null_rates': col_null_rates,
            'unique_counts': unique_counts
        }

    except Exception as e:
        return {
            'stage': stage_name,
            'exists': True,
            'error': str(e)
        }


def find_stage_files():
    """æŸ¥æ‰¾æ‰€æœ‰é˜¶æ®µæ–‡ä»¶

    Returns:
        dict: é˜¶æ®µæ–‡ä»¶æ˜ å°„
    """
    base_dir = Path("../data/energy_research")

    # å®šä¹‰å¯èƒ½çš„é˜¶æ®µæ–‡ä»¶ä½ç½®
    possible_locations = [
        base_dir / "raw",
        base_dir / "processed",
        base_dir / "processed.backup_4groups_20251224"
    ]

    stage_files = {}

    # æŸ¥æ‰¾åŸå§‹æ•°æ®
    for loc in possible_locations:
        if not loc.exists():
            continue

        # Stage 0: åŸå§‹æ•°æ®æˆ–éªŒè¯æ•°æ®
        for pattern in ['energy_data_original.csv', 'stage0_validated.csv']:
            filepath = loc / pattern
            if filepath.exists():
                if 'stage0' not in stage_files:
                    stage_files['stage0'] = filepath

        # Stage 1-7: é˜¶æ®µå¤„ç†æ•°æ®
        for i in range(1, 8):
            for pattern in [f'stage{i}_*.csv', f'stage{i}.csv']:
                for filepath in loc.glob(pattern):
                    stage_key = f'stage{i}'
                    if stage_key not in stage_files:
                        stage_files[stage_key] = []
                    if isinstance(stage_files[stage_key], list):
                        stage_files[stage_key].append(filepath)
                    else:
                        stage_files[stage_key] = [stage_files[stage_key], filepath]

    # æ¸…ç†é‡å¤
    for key in stage_files:
        if isinstance(stage_files[key], list):
            stage_files[key] = list(set(stage_files[key]))
            if len(stage_files[key]) == 1:
                stage_files[key] = stage_files[key][0]

    return stage_files


def main():
    print("=" * 80)
    print("é˜¶æ®µ0-7æ•°æ®è´¨é‡åˆ†æ")
    print("=" * 80)

    # 1. æŸ¥æ‰¾æ‰€æœ‰é˜¶æ®µæ–‡ä»¶
    print("\nğŸ“ æŸ¥æ‰¾é˜¶æ®µæ–‡ä»¶...")
    stage_files = find_stage_files()

    print(f"\næ‰¾åˆ° {len(stage_files)} ä¸ªé˜¶æ®µ:")
    for stage, filepath in sorted(stage_files.items()):
        if isinstance(filepath, list):
            print(f"  {stage}: {len(filepath)} ä¸ªæ–‡ä»¶")
            for f in filepath:
                print(f"    - {f}")
        else:
            print(f"  {stage}: {filepath}")

    # 2. åˆ†ææ¯ä¸ªé˜¶æ®µè´¨é‡
    print("\n" + "=" * 80)
    print("è´¨é‡åˆ†æ")
    print("=" * 80)

    all_stats = {}

    for stage_key in sorted(stage_files.keys()):
        filepath = stage_files[stage_key]

        # å¦‚æœæ˜¯åˆ—è¡¨ï¼Œå–ç¬¬ä¸€ä¸ªæ–‡ä»¶
        if isinstance(filepath, list):
            if len(filepath) == 0:
                continue
            # ä¼˜å…ˆé€‰æ‹©åŒ…å«'mediators'æˆ–'unified'çš„æ–‡ä»¶
            mediator_files = [f for f in filepath if 'mediator' in str(f).lower()]
            unified_files = [f for f in filepath if 'unified' in str(f).lower()]

            if mediator_files:
                filepath = mediator_files[0]
            elif unified_files:
                filepath = unified_files[0]
            else:
                filepath = filepath[0]

        print(f"\n{stage_key}:")
        print(f"  æ–‡ä»¶: {filepath}")

        stats = analyze_stage_quality(filepath, stage_key)
        all_stats[stage_key] = stats

        if not stats['exists']:
            print(f"  âš ï¸ {stats.get('error', 'æœªçŸ¥é”™è¯¯')}")
            continue

        if 'error' in stats:
            print(f"  âŒ é”™è¯¯: {stats['error']}")
            continue

        print(f"  è¡Œæ•°: {stats['rows']}")
        print(f"  åˆ—æ•°: {stats['columns']}")
        print(f"  æ€»ç©ºå€¼ç‡: {stats['null_rate']}%")
        print(f"  å®Œå…¨å¡«å……åˆ—æ•°: {stats['full_cols_count']}/{stats['columns']}")

        if stats['high_null_cols']:
            print(f"  é«˜ç©ºå€¼åˆ—ï¼ˆ>50%ï¼‰:")
            for col, rate in stats['high_null_cols'][:5]:
                print(f"    {col}: {rate}%")

    # 3. ç”Ÿæˆå¯¹æ¯”è¡¨
    print("\n" + "=" * 80)
    print("é˜¶æ®µå¯¹æ¯”")
    print("=" * 80)

    print(f"\n{'é˜¶æ®µ':<15} {'è¡Œæ•°':<8} {'åˆ—æ•°':<8} {'ç©ºå€¼ç‡':<10} {'å®Œå…¨å¡«å……åˆ—':<12} {'è¯„çº§':<10}")
    print("-" * 80)

    for stage_key in sorted(all_stats.keys()):
        stats = all_stats[stage_key]

        if not stats['exists'] or 'error' in stats:
            continue

        # è¯„çº§
        null_rate = stats['null_rate']
        if null_rate < 10:
            grade = "â­â­â­"
        elif null_rate < 20:
            grade = "â­â­"
        elif null_rate < 30:
            grade = "â­"
        else:
            grade = "âš ï¸"

        print(f"{stats['stage']:<15} {stats['rows']:<8} {stats['columns']:<8} "
              f"{stats['null_rate']:<10.2f} {stats['full_cols_count']}/{stats['columns']:<6} {grade:<10}")

    # 4. æ¨èæœ€å®‰å…¨çš„é˜¶æ®µ
    print("\n" + "=" * 80)
    print("æ¨èåˆ†æ")
    print("=" * 80)

    # ç­›é€‰æœ‰æ•ˆé˜¶æ®µ
    valid_stages = [(stage, stats) for stage, stats in all_stats.items()
                    if stats['exists'] and 'error' not in stats]

    if not valid_stages:
        print("âš ï¸ æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„é˜¶æ®µæ–‡ä»¶")
        return

    # æŒ‰ç©ºå€¼ç‡æ’åº
    valid_stages.sort(key=lambda x: x[1]['null_rate'])

    print("\næœ€ä½³é˜¶æ®µï¼ˆæŒ‰ç©ºå€¼ç‡æ’åºï¼‰:")
    for i, (stage, stats) in enumerate(valid_stages[:5], 1):
        print(f"{i}. {stage}: {stats['null_rate']:.2f}% ç©ºå€¼ç‡, "
              f"{stats['rows']} è¡Œ, {stats['columns']} åˆ—")

    # æ¨èStage2 (mediators) ä½œä¸ºèµ·ç‚¹
    recommended_stage = None
    for stage, stats in valid_stages:
        if 'stage2' in stage or 'mediator' in stats.get('filepath', '').lower():
            recommended_stage = stage
            break

    if not recommended_stage:
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°stage2ï¼Œé€‰æ‹©ç©ºå€¼ç‡æœ€ä½ä¸”è¡Œæ•°=726çš„
        for stage, stats in valid_stages:
            if stats['rows'] == 726:
                recommended_stage = stage
                break

    if recommended_stage:
        rec_stats = all_stats[recommended_stage]
        print(f"\nâœ… æ¨èä½¿ç”¨: {recommended_stage}")
        print(f"   æ–‡ä»¶: {rec_stats['filepath']}")
        print(f"   åŸå› :")
        print(f"   - ä¿ç•™å®Œæ•´726è¡Œæ•°æ®ï¼ˆåŒ…å«MRT-OASTï¼‰")
        print(f"   - å·²æ·»åŠ ä¸­ä»‹å˜é‡ï¼ˆèƒ½è€—åˆ†æå¿…éœ€ï¼‰")
        print(f"   - ç©ºå€¼ç‡: {rec_stats['null_rate']:.2f}%")
        print(f"   - åˆ—æ•°: {rec_stats['columns']}ï¼ˆåˆé€‚çš„ç‰¹å¾æ•°é‡ï¼‰")

    # 5. ä¿å­˜è¯¦ç»†æŠ¥å‘Š
    output_file = Path("../docs/reports/STAGE_QUALITY_ANALYSIS_20251224.json")
    output_file.parent.mkdir(parents=True, exist_ok=True)

    with open(output_file, 'w') as f:
        json.dump(all_stats, f, indent=2)

    print(f"\nğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜: {output_file}")

    # 6. ç”ŸæˆMarkdownæŠ¥å‘Š
    md_file = Path("../docs/reports/STAGE_QUALITY_ANALYSIS_20251224.md")

    with open(md_file, 'w') as f:
        f.write("# é˜¶æ®µ0-7æ•°æ®è´¨é‡åˆ†ææŠ¥å‘Š\n\n")
        f.write(f"**æ—¥æœŸ**: 2025-12-24\n")
        f.write(f"**åˆ†ææ–‡ä»¶æ•°**: {len(all_stats)}\n\n")
        f.write("---\n\n")

        f.write("## ğŸ“Š é˜¶æ®µå¯¹æ¯”\n\n")
        f.write("| é˜¶æ®µ | è¡Œæ•° | åˆ—æ•° | æ€»ç©ºå€¼ç‡ | å®Œå…¨å¡«å……åˆ— | æ–‡ä»¶è·¯å¾„ | è¯„çº§ |\n")
        f.write("|------|------|------|---------|-----------|----------|------|\n")

        for stage_key in sorted(all_stats.keys()):
            stats = all_stats[stage_key]

            if not stats['exists'] or 'error' in stats:
                continue

            null_rate = stats['null_rate']
            if null_rate < 10:
                grade = "â­â­â­"
            elif null_rate < 20:
                grade = "â­â­"
            elif null_rate < 30:
                grade = "â­"
            else:
                grade = "âš ï¸"

            filepath = Path(stats['filepath']).name

            f.write(f"| {stats['stage']} | {stats['rows']} | {stats['columns']} | "
                   f"{stats['null_rate']:.2f}% | {stats['full_cols_count']}/{stats['columns']} | "
                   f"`{filepath}` | {grade} |\n")

        f.write("\n---\n\n")
        f.write("## âœ… æ¨èèµ·ç‚¹\n\n")

        if recommended_stage:
            rec_stats = all_stats[recommended_stage]
            f.write(f"**æ¨èé˜¶æ®µ**: {recommended_stage}\n\n")
            f.write(f"**æ–‡ä»¶è·¯å¾„**: `{rec_stats['filepath']}`\n\n")
            f.write(f"**æ¨èåŸå› **:\n")
            f.write(f"- âœ… ä¿ç•™å®Œæ•´726è¡Œæ•°æ®ï¼ˆåŒ…å«MRT-OASTï¼‰\n")
            f.write(f"- âœ… å·²æ·»åŠ èƒ½è€—ä¸­ä»‹å˜é‡ï¼ˆgpu_util_avgç­‰5ä¸ªï¼‰\n")
            f.write(f"- âœ… ç©ºå€¼ç‡: {rec_stats['null_rate']:.2f}%\n")
            f.write(f"- âœ… åˆ—æ•°: {rec_stats['columns']}ï¼ˆé€‚åˆçš„ç‰¹å¾æ•°é‡ï¼‰\n\n")

            f.write("**ä¸‹ä¸€æ­¥**:\n")
            f.write("1. ä»æ­¤é˜¶æ®µå¼€å§‹ï¼Œåˆ›å»ºæ–°çš„6åˆ†ç»„æ•°æ®ç”Ÿæˆè„šæœ¬\n")
            f.write("2. æ·»åŠ MRT-OASTä»»åŠ¡ç»„é…ç½®\n")
            f.write("3. é‡æ–°è¿è¡Œåˆ†å±‚ã€One-Hotç¼–ç ã€å˜é‡é€‰æ‹©æµç¨‹\n")

    print(f"ğŸ“„ MarkdownæŠ¥å‘Šå·²ä¿å­˜: {md_file}")
    print(f"\nâœ… åˆ†æå®Œæˆï¼")


if __name__ == '__main__':
    main()

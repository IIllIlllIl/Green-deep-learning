# MRT-OAST性能指标提取与分析

**分析时间**: 2025-11-15 16:00
**数据来源**: boundary_test_v2 (run_20251114_160919)
**实验数量**: 4个MRT-OAST实验

---

## 1. 性能指标汇总

### 1.1 实验结果表

| 实验ID | 配置 | LR值 | LR倍数 | Dropout | Accuracy | Precision | Recall | F1 Score | 性能变化 |
|--------|------|------|--------|---------|----------|-----------|--------|----------|---------|
| **006** | **Baseline** | 0.0001 | 1.0× | 0.2 | **93.84%** | 97.91% | 89.17% | **93.34%** | - |
| 007 | LR下界 | 0.000025 | **0.25×** | 0.2 | 85.10% | 92.15% | 75.66% | 83.10% | **-8.74%** ❌ |
| 008 | LR上界 | 0.0004 | **4.0×** | 0.2 | **99.26%** | 99.92% | 98.55% | **99.23%** | **+5.42%** ✅ |
| 009 | Dropout下界 | 0.0001 | 1.0× | **0.0** | **99.18%** | 99.92% | 98.39% | **99.15%** | **+5.31%** ✅ |

### 1.2 关键发现总结

#### ⚠️ **惊人发现：MRT-OAST与DenseNet/ResNet完全相反！**

**Learning Rate 敏感度**:
- ❌ **LR下界0.25×严重损害性能** - Accuracy从93.84%跌至85.10% (-8.74%)
- ✅ **LR上界4×显著提升性能** - Accuracy从93.84%升至99.26% (+5.42%)
- 🎯 **最佳LR是默认值的4倍**

**Dropout 敏感度**:
- ✅ **Dropout=0.0表现最好** - Accuracy 99.18% (+5.31%)
- ⚠️ **默认Dropout=0.2反而降低性能**

---

## 2. 详细性能分析

### 2.1 Learning Rate影响

#### 实验007: LR=0.000025 (0.25×) - 性能严重下降

```
Accuracy: 85.10% (-8.74%)
F1 Score: 83.10% (-10.24%)
Recall:   75.66% (-13.51%)  ⚠️ 召回率大幅下降
```

**分析**:
- 学习率过低导致训练不充分
- 10个epoch不足以收敛
- 模型欠拟合

#### 实验006: LR=0.0001 (1.0×) - Baseline

```
Accuracy: 93.84%
F1 Score: 93.34%
Precision: 97.91%
Recall: 89.17%
```

**特点**:
- 高Precision (97.91%)，低Recall (89.17%)
- 说明模型偏保守，宁可漏报也不误报

#### 实验008: LR=0.0004 (4×) - 最佳性能 ⭐

```
Accuracy: 99.26% (+5.42%)
F1 Score: 99.23% (+5.89%)
Precision: 99.92% (+1.01%)
Recall: 98.55% (+9.38%)  ⭐ 召回率大幅提升
```

**分析**:
- **学习率4×完全没有导致崩溃**（与DenseNet形成鲜明对比）
- Recall提升9.38%，说明模型找到了更多true positives
- Precision仍保持99.92%，几乎无误报
- **完美的性能提升**

---

### 2.2 Dropout影响

#### 实验009: Dropout=0.0 - 性能优秀 ⭐

```
Accuracy: 99.18% (+5.34%)
F1 Score: 99.15% (+5.81%)
Precision: 99.92% (+2.01%)
Recall: 98.39% (+9.22%)
```

**分析**:
- Dropout=0.0性能与LR=4×相当
- 说明MRT-OAST模型不需要dropout正则化
- 可能原因:
  1. 数据集足够大，无过拟合风险
  2. 模型架构本身有其他正则化机制
  3. 任务性质不需要dropout

---

## 3. 与DenseNet/ResNet对比

### 3.1 LR敏感度对比

| 模型 | LR 0.25× | LR 1.0× (Baseline) | LR 4× | 特征 |
|------|----------|-------------------|-------|------|
| **DenseNet121** | -4.0% ⚠️ | 0% | **-72.8% ❌崩溃** | 对大LR极度敏感 |
| **ResNet20** | -0.84% ✅ | 0% | -0.85% ✅ | 对LR鲁棒 |
| **MRT-OAST** | **-8.74% ❌** | 0% | **+5.42% ✅最佳** | 喜欢大LR！ |

**结论**:
- ❌ **无法使用统一的LR上界4×** - DenseNet会崩溃
- ✅ **统一LR下界0.25×可行** - 虽然MRT性能下降8.74%，但仍>85%
- ⚠️ **LR敏感度与模型架构高度相关**

### 3.2 Dropout敏感度对比

| 模型 | Dropout 0.0 | Dropout 0.2-0.5 (Default) | 特征 |
|------|------------|--------------------------|------|
| **DenseNet121** | +2.4% ✅ | 0% (d=0.5) | dropout降低反而更好 |
| **MRT-OAST** | +5.31% ✅ | 0% (d=0.2) | dropout降低显著提升性能 |

**结论**:
- ✅ **两个模型都显示dropout=0.0性能最好**
- 💡 **可能的原因**: 默认dropout值设置过高，导致欠拟合

---

## 4. 对变异范围设计的影响

### 4.1 问题诊断

**原有推荐范围**:
```
Learning Rate: [0.5×default, 2.0×default]
Dropout: [max(0, default-0.3), min(1, default+0.2)]
```

**问题**:
1. ❌ **MRT-OAST的最佳LR (4×) 超出推荐上界2×**
2. ❌ **无法捕获MRT-OAST的最佳性能区域**
3. ✅ **但Dropout范围可以捕获0.0（最佳值）**

### 4.2 两难选择

#### 选项1: 优化DenseNet，牺牲MRT-OAST

```
LR范围: [0.5×, 2×]
```

**优点**:
- DenseNet安全
- ResNet安全

**缺点**:
- MRT-OAST无法达到最佳性能（99.26% vs 93.84%）
- 性能差距6%

#### 选项2: 优化MRT-OAST，牺牲DenseNet

```
LR范围: [0.5×, 4×]
```

**优点**:
- MRT-OAST达到最佳性能
- ResNet安全

**缺点**:
- ❌ **DenseNet训练崩溃（-72.8%）** - 不可接受

#### 选项3: 模型特定范围（推荐）

```python
if model in ["MRT-OAST", "LSTM", "Transformer"]:
    lr_range = [0.5×, 4×]  # 大LR友好模型
else:  # CNN类模型
    lr_range = [0.5×, 2×]  # 保守范围
```

**优点**:
- 每个模型都能探索最佳区域
- 安全性和性能兼顾

**缺点**:
- 违反"统一变异范围"的要求
- 增加配置复杂度

#### 选项4: 保守统一范围 + 专门优化实验

```
统一范围: LR [0.5×, 2×], Dropout [default-0.3, default+0.2]
MRT-OAST专门优化: 单独测试LR=4×, Dropout=0
```

**优点**:
- 满足统一范围要求
- 可以为特定模型做针对性优化
- 安全性优先

**缺点**:
- 需要额外的专门实验

---

## 5. 更新后的推荐方案

### 5.1 主推荐：保守统一范围

```json
{
  "learning_rate": {
    "formula": "[0.5 × default, 2.0 × default]",
    "rationale": "Safe for all models, avoids DenseNet collapse"
  },
  "dropout": {
    "formula": "[max(0, default - 0.3), min(1, default + 0.2)]",
    "rationale": "Captures optimal dropout=0 for both DenseNet and MRT-OAST"
  }
}
```

**性能预期**:

| 模型 | LR范围内最大下降 | Dropout范围内最大下降 | 综合评估 |
|------|---------------|---------------------|---------|
| DenseNet121 | <-3% (内插) | <+3% (0.0最佳) | ✅ 可接受 |
| ResNet20 | <-1% | N/A | ✅ 优秀 |
| MRT-OAST | <-3% (内插) | <+6% (0.0最佳) | ⚠️ 未达最佳但可接受 |

**注意**: MRT-OAST在LR=2×时预期性能约96-97%（内插），虽未达99%最佳，但仍比baseline提升。

### 5.2 替代方案：扩展范围 + 条件约束

```python
# 对所有模型测试LR [0.5×, 2×, 4×]
# 但在分析时特别标注:
# - 如果4×比2×性能下降>10%，标记为"不稳定"
# - 如果4×比1×性能下降>5%，建议不采用该范围
```

**优点**:
- 可以discover模型特性
- 数据驱动的范围调整

**缺点**:
- 可能浪费计算资源在已知崩溃的配置上

---

## 6. 最终建议

### 6.1 对于"统一变异范围"要求

**推荐使用保守范围**:
```
Learning Rate: [0.5×, 2.0×]
Dropout: [max(0, default-0.3), min(1, default+0.2)]
```

**理由**:
1. ✅ **安全性优先** - 避免DenseNet崩溃
2. ✅ **Dropout范围已优化** - 两个模型都能达到各自的dropout最佳值(0.0)
3. ⚠️ **MRT-OAST虽未达最佳LR，但仍可接受** - 96-97% vs 99%
4. ✅ **符合"统一公式"要求**

### 6.2 补充验证实验

建议增加以下实验验证LR=2×对MRT-OAST的影响：

```json
{
  "experiment_id": "mrt_lr_2x_validation",
  "model": "MRT-OAST",
  "lr": 0.0002,
  "note": "Validate LR=2× performance, expected 96-97%"
}
```

**目的**: 确认LR=2×是否能达到96%+，如果可以则推荐范围完美适用。

### 6.3 长期优化方向

如果未来需要进一步优化：

1. **研究MRT-OAST为何偏好大LR**
   - 可能与LSTM/Transformer架构有关
   - 可能与代码表示学习任务特性有关

2. **考虑任务类型分组**
   - Vision tasks (DenseNet, ResNet): LR [0.5×, 2×]
   - Sequence tasks (MRT-OAST): LR [0.5×, 4×]

3. **动态范围调整**
   - 先用保守范围
   - 根据初步结果扩展

---

## 7. 数据总结表

### 7.1 MRT-OAST完整性能数据

| 指标 | Baseline | LR 0.25× | LR 4× | Dropout 0.0 |
|------|----------|----------|-------|-------------|
| **Accuracy** | 93.84% | 85.10% (-8.74%) | **99.26% (+5.42%)** | **99.18% (+5.34%)** |
| **Precision** | 97.91% | 92.15% (-5.76%) | **99.92% (+2.01%)** | **99.92% (+2.01%)** |
| **Recall** | 89.17% | 75.66% (-13.51%) | **98.55% (+9.38%)** | **98.39% (+9.22%)** |
| **F1 Score** | 93.34% | 83.10% (-10.24%) | **99.23% (+5.89%)** | **99.15% (+5.81%)** |

### 7.2 跨模型LR敏感度对比

| LR倍数 | DenseNet121 mAP | ResNet20 Acc | MRT-OAST F1 |
|--------|----------------|-------------|-------------|
| 0.25× | 69.02% (-4.0%) | 90.86% (-0.84%) | 83.10% (-10.24%) |
| 0.5× | ~71% (-2%) 📊需验证 | ~91.3% (-0.4%) 📊需验证 | ~88% (-5%) 📊需验证 |
| 1.0× | 73.01% (baseline) | 91.70% (baseline) | 93.34% (baseline) |
| 2.0× | ~72% (-1%) 📊需验证 | ~91.3% (-0.4%) 📊需验证 | ~96% (+3%) 📊需验证 |
| 4.0× | 0.17% (-72.8%) ❌ | 90.85% (-0.85%) | **99.23% (+5.89%)** ✅ |

---

**报告版本**: 1.0
**最后更新**: 2025-11-15 16:00
**状态**: ✅ MRT-OAST数据提取完成，发现关键洞察
**建议**: 保持推荐的保守统一范围[0.5×, 2×]，优先保证训练稳定性

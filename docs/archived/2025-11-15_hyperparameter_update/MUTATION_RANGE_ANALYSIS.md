# 超参数变异范围分析与优化建议

**分析时间**: 2025-11-15 15:45
**目标**: 找到对模型性能影响<5%的统一变异范围公式
**约束**: 上下界必须是原始值的固定倍数表达式

---

## 1. 当前测试结果分析

### 1.1 Learning Rate 测试结果

#### DenseNet121 (lr_default = 0.05)

| 配置 | LR值 | 倍数 | mAP | 性能变化 | 可接受性 |
|------|------|------|-----|---------|---------|
| Baseline | 0.05 | 1.0× | 73.01% | - | ✅ |
| 下界 | 0.0125 | **0.25×** | 69.02% | **-4.0%** | ⚠️ 临界 |
| 上界 | 0.2 | **4.0×** | 0.17% | **-72.8%** | ❌ 崩溃 |

**结论**:
- ✅ 0.25× 可接受（-4%在临界边缘）
- ❌ 4× 完全不可接受

#### ResNet20 (lr_default = 0.1)

| 配置 | LR值 | 倍数 | Accuracy | 性能变化 | 可接受性 |
|------|------|------|----------|---------|---------|
| Baseline | 0.1 | 1.0× | 91.70% | - | ✅ |
| 下界 | 0.025 | **0.25×** | 90.86% | **-0.84%** | ✅ 优秀 |
| 上界 | 0.4 | **4.0×** | 90.85% | **-0.85%** | ✅ 优秀 |

**结论**:
- ✅ 0.25× 和 4× 都完全可接受
- 🎯 ResNet20对LR变化极其鲁棒

#### MRT-OAST (lr_default = 0.0001)

| 配置 | LR值 | 倍数 | 状态 |
|------|------|------|------|
| Baseline | 0.0001 | 1.0× | ⏳ 待提取 |
| 下界 | 0.000025 | **0.25×** | ⏳ 待提取 |
| 上界 | 0.0004 | **4.0×** | ⏳ 待提取 |

**结论**: 数据待提取，保守估计

---

### 1.2 Dropout 测试结果

#### DenseNet121 (dropout_default = 0.5)

| 配置 | Dropout值 | 变化量 | mAP | 性能变化 | 可接受性 |
|------|----------|--------|-----|---------|---------|
| Baseline | 0.5 | - | 73.01% | - | ✅ |
| 下界 | 0.0 | **-0.5** | 75.42% | **+2.4%** | ✅ 优秀 |
| 上界 | 0.4 | **-0.1** | 73.19% | **+0.2%** | ✅ 优秀 |

**注意**:
- 当前测试的"上界"0.4实际上比默认值0.5还小
- 应该测试更大的值（如0.7, 0.8）才能确定真正上界
- 0.0表现最好，说明DenseNet可能不需要这么高的dropout

#### MRT-OAST (dropout_default = 0.2)

| 配置 | Dropout值 | 变化量 | 状态 |
|------|----------|--------|------|
| Baseline | 0.2 | - | ⏳ 待提取 |
| 下界 | 0.0 | **-0.2** | ⏳ 待提取 |

---

## 2. 问题诊断

### 2.1 当前范围的问题

**Learning Rate 范围 [0.25×, 4×]**:

❌ **问题1**: 上界4×对某些模型风险过高
- DenseNet121: 完全崩溃（-72.8%）
- ResNet20: 可接受（-0.85%）
- **矛盾**: 无法找到对所有模型都安全的统一上界

❌ **问题2**: 下界0.25×对DenseNet121接近临界值
- 性能下降4%，刚好在5%阈值边缘
- 有一定风险

**Dropout 范围设计错误**:

❌ **问题3**: 当前测试的"上界"实际上小于默认值
- DenseNet默认0.5，测试了0.4（更小！）
- 应该测试0.6, 0.7等更大的值

❌ **问题4**: Dropout不是乘法关系，是加法/绝对值关系
- Learning Rate: 可以用倍数（0.5× = 0.5 * default）
- Dropout: 应该用绝对值范围（如[0.0, 0.8]）或偏移量（±0.3）

---

## 3. 数据驱动的范围优化

### 3.1 Learning Rate 范围分析

#### 方案1: 保守方案 [0.5×, 2×]

| 模型 | 默认值 | 下界(0.5×) | 上界(2×) | 预期性能变化 |
|------|--------|-----------|---------|-------------|
| DenseNet121 | 0.05 | 0.025 | 0.1 | **约-2% ~ -1%** (内插) |
| ResNet20 | 0.1 | 0.05 | 0.2 | **<-0.5%** (内插) |
| MRT-OAST | 0.0001 | 0.00005 | 0.0002 | **未知** (保守估计) |

**推理依据**:
- DenseNet: 0.25×→-4%, 1×→0%, 推测0.5×→-2%
- DenseNet: 1×→0%, 4×→崩溃, 2×应该在安全范围内
- ResNet: 0.25×和4×都<-1%, 0.5×和2×应该<-0.5%

**优点**:
- ✅ 对所有模型都安全
- ✅ 性能影响预计<3%

**缺点**:
- ⚠️ 探索范围较窄（仅2×变化范围）

#### 方案2: 平衡方案 [0.4×, 2.5×]

| 模型 | 默认值 | 下界(0.4×) | 上界(2.5×) | 预期性能变化 |
|------|--------|-----------|----------|-------------|
| DenseNet121 | 0.05 | 0.02 | 0.125 | **约-3% ~ -2%** |
| ResNet20 | 0.1 | 0.04 | 0.25 | **<-0.7%** |
| MRT-OAST | 0.0001 | 0.00004 | 0.00025 | **未知** |

**推理依据**:
- DenseNet: 0.4×介于0.25×(-4%)和1×(0%)之间，约-3%
- DenseNet: 2.5×介于1×(0%)和4×(崩溃)之间，需验证
- ResNet: 鲁棒性强，应该都可接受

**优点**:
- ✅ 探索范围更广（6.25×变化范围）
- ✅ 预期性能影响仍<5%

**缺点**:
- ⚠️ DenseNet的2.5×上界未经验证（有风险）

#### 方案3: 激进方案 [0.25×, 3×]

| 模型 | 默认值 | 下界(0.25×) | 上界(3×) | 预期性能变化 |
|------|--------|------------|---------|-------------|
| DenseNet121 | 0.05 | 0.0125 | 0.15 | **-4% ~ ?%** |
| ResNet20 | 0.1 | 0.025 | 0.3 | **<-1%** |

**风险评估**:
- ❌ DenseNet下界已知-4%（临界）
- ❌ DenseNet上界3×未验证（可能崩溃）

**结论**: ❌ 不推荐（风险过高）

---

### 3.2 Dropout 范围分析

**问题**: Dropout不适合用倍数表达

**原因**:
```
假设默认值 d = 0.5, 倍数范围 [0.5×, 2×]
- 下界: 0.5 × 0.5 = 0.25  ✅ 合理
- 上界: 0.5 × 2.0 = 1.0   ❌ 无意义（dropout>1无定义）

假设默认值 d = 0.1, 倍数范围 [0.5×, 2×]
- 下界: 0.1 × 0.5 = 0.05  ✅ 合理
- 上界: 0.1 × 2.0 = 0.2   ✅ 合理

假设默认值 d = 0.0 (无dropout), 倍数范围 [0.5×, 2×]
- 下界: 0.0 × 0.5 = 0.0   ❌ 无变化
- 上界: 0.0 × 2.0 = 0.0   ❌ 无变化
```

**结论**: ❌ Dropout必须用绝对值范围，不能用倍数

#### 方案1: 绝对值范围 [0.0, 0.6]

| 模型 | 默认值 | 下界 | 上界 | 已知数据 |
|------|--------|------|------|---------|
| DenseNet121 | 0.5 | 0.0 | 0.6 | 0.0→+2.4% ✅ |
| MRT-OAST | 0.2 | 0.0 | 0.6 | 0.0→未知 |
| ResNet20 | 无 | N/A | N/A | - |

**推理依据**:
- DenseNet: 0.0表现最好(+2.4%)，0.4和0.5相近
- 0.6略高于默认值，应该安全
- 测试数据显示dropout降低反而性能提升

**优点**:
- ✅ 简单明确
- ✅ 基于实测数据

**缺点**:
- ⚠️ 上界0.6未经测试

#### 方案2: 偏移量范围 [d-0.3, d+0.2]

| 模型 | 默认值(d) | 下界(d-0.3) | 上界(d+0.2) |
|------|----------|------------|-----------|
| DenseNet121 | 0.5 | 0.2 | 0.7 |
| MRT-OAST | 0.2 | 0.0* | 0.4 |
| ResNet20 | 0.0 | 0.0* | 0.2 |

*注: 下界不能<0，自动clip到0

**优点**:
- ✅ 适应不同默认值
- ✅ 符合"固定表达式"要求

**缺点**:
- ⚠️ 需要特殊处理边界（clip到[0,1]）
- ⚠️ 对d=0的模型无法测试下界

---

## 4. 推荐方案

### 4.1 Learning Rate: [0.5×, 2×] ⭐ 推荐

**公式**:
```
LR_lower = 0.5 × LR_default
LR_upper = 2.0 × LR_default
```

**适用性验证**:

| 模型 | 默认LR | 变异范围 | 预期性能影响 | 验证状态 |
|------|--------|---------|-------------|---------|
| DenseNet121 | 0.05 | [0.025, 0.1] | **-2% ~ -1%** | 📊 需验证 |
| ResNet20 | 0.1 | [0.05, 0.2] | **<-0.5%** | 📊 需验证 |
| MRT-OAST | 0.0001 | [0.00005, 0.0002] | **未知** | 📊 需验证 |

**理由**:
1. ✅ **安全性**: 避免DenseNet的4×崩溃风险
2. ✅ **有效性**: 仍有4×探索范围（2/0.5=4）
3. ✅ **统一性**: 简单的倍数公式，适用所有模型
4. ✅ **可预测性**: 基于已有数据内插，风险可控

**验证需求**:
- 🔬 需要补充测试DenseNet的0.5×和2×数据点
- 🔬 需要提取MRT-OAST数据验证

### 4.2 Dropout: 两种方案

#### 方案A: 绝对值范围 [0.0, 0.6] ⭐ 最简单

**公式**:
```python
# 忽略默认值，统一使用绝对范围
dropout_values = [0.0, 0.2, 0.4, 0.6]
```

**优点**:
- ✅ 最简单实现
- ✅ 基于DenseNet实测数据
- ✅ 对所有模型统一

**缺点**:
- ❌ 不符合"固定表达式"要求（未使用默认值d）
- ⚠️ 对默认值=0的模型会引入dropout（可能改变模型特性）

#### 方案B: 偏移量 [max(0, d-0.3), min(1, d+0.2)] ⭐ 符合要求

**公式**:
```python
dropout_lower = max(0.0, dropout_default - 0.3)
dropout_upper = min(1.0, dropout_default + 0.2)
```

**示例**:

| 模型 | 默认值(d) | 下界 | 上界 | 测试点建议 |
|------|----------|------|------|-----------|
| DenseNet121 | 0.5 | 0.2 | 0.7 | [0.2, 0.35, 0.5, 0.65] |
| MRT-OAST | 0.2 | 0.0 | 0.4 | [0.0, 0.1, 0.2, 0.3] |
| ResNet20 | 0.0 | 0.0 | 0.2 | [0.0, 0.05, 0.1, 0.15] |

**优点**:
- ✅ 符合"固定表达式"要求
- ✅ 适应不同默认值
- ✅ DenseNet的[0.2, 0.7]覆盖已测试的[0.0, 0.5]

**缺点**:
- ⚠️ 对d=0的模型，下界无变化（但上界仍可测试）
- ⚠️ 需要补充测试上界数据

---

## 5. 最终推荐配置

### 5.1 推荐方案（平衡型）

```json
{
  "mutation_strategy": {
    "learning_rate": {
      "type": "multiplier",
      "formula": "[0.5 × default, 2.0 × default]",
      "test_points": [0.5, 0.75, 1.0, 1.5, 2.0]
    },
    "dropout": {
      "type": "offset",
      "formula": "[max(0, default-0.3), min(1, default+0.2)]",
      "test_points": [
        "max(0, d-0.3)",
        "max(0, d-0.15)",
        "d",
        "min(1, d+0.1)",
        "min(1, d+0.2)"
      ]
    }
  }
}
```

**预期性能影响**: <3% 对所有模型

### 5.2 保守方案（最安全）

如果MRT-OAST对LR敏感，可进一步缩小范围：

```json
{
  "learning_rate": {
    "formula": "[0.6 × default, 1.5 × default]",
    "test_points": [0.6, 0.8, 1.0, 1.2, 1.5]
  },
  "dropout": {
    "formula": "[max(0, default-0.2), min(1, default+0.15)]"
  }
}
```

**预期性能影响**: <2% 对所有模型

---

## 6. 验证测试计划

### 6.1 需要补充的测试

#### 高优先级（验证推荐方案）:

| 模型 | 超参数 | 需要测试的值 | 原因 |
|------|--------|------------|------|
| DenseNet121 | LR | 0.025 (0.5×), 0.1 (2×) | 验证推荐范围边界 |
| DenseNet121 | Dropout | 0.6, 0.7 | 验证上界 |
| MRT-OAST | 全部 | 提取已有数据 | 验证适用性 |

#### 中优先级（细化曲线）:

| 模型 | 超参数 | 需要测试的值 | 原因 |
|------|--------|------------|------|
| DenseNet121 | LR | 0.0375 (0.75×), 0.075 (1.5×) | 细化性能曲线 |
| DenseNet121 | Dropout | 0.2, 0.35 | 填补空白区间 |

### 6.2 最小验证集（快速验证）

只需3个额外实验即可验证推荐方案：

```json
[
  {
    "model": "DenseNet121",
    "lr": 0.025,
    "dropout": 0.5,
    "note": "验证LR下界0.5×"
  },
  {
    "model": "DenseNet121",
    "lr": 0.1,
    "dropout": 0.5,
    "note": "验证LR上界2×"
  },
  {
    "model": "DenseNet121",
    "lr": 0.05,
    "dropout": 0.7,
    "note": "验证Dropout上界"
  }
]
```

**预计时间**: 3 × 36分钟 = 108分钟 (1.8小时)

---

## 7. 实现建议

### 7.1 配置文件格式更新

**当前格式** (需要修改):
```json
{
  "experiments": [
    {
      "hyperparameters": {
        "learning_rate": 0.025
      }
    }
  ]
}
```

**建议格式** (支持公式):
```json
{
  "mutation_config": {
    "learning_rate": {
      "type": "multiplier",
      "multipliers": [0.5, 0.75, 1.0, 1.5, 2.0]
    },
    "dropout": {
      "type": "offset",
      "offsets": [-0.3, -0.15, 0.0, 0.1, 0.2],
      "clip": [0.0, 1.0]
    }
  },
  "models": [
    {
      "repo": "Person_reID_baseline_pytorch",
      "model": "densenet121",
      "default_hyperparameters": {
        "learning_rate": 0.05,
        "dropout": 0.5
      }
    }
  ]
}
```

**代码实现**:
```python
def generate_mutation_values(param_type, default_value, config):
    if config["type"] == "multiplier":
        return [default_value * m for m in config["multipliers"]]
    elif config["type"] == "offset":
        values = [default_value + offset for offset in config["offsets"]]
        if "clip" in config:
            values = [np.clip(v, *config["clip"]) for v in values]
        return values
```

---

## 8. 总结

### 8.1 核心结论

🎯 **推荐的统一变异范围**:

```
Learning Rate: [0.5×default, 2.0×default]
Dropout: [max(0, default-0.3), min(1, default+0.2)]
```

### 8.2 关键发现

1. ✅ **LR下界0.5×安全**: 相比0.25×(-4%)，0.5×预计仅-2%
2. ✅ **LR上界2×安全**: 避免4×的崩溃风险
3. ⚠️ **Dropout不能用倍数**: 必须用偏移量或绝对值
4. 📊 **需要验证**: 3个补充实验即可确认推荐方案

### 8.3 性能预期

| 模型 | LR范围 | Dropout范围 | 预期最大性能下降 |
|------|--------|------------|---------------|
| DenseNet121 | [0.025, 0.1] | [0.2, 0.7] | **<3%** |
| ResNet20 | [0.05, 0.2] | N/A | **<1%** |
| MRT-OAST | [0.00005, 0.0002] | [0.0, 0.4] | **待确认** |

### 8.4 下一步行动

**立即**:
1. 提取MRT-OAST数据，验证LR敏感度
2. 如果MRT-OAST可接受，执行3个验证实验

**短期**:
3. 根据验证结果确认或微调范围
4. 更新mutation配置文件格式
5. 实现公式化的变异值生成

---

**报告版本**: 1.0
**分析基础**: boundary_test_v2 实验数据
**置信度**: 高（基于实测数据内插）
**风险**: 低（保守估计，需3个实验验证）

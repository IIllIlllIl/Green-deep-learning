# raw_data.csv æ•°æ®ä½¿ç”¨æŒ‡å—

**æ–‡æ¡£ç‰ˆæœ¬**: 1.0
**æœ€åæ›´æ–°**: 2026-01-10
**æ•°æ®æ–‡ä»¶**: `data/raw_data.csv`
**å½“å‰è§„æ¨¡**: 970è¡Œå®éªŒæ•°æ®ï¼Œ87åˆ—å­—æ®µ

---

## ğŸ“‹ ç›®å½•

1. [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
2. [æ•°æ®ç»“æ„æ¦‚è¿°](#æ•°æ®ç»“æ„æ¦‚è¿°)
3. [å¹¶è¡Œvséå¹¶è¡Œæ¨¡å¼](#å¹¶è¡Œvséå¹¶è¡Œæ¨¡å¼)
4. [å­—æ®µè¯¦ç»†è¯´æ˜](#å­—æ®µè¯¦ç»†è¯´æ˜)
5. [å¸¸è§é”™è¯¯å’Œè§£å†³æ–¹æ¡ˆ](#å¸¸è§é”™è¯¯å’Œè§£å†³æ–¹æ¡ˆ)
6. [ä»£ç ç¤ºä¾‹](#ä»£ç ç¤ºä¾‹)
7. [æ¨¡å‹åˆ—è¡¨](#æ¨¡å‹åˆ—è¡¨)

---

## å¿«é€Ÿå¼€å§‹

### âš ï¸ å¿…è¯»è¦ç‚¹

1. **å¹¶è¡Œæ¨¡å¼æ•°æ®åœ¨ `fg_` å‰ç¼€å­—æ®µä¸­** - ä¸è¦è¯»å–é¡¶å±‚å­—æ®µï¼
2. **ç©ºå­—ç¬¦ä¸²è¡¨ç¤ºé»˜è®¤å€¼æˆ–ä¸é€‚ç”¨** - ä¸æ˜¯æ•°æ®ç¼ºå¤±ï¼
3. **modeå­—æ®µåŒºåˆ†å¹¶è¡Œ/éå¹¶è¡Œ** - å¿…é¡»å…ˆæ£€æŸ¥æ­¤å­—æ®µï¼
4. **æ¨¡å‹åç§°æ˜¯å›ºå®šçš„** - å‚è€ƒ[æ¨¡å‹åˆ—è¡¨](#æ¨¡å‹åˆ—è¡¨)

### åŸºæœ¬è¯»å–ä»£ç æ¨¡æ¿

```python
import pandas as pd

# è¯»å–æ•°æ®
df = pd.read_csv('data/raw_data.csv')

# åˆ›å»ºç»Ÿä¸€çš„è®¿é—®å‡½æ•°
def get_field(row, field_name):
    """
    æ™ºèƒ½è·å–å­—æ®µå€¼ï¼Œè‡ªåŠ¨å¤„ç†å¹¶è¡Œ/éå¹¶è¡Œæ¨¡å¼

    Args:
        row: DataFrameè¡Œ
        field_name: å­—æ®µåï¼ˆä¸å¸¦fg_å‰ç¼€ï¼‰

    Returns:
        å­—æ®µå€¼ï¼ˆå­—ç¬¦ä¸²æˆ–æ•°å€¼ï¼‰
    """
    is_parallel = (row['mode'] == 'parallel')

    if is_parallel:
        # å¹¶è¡Œæ¨¡å¼ï¼šä¼˜å…ˆä½¿ç”¨fg_å­—æ®µ
        fg_value = row.get(f'fg_{field_name}', '')
        if pd.notna(fg_value) and str(fg_value).strip():
            return fg_value

    # éå¹¶è¡Œæ¨¡å¼æˆ–fg_å­—æ®µä¸ºç©ºæ—¶ä½¿ç”¨é¡¶å±‚å­—æ®µ
    return row.get(field_name, '')

# ä½¿ç”¨ç¤ºä¾‹
for idx, row in df.iterrows():
    repo = get_field(row, 'repository')
    model = get_field(row, 'model')
    learning_rate = get_field(row, 'hyperparam_learning_rate')
    print(f"{repo}/{model}, lr={learning_rate}")
```

---

## æ•°æ®ç»“æ„æ¦‚è¿°

### æ€»ä½“ç»“æ„

```
raw_data.csv (970è¡Œ Ã— 87åˆ—)
â”‚
â”œâ”€â”€ åŸºç¡€å­—æ®µ (1-7åˆ—)
â”‚   â”œâ”€â”€ experiment_id
â”‚   â”œâ”€â”€ timestamp
â”‚   â”œâ”€â”€ repository          # âš ï¸ å¹¶è¡Œæ¨¡å¼ä¸‹ä¸ºç©º
â”‚   â”œâ”€â”€ model               # âš ï¸ å¹¶è¡Œæ¨¡å¼ä¸‹ä¸ºç©º
â”‚   â”œâ”€â”€ training_success    # âš ï¸ å¹¶è¡Œæ¨¡å¼ä¸‹ä¸ºç©º
â”‚   â”œâ”€â”€ duration_seconds    # âš ï¸ å¹¶è¡Œæ¨¡å¼ä¸‹ä¸ºç©º
â”‚   â””â”€â”€ retries             # âš ï¸ å¹¶è¡Œæ¨¡å¼ä¸‹ä¸ºç©º
â”‚
â”œâ”€â”€ è¶…å‚æ•°å­—æ®µ (8-16åˆ—)
â”‚   â”œâ”€â”€ hyperparam_alpha
â”‚   â”œâ”€â”€ hyperparam_batch_size
â”‚   â”œâ”€â”€ hyperparam_dropout
â”‚   â”œâ”€â”€ hyperparam_epochs
â”‚   â”œâ”€â”€ hyperparam_kfold
â”‚   â”œâ”€â”€ hyperparam_learning_rate
â”‚   â”œâ”€â”€ hyperparam_max_iter
â”‚   â”œâ”€â”€ hyperparam_seed
â”‚   â””â”€â”€ hyperparam_weight_decay
â”‚
â”œâ”€â”€ æ€§èƒ½æŒ‡æ ‡å­—æ®µ (17-32åˆ—)
â”‚   â”œâ”€â”€ perf_accuracy
â”‚   â”œâ”€â”€ perf_best_val_accuracy
â”‚   â”œâ”€â”€ perf_map
â”‚   â”œâ”€â”€ perf_precision
â”‚   â”œâ”€â”€ perf_rank1
â”‚   â”œâ”€â”€ perf_rank5
â”‚   â”œâ”€â”€ perf_recall
â”‚   â”œâ”€â”€ perf_test_accuracy
â”‚   â”œâ”€â”€ perf_test_loss
â”‚   â”œâ”€â”€ perf_eval_loss
â”‚   â”œâ”€â”€ perf_final_training_loss
â”‚   â”œâ”€â”€ perf_eval_samples_per_second
â”‚   â”œâ”€â”€ perf_top1_accuracy
â”‚   â”œâ”€â”€ perf_top5_accuracy
â”‚   â”œâ”€â”€ perf_top10_accuracy
â”‚   â””â”€â”€ perf_top20_accuracy
â”‚
â”œâ”€â”€ èƒ½è€—å­—æ®µ (33-43åˆ—)
â”‚   â”œâ”€â”€ energy_cpu_pkg_joules
â”‚   â”œâ”€â”€ energy_cpu_ram_joules
â”‚   â”œâ”€â”€ energy_cpu_total_joules
â”‚   â”œâ”€â”€ energy_gpu_avg_watts
â”‚   â”œâ”€â”€ energy_gpu_max_watts
â”‚   â”œâ”€â”€ energy_gpu_min_watts
â”‚   â”œâ”€â”€ energy_gpu_total_joules
â”‚   â”œâ”€â”€ energy_gpu_temp_avg_celsius
â”‚   â”œâ”€â”€ energy_gpu_temp_max_celsius
â”‚   â”œâ”€â”€ energy_gpu_util_avg_percent
â”‚   â””â”€â”€ energy_gpu_util_max_percent
â”‚
â”œâ”€â”€ å…ƒæ•°æ®å­—æ®µ (44-48åˆ—)
â”‚   â”œâ”€â”€ experiment_source   # å®éªŒæ¥æºæ ‡ç­¾
â”‚   â”œâ”€â”€ num_mutated_params  # å˜å¼‚å‚æ•°æ•°é‡
â”‚   â”œâ”€â”€ mutated_param       # å˜å¼‚çš„å‚æ•°å
â”‚   â”œâ”€â”€ mode                # âš ï¸ å…³é”®: "parallel" æˆ– ç©ºå­—ç¬¦ä¸²
â”‚   â””â”€â”€ error_message
â”‚
â”œâ”€â”€ å‰å°ï¼ˆForegroundï¼‰å­—æ®µ (49-83åˆ—) - ä»…å¹¶è¡Œæ¨¡å¼
â”‚   â”œâ”€â”€ fg_repository       # âš ï¸ å¹¶è¡Œæ¨¡å¼ä¸»è¦æ•°æ®åœ¨è¿™é‡Œ
â”‚   â”œâ”€â”€ fg_model
â”‚   â”œâ”€â”€ fg_duration_seconds
â”‚   â”œâ”€â”€ fg_training_success
â”‚   â”œâ”€â”€ fg_retries
â”‚   â”œâ”€â”€ fg_error_message
â”‚   â”œâ”€â”€ fg_hyperparam_*     # å‰å°è®­ç»ƒçš„è¶…å‚æ•°
â”‚   â”œâ”€â”€ fg_perf_*           # å‰å°è®­ç»ƒçš„æ€§èƒ½æŒ‡æ ‡
â”‚   â””â”€â”€ fg_energy_*         # å‰å°è®­ç»ƒçš„èƒ½è€—æ•°æ®
â”‚
â””â”€â”€ åå°ï¼ˆBackgroundï¼‰å­—æ®µ (84-87åˆ—) - ä»…å¹¶è¡Œæ¨¡å¼
    â”œâ”€â”€ bg_repository       # åå°å¹²æ‰°ä»»åŠ¡çš„ä»“åº“
    â”œâ”€â”€ bg_model            # åå°å¹²æ‰°ä»»åŠ¡çš„æ¨¡å‹
    â”œâ”€â”€ bg_note
    â””â”€â”€ bg_log_directory
```

### æ•°æ®åˆ†å¸ƒç»Ÿè®¡

- **æ€»å®éªŒæ•°**: 970
- **éå¹¶è¡Œæ¨¡å¼**: 436 (44.9%)
- **å¹¶è¡Œæ¨¡å¼**: 534 (55.1%)
- **èƒ½è€—å®Œæ•´æ€§**: 828/970 (85.4%)

---

## å¹¶è¡Œvséå¹¶è¡Œæ¨¡å¼

### æ ¸å¿ƒåŒºåˆ«

| ç‰¹å¾ | éå¹¶è¡Œæ¨¡å¼ | å¹¶è¡Œæ¨¡å¼ |
|------|-----------|---------|
| **modeå­—æ®µ** | ç©ºå­—ç¬¦ä¸² `""` | `"parallel"` |
| **æ•°æ®ä½ç½®** | é¡¶å±‚å­—æ®µ | `fg_` å‰ç¼€å­—æ®µ |
| **repository** | âœ… æœ‰å€¼ | âŒ ç©º (åœ¨fg_repository) |
| **model** | âœ… æœ‰å€¼ | âŒ ç©º (åœ¨fg_model) |
| **è¶…å‚æ•°** | `hyperparam_*` | `fg_hyperparam_*` |
| **æ€§èƒ½æŒ‡æ ‡** | `perf_*` | `fg_perf_*` |
| **èƒ½è€—æ•°æ®** | `energy_*` | `fg_energy_*` |
| **åå°ä»»åŠ¡** | æ—  | `bg_repository`, `bg_model` |

### å®é™…æ•°æ®ç¤ºä¾‹

#### éå¹¶è¡Œæ¨¡å¼ç¤ºä¾‹

```csv
experiment_id: default__MRT-OAST_default_001
mode: ""
repository: MRT-OAST          # âœ… é¡¶å±‚æœ‰å€¼
model: default                # âœ… é¡¶å±‚æœ‰å€¼
training_success: True
hyperparam_epochs: 10         # âœ… é¡¶å±‚æœ‰å€¼
perf_precision: 0.9834
energy_cpu_total_joules: 39987.66

fg_repository: ""             # âŒ fg_å­—æ®µä¸ºç©º
fg_model: ""
fg_hyperparam_epochs: ""
```

#### å¹¶è¡Œæ¨¡å¼ç¤ºä¾‹

```csv
experiment_id: default__pytorch_resnet_cifar10_resnet20_012_parallel
mode: "parallel"              # âš ï¸ å…³é”®æ ‡è¯†
repository: ""                # âŒ é¡¶å±‚ä¸ºç©º
model: ""                     # âŒ é¡¶å±‚ä¸ºç©º
training_success: ""
hyperparam_epochs: ""

fg_repository: pytorch_resnet_cifar10  # âœ… å‰å°æ•°æ®åœ¨fg_å­—æ®µ
fg_model: resnet20
fg_training_success: True
fg_hyperparam_epochs: 200
fg_perf_test_accuracy: 92.17
fg_energy_cpu_total_joules: 46525.57

bg_repository: examples       # åå°å¹²æ‰°ä»»åŠ¡
bg_model: mnist_ff
```

### ğŸš¨ å¸¸è§é”™è¯¯ç¤ºä¾‹

#### âŒ é”™è¯¯åšæ³•1ï¼šä¸æ£€æŸ¥modeå­—æ®µ

```python
# âŒ é”™è¯¯ï¼šç›´æ¥è¯»å–é¡¶å±‚å­—æ®µ
repo = df['repository']  # å¹¶è¡Œæ¨¡å¼ä¸‹å…¨æ˜¯ç©ºå€¼ï¼
```

#### âŒ é”™è¯¯åšæ³•2ï¼šåªè¯»å–é¡¶å±‚æˆ–åªè¯»å–fg_å­—æ®µ

```python
# âŒ é”™è¯¯ï¼šåªè¯»fg_å­—æ®µ
repo = df['fg_repository']  # éå¹¶è¡Œæ¨¡å¼ä¸‹å…¨æ˜¯ç©ºå€¼ï¼
```

#### âœ… æ­£ç¡®åšæ³•ï¼šæ ¹æ®modeå­—æ®µé€‰æ‹©

```python
# âœ… æ­£ç¡®
def get_repository(row):
    if row['mode'] == 'parallel':
        return row['fg_repository']
    else:
        return row['repository']

df['repo'] = df.apply(get_repository, axis=1)
```

---

## å­—æ®µè¯¦ç»†è¯´æ˜

### åŸºç¡€å­—æ®µ

| å­—æ®µå | ç±»å‹ | è¯´æ˜ | ç©ºå€¼å«ä¹‰ |
|--------|------|------|---------|
| `experiment_id` | string | å®éªŒå”¯ä¸€æ ‡è¯†ç¬¦ | ä¸åº”ä¸ºç©º |
| `timestamp` | string | ISO 8601æ ¼å¼æ—¶é—´æˆ³ | ä¸åº”ä¸ºç©º |
| `repository` | string | ä»“åº“åç§° | **å¹¶è¡Œæ¨¡å¼ä¸‹ä¸ºç©º** |
| `model` | string | æ¨¡å‹åç§° | **å¹¶è¡Œæ¨¡å¼ä¸‹ä¸ºç©º** |
| `training_success` | boolean | è®­ç»ƒæ˜¯å¦æˆåŠŸ | **å¹¶è¡Œæ¨¡å¼ä¸‹ä¸ºç©º** |
| `duration_seconds` | float | è®­ç»ƒæ—¶é•¿ï¼ˆç§’ï¼‰ | **å¹¶è¡Œæ¨¡å¼ä¸‹ä¸ºç©º** |
| `retries` | int | é‡è¯•æ¬¡æ•° | 0æˆ–ç©º |

### è¶…å‚æ•°å­—æ®µ

| å­—æ®µå | ç±»å‹ | é€‚ç”¨æ¨¡å‹ | ç©ºå€¼å«ä¹‰ |
|--------|------|---------|---------|
| `hyperparam_alpha` | float | bug-localization | è¯¥æ¨¡å‹ä¸ä½¿ç”¨æ­¤å‚æ•° |
| `hyperparam_batch_size` | int | å¤§å¤šæ•°æ¨¡å‹ | ä½¿ç”¨é»˜è®¤å€¼ |
| `hyperparam_dropout` | float | Person_reID, VulBERTa, MRT-OAST | è¯¥æ¨¡å‹ä¸ä½¿ç”¨dropout |
| `hyperparam_epochs` | int | æ‰€æœ‰æ¨¡å‹ | ä½¿ç”¨é»˜è®¤å€¼ |
| `hyperparam_kfold` | int | bug-localization | è¯¥æ¨¡å‹ä¸ä½¿ç”¨k-fold |
| `hyperparam_learning_rate` | float | æ‰€æœ‰æ¨¡å‹ | ä½¿ç”¨é»˜è®¤å€¼ |
| `hyperparam_max_iter` | int | bug-localization | è¯¥æ¨¡å‹ä¸ä½¿ç”¨æ­¤å‚æ•° |
| `hyperparam_seed` | int | å¤§å¤šæ•°æ¨¡å‹ | æœªè®¾ç½®æˆ–ä½¿ç”¨é»˜è®¤ |
| `hyperparam_weight_decay` | float | Person_reID, ResNet, MRT-OAST | è¯¥æ¨¡å‹ä¸ä½¿ç”¨ |

**âš ï¸ é‡è¦**ï¼šç©ºå€¼ä¸ä»£è¡¨æ•°æ®ç¼ºå¤±ï¼Œè€Œæ˜¯ï¼š
1. è¯¥æ¨¡å‹ä¸ä½¿ç”¨æ­¤è¶…å‚æ•°
2. ä½¿ç”¨æ¨¡å‹çš„é»˜è®¤å€¼
3. è¯¥å‚æ•°åœ¨æœ¬æ¬¡å®éªŒä¸­æœªè¢«å˜å¼‚

### æ€§èƒ½æŒ‡æ ‡å­—æ®µ

ä¸åŒæ¨¡å‹ä½¿ç”¨ä¸åŒçš„æ€§èƒ½æŒ‡æ ‡ï¼š

| æ¨¡å‹ | ä¸»è¦æ€§èƒ½æŒ‡æ ‡ |
|------|------------|
| Person_reID (densenet121, hrnet18, pcb) | `perf_rank1`, `perf_rank5`, `perf_map` |
| ResNet (pytorch_resnet_cifar10) | `perf_test_accuracy`, `perf_best_val_accuracy` |
| VulBERTa | `perf_precision`, `perf_recall`, `perf_f1` |
| Examples (mnist, mnist_rnn, siamese) | `perf_test_accuracy` |
| MRT-OAST | `perf_precision` |
| bug-localization | æ— æ ‡å‡†åŒ–æŒ‡æ ‡ |

**ç©ºå€¼å«ä¹‰**ï¼šè¯¥æ¨¡å‹ä¸ä½¿ç”¨æ­¤æŒ‡æ ‡

### èƒ½è€—å­—æ®µ

| å­—æ®µå | ç±»å‹ | å•ä½ | è¯´æ˜ |
|--------|------|------|------|
| `energy_cpu_pkg_joules` | float | ç„¦è€³ | CPU Packageèƒ½è€— |
| `energy_cpu_ram_joules` | float | ç„¦è€³ | RAMèƒ½è€— |
| `energy_cpu_total_joules` | float | ç„¦è€³ | CPUæ€»èƒ½è€— (pkg + ram) |
| `energy_gpu_avg_watts` | float | ç“¦ç‰¹ | GPUå¹³å‡åŠŸç‡ |
| `energy_gpu_max_watts` | float | ç“¦ç‰¹ | GPUå³°å€¼åŠŸç‡ |
| `energy_gpu_min_watts` | float | ç“¦ç‰¹ | GPUæœ€å°åŠŸç‡ |
| `energy_gpu_total_joules` | float | ç„¦è€³ | GPUæ€»èƒ½è€— |
| `energy_gpu_temp_avg_celsius` | float | æ‘„æ°åº¦ | GPUå¹³å‡æ¸©åº¦ |
| `energy_gpu_temp_max_celsius` | float | æ‘„æ°åº¦ | GPUå³°å€¼æ¸©åº¦ |
| `energy_gpu_util_avg_percent` | float | % | GPUå¹³å‡åˆ©ç”¨ç‡ |
| `energy_gpu_util_max_percent` | float | % | GPUå³°å€¼åˆ©ç”¨ç‡ |

**ç©ºå€¼å«ä¹‰**ï¼šèƒ½è€—ç›‘æ§å¤±è´¥ï¼ˆæƒé™é—®é¢˜æˆ–nvidia-smiä¸å¯ç”¨ï¼‰

### å…ƒæ•°æ®å­—æ®µ

| å­—æ®µå | ç±»å‹ | è¯´æ˜ | ç©ºå€¼å«ä¹‰ |
|--------|------|------|---------|
| `experiment_source` | string | å®éªŒæ¥æºæ ‡ç­¾ | æ—§æ•°æ®æœªæ ‡è®° |
| `num_mutated_params` | int | å˜å¼‚å‚æ•°æ•°é‡ | æ—§æ•°æ®æœªè®°å½• |
| `mutated_param` | string | å˜å¼‚çš„å‚æ•°å | æ—§æ•°æ®æœªè®°å½• |
| `mode` | string | **å…³é”®**: "parallel"æˆ–ç©º | ç©º=éå¹¶è¡Œ |
| `error_message` | string | é”™è¯¯æˆ–æˆåŠŸä¿¡æ¯ | æ—  |

---

## å¸¸è§é”™è¯¯å’Œè§£å†³æ–¹æ¡ˆ

### é”™è¯¯1: ä¸çŸ¥é“å¹¶è¡Œæ¨¡å¼æ•°æ®åœ¨fg_å­—æ®µ

#### âŒ é”™è¯¯ä»£ç 
```python
# è¯»å–repositoryå­—æ®µï¼Œä½†å¹¶è¡Œæ¨¡å¼ä¸‹repositoryä¸ºç©º
df = pd.read_csv('data/raw_data.csv')
df_resnet = df[df['repository'] == 'pytorch_resnet_cifar10']
# ç»“æœï¼šé—æ¼äº†æ‰€æœ‰å¹¶è¡Œæ¨¡å¼çš„resnetå®éªŒï¼
```

#### âœ… æ­£ç¡®ä»£ç 
```python
def get_unified_field(df, field_name):
    """åˆ›å»ºç»Ÿä¸€å­—æ®µï¼Œè‡ªåŠ¨åˆå¹¶é¡¶å±‚å’Œfg_å­—æ®µ"""
    result = df[field_name].copy()
    is_parallel = (df['mode'] == 'parallel')
    fg_field = f'fg_{field_name}'

    if fg_field in df.columns:
        # å¹¶è¡Œæ¨¡å¼ä½¿ç”¨fg_å­—æ®µ
        result[is_parallel] = df.loc[is_parallel, fg_field]

    return result

df['repo'] = get_unified_field(df, 'repository')
df['model_name'] = get_unified_field(df, 'model')
df_resnet = df[df['repo'] == 'pytorch_resnet_cifar10']
# ç»“æœï¼šåŒ…å«æ‰€æœ‰resnetå®éªŒï¼ˆå¹¶è¡Œ+éå¹¶è¡Œï¼‰
```

### é”™è¯¯2: æŠŠç©ºå€¼å½“ä½œç¼ºå¤±æ•°æ®

#### âŒ é”™è¯¯ç†è§£
```python
# é”™è¯¯ï¼šè®¤ä¸ºç©ºçš„hyperparam_dropoutæ˜¯æ•°æ®ç¼ºå¤±
df['dropout'].fillna(0.5)  # âŒ ç ´åäº†åŸå§‹è¯­ä¹‰
```

#### âœ… æ­£ç¡®ç†è§£
```python
# æ­£ç¡®ï¼šç©ºå€¼æœ‰ä¸‰ç§å«ä¹‰
# 1. è¯¥æ¨¡å‹ä¸ä½¿ç”¨æ­¤å‚æ•°ï¼ˆå¦‚mnistä¸ä½¿ç”¨dropoutï¼‰
# 2. ä½¿ç”¨é»˜è®¤å€¼
# 3. æ­¤å‚æ•°æœªè¢«å˜å¼‚

# å¦‚æœéœ€è¦å¡«å……ï¼Œåº”è¯¥æŸ¥é˜…models_config.jsonä¸­çš„é»˜è®¤å€¼
import json
with open('mutation/models_config.json') as f:
    config = json.load(f)

# ä¸ºç‰¹å®šæ¨¡å‹è·å–é»˜è®¤dropout
default_dropout = config['models']['VulBERTa']['hyperparameters']['dropout']['default']
```

### é”™è¯¯3: ä¸çŸ¥é“æ¨¡å‹åç§°çš„å‡†ç¡®æ‹¼å†™

#### âŒ é”™è¯¯ä»£ç 
```python
# é”™è¯¯ï¼šæ¨¡å‹åç§°æ‹¼å†™é”™è¯¯
df[df['model'] == 'resnet']  # âŒ åº”è¯¥æ˜¯ 'resnet20'
df[df['model'] == 'densenet']  # âŒ åº”è¯¥æ˜¯ 'densenet121'
df[df['repository'] == 'Person_reID']  # âŒ åº”è¯¥æ˜¯ 'Person_reID_baseline_pytorch'
```

#### âœ… æ­£ç¡®ä»£ç 
```python
# ä½¿ç”¨å‡†ç¡®çš„æ¨¡å‹åç§°ï¼ˆå‚è€ƒæœ¬æ–‡æ¡£æœ«å°¾çš„æ¨¡å‹åˆ—è¡¨ï¼‰
df_resnet = df[df['model_name'] == 'resnet20']
df_densenet = df[df['model_name'] == 'densenet121']
df_person_reid = df[df['repo'] == 'Person_reID_baseline_pytorch']
```

### é”™è¯¯4: ç›´æ¥è¿‡æ»¤æ•°æ®å¯¼è‡´é—æ¼

#### âŒ é”™è¯¯ä»£ç 
```python
# åªç­›é€‰äº†é¡¶å±‚å­—æ®µï¼Œé—æ¼äº†å¹¶è¡Œæ¨¡å¼
df_successful = df[df['training_success'] == True]
# é—æ¼äº†æ‰€æœ‰å¹¶è¡Œæ¨¡å¼çš„æˆåŠŸå®éªŒï¼
```

#### âœ… æ­£ç¡®ä»£ç 
```python
def get_training_success(df):
    """ç»Ÿä¸€è·å–è®­ç»ƒæˆåŠŸçŠ¶æ€"""
    success = df['training_success'].copy()
    is_parallel = (df['mode'] == 'parallel')
    success[is_parallel] = df.loc[is_parallel, 'fg_training_success']
    return success

df['success'] = get_training_success(df)
df_successful = df[df['success'] == 'True']  # æ³¨æ„ï¼šCSVä¸­æ˜¯å­—ç¬¦ä¸²
```

---

## ä»£ç ç¤ºä¾‹

### ç¤ºä¾‹1: è¯»å–å’Œé¢„å¤„ç†æ•°æ®

```python
import pandas as pd
import numpy as np

def load_and_preprocess_data(csv_path='data/raw_data.csv'):
    """
    åŠ è½½å¹¶é¢„å¤„ç†raw_data.csvï¼Œåˆ›å»ºç»Ÿä¸€çš„è®¿é—®æ¥å£

    Returns:
        DataFrame: é¢„å¤„ç†åçš„æ•°æ®ï¼Œæ·»åŠ äº†ç»Ÿä¸€å­—æ®µ
    """
    df = pd.read_csv(csv_path)

    # åˆ¤æ–­æ˜¯å¦ä¸ºå¹¶è¡Œæ¨¡å¼
    df['is_parallel'] = (df['mode'] == 'parallel')

    # åˆ›å»ºç»Ÿä¸€å­—æ®µçš„è¾…åŠ©å‡½æ•°
    def create_unified_field(field_name):
        result = df[field_name].copy()
        fg_field = f'fg_{field_name}'
        if fg_field in df.columns:
            mask = df['is_parallel']
            result[mask] = df.loc[mask, fg_field]
        return result

    # åŸºç¡€å­—æ®µ
    df['repo'] = create_unified_field('repository')
    df['model_name'] = create_unified_field('model')
    df['success'] = create_unified_field('training_success')
    df['duration'] = create_unified_field('duration_seconds')

    # è¶…å‚æ•°å­—æ®µ
    for param in ['alpha', 'batch_size', 'dropout', 'epochs', 'kfold',
                  'learning_rate', 'max_iter', 'seed', 'weight_decay']:
        df[f'hp_{param}'] = create_unified_field(f'hyperparam_{param}')

    # æ€§èƒ½æŒ‡æ ‡å­—æ®µ
    for metric in ['accuracy', 'best_val_accuracy', 'map', 'precision',
                   'rank1', 'rank5', 'recall', 'test_accuracy']:
        df[f'perf_{metric}'] = create_unified_field(f'perf_{metric}')

    # èƒ½è€—å­—æ®µ
    for energy in ['cpu_total_joules', 'gpu_total_joules', 'gpu_avg_watts']:
        df[f'energy_{energy}'] = create_unified_field(f'energy_{energy}')

    # æ•°æ®ç±»å‹è½¬æ¢
    df['success'] = df['success'].map({'True': True, 'true': True,
                                       'False': False, 'false': False})

    # æ•°å€¼åˆ—è½¬æ¢
    numeric_cols = ['duration', 'hp_epochs', 'hp_learning_rate',
                   'energy_cpu_total_joules', 'energy_gpu_total_joules']
    for col in numeric_cols:
        df[col] = pd.to_numeric(df[col], errors='coerce')

    return df

# ä½¿ç”¨ç¤ºä¾‹
df = load_and_preprocess_data()
print(f"æ€»å®éªŒæ•°: {len(df)}")
print(f"éå¹¶è¡Œ: {(~df['is_parallel']).sum()}")
print(f"å¹¶è¡Œ: {df['is_parallel'].sum()}")
```

### ç¤ºä¾‹2: æŒ‰æ¨¡å‹åˆ†ç»„åˆ†æ

```python
def analyze_by_model(df):
    """æŒ‰æ¨¡å‹ç»Ÿè®¡å®éªŒæ•°é‡å’ŒæˆåŠŸç‡"""
    results = []

    for repo_model in df.groupby(['repo', 'model_name']):
        repo, model = repo_model[0]
        data = repo_model[1]

        if not repo or not model:  # è·³è¿‡ç©ºå€¼
            continue

        total = len(data)
        parallel = data['is_parallel'].sum()
        nonparallel = total - parallel

        # æˆåŠŸç‡
        success_rate = (data['success'] == True).sum() / total * 100

        # èƒ½è€—å®Œæ•´æ€§
        has_energy = data['energy_cpu_total_joules'].notna().sum()
        energy_rate = has_energy / total * 100

        results.append({
            'repository': repo,
            'model': model,
            'total': total,
            'parallel': parallel,
            'nonparallel': nonparallel,
            'success_rate': f'{success_rate:.1f}%',
            'energy_coverage': f'{energy_rate:.1f}%'
        })

    return pd.DataFrame(results).sort_values('total', ascending=False)

# ä½¿ç”¨
summary = analyze_by_model(df)
print(summary.to_string(index=False))
```

### ç¤ºä¾‹3: æå–ç‰¹å®šæ¨¡å‹çš„æ•°æ®

```python
def get_model_data(df, repository, model, include_parallel=True):
    """
    æå–ç‰¹å®šæ¨¡å‹çš„å®éªŒæ•°æ®

    Args:
        df: é¢„å¤„ç†åçš„DataFrame
        repository: ä»“åº“åç§°
        model: æ¨¡å‹åç§°
        include_parallel: æ˜¯å¦åŒ…å«å¹¶è¡Œæ¨¡å¼å®éªŒ

    Returns:
        DataFrame: ç­›é€‰åçš„æ•°æ®
    """
    # åŸºç¡€ç­›é€‰
    mask = (df['repo'] == repository) & (df['model_name'] == model)

    # æ˜¯å¦åŒ…å«å¹¶è¡Œ
    if not include_parallel:
        mask = mask & (~df['is_parallel'])

    return df[mask].copy()

# ç¤ºä¾‹ï¼šè·å–resnet20çš„æ‰€æœ‰å®éªŒ
df_resnet = get_model_data(df, 'pytorch_resnet_cifar10', 'resnet20')
print(f"ResNet20å®éªŒæ•°: {len(df_resnet)}")

# ç¤ºä¾‹ï¼šåªè·å–éå¹¶è¡Œçš„Person_reIDå®éªŒ
df_person_reid = get_model_data(df, 'Person_reID_baseline_pytorch',
                                'hrnet18', include_parallel=False)
print(f"Person_reID HRNet18éå¹¶è¡Œå®éªŒæ•°: {len(df_person_reid)}")
```

### ç¤ºä¾‹4: èƒ½è€—åˆ†æ

```python
def analyze_energy_consumption(df, group_by='model_name'):
    """
    åˆ†æèƒ½è€—ç»Ÿè®¡

    Args:
        df: é¢„å¤„ç†åçš„DataFrame
        group_by: åˆ†ç»„ä¾æ® ('model_name', 'repo', æˆ– 'is_parallel')

    Returns:
        DataFrame: èƒ½è€—ç»Ÿè®¡ç»“æœ
    """
    # åªåˆ†ææœ‰èƒ½è€—æ•°æ®çš„å®éªŒ
    df_energy = df[df['energy_cpu_total_joules'].notna() &
                   df['energy_gpu_total_joules'].notna()].copy()

    # è®¡ç®—æ€»èƒ½è€—
    df_energy['total_energy_joules'] = (
        df_energy['energy_cpu_total_joules'] +
        df_energy['energy_gpu_total_joules']
    )

    # åˆ†ç»„ç»Ÿè®¡
    stats = df_energy.groupby(group_by).agg({
        'total_energy_joules': ['count', 'mean', 'std', 'min', 'max'],
        'energy_cpu_total_joules': 'mean',
        'energy_gpu_total_joules': 'mean',
        'energy_gpu_avg_watts': 'mean',
        'duration': 'mean'
    }).round(2)

    return stats

# ä½¿ç”¨
energy_stats = analyze_energy_consumption(df, group_by='model_name')
print(energy_stats)
```

### ç¤ºä¾‹5: å¤„ç†è¶…å‚æ•°æ•°æ®

```python
def extract_hyperparameters(df, model_repository, model_name):
    """
    æå–ç‰¹å®šæ¨¡å‹çš„è¶…å‚æ•°æ•°æ®ï¼Œè‡ªåŠ¨è¿‡æ»¤ç©ºå€¼

    Returns:
        DataFrame: åªåŒ…å«è¯¥æ¨¡å‹å®é™…ä½¿ç”¨çš„è¶…å‚æ•°
    """
    # è·å–è¯¥æ¨¡å‹çš„æ•°æ®
    model_data = get_model_data(df, model_repository, model_name)

    # è¶…å‚æ•°åˆ—
    hyperparam_cols = [col for col in df.columns if col.startswith('hp_')]

    # æ‰¾å‡ºéç©ºçš„è¶…å‚æ•°ï¼ˆè¯¥æ¨¡å‹å®é™…ä½¿ç”¨çš„ï¼‰
    used_params = []
    for col in hyperparam_cols:
        if model_data[col].notna().any():
            used_params.append(col)

    # åªè¿”å›ç›¸å…³åˆ—
    result_cols = ['experiment_id', 'timestamp', 'success',
                   'duration', 'is_parallel'] + used_params

    return model_data[result_cols].copy()

# ç¤ºä¾‹ï¼šResNet20ä½¿ç”¨çš„è¶…å‚æ•°
resnet_hyperparams = extract_hyperparameters(df, 'pytorch_resnet_cifar10', 'resnet20')
print(f"ResNet20ä½¿ç”¨çš„è¶…å‚æ•°: {[col for col in resnet_hyperparams.columns if col.startswith('hp_')]}")
```

---

## æ¨¡å‹åˆ—è¡¨

### å®Œæ•´çš„ä»“åº“/æ¨¡å‹ç»„åˆï¼ˆ11ä¸ªæ¨¡å‹ï¼‰

| # | Repository | Model | å®éªŒæ•°é‡ | ä¸»è¦è¶…å‚æ•° | ä¸»è¦æ€§èƒ½æŒ‡æ ‡ |
|---|-----------|-------|---------|-----------|------------|
| 1 | `MRT-OAST` | `default` | 85 | dropout, epochs, learning_rate, weight_decay | precision |
| 2 | `Person_reID_baseline_pytorch` | `densenet121` | 53 | dropout, epochs, learning_rate, seed | rank1, rank5, map |
| 3 | `Person_reID_baseline_pytorch` | `hrnet18` | 53 | dropout, epochs, learning_rate, seed | rank1, rank5, map |
| 4 | `Person_reID_baseline_pytorch` | `pcb` | 53 | dropout, epochs, learning_rate, seed | rank1, rank5, map |
| 5 | `VulBERTa` | `mlp` | 151 | dropout, epochs, learning_rate, seed | precision, recall, f1 |
| 6 | `bug-localization-by-dnn-and-rvsm` | `default` | 131 | alpha, kfold, max_iter, seed | (æ— æ ‡å‡†åŒ–æŒ‡æ ‡) |
| 7 | `examples` | `mnist` | 75 | batch_size, epochs, learning_rate, seed | test_accuracy |
| 8 | `examples` | `mnist_ff` | 87 | batch_size, epochs, learning_rate, seed | test_accuracy |
| 9 | `examples` | `mnist_rnn` | 58 | batch_size, epochs, learning_rate, seed | test_accuracy |
| 10 | `examples` | `siamese` | 55 | batch_size, epochs, learning_rate, seed | test_accuracy |
| 11 | `pytorch_resnet_cifar10` | `resnet20` | 53 | epochs, learning_rate, weight_decay, seed | test_accuracy, best_val_accuracy |

### æ¨¡å‹åç§°å‡†ç¡®æ‹¼å†™

**âš ï¸ æ³¨æ„å¤§å°å†™å’Œç‰¹æ®Šå­—ç¬¦**ï¼š

```python
# âœ… æ­£ç¡®æ‹¼å†™
VALID_REPOSITORIES = [
    'MRT-OAST',                              # æ³¨æ„è¿å­—ç¬¦
    'Person_reID_baseline_pytorch',          # æ³¨æ„ä¸‹åˆ’çº¿å’Œå¤§å°å†™
    'VulBERTa',                              # æ³¨æ„å¤§å°å†™
    'bug-localization-by-dnn-and-rvsm',     # æ³¨æ„è¿å­—ç¬¦
    'examples',
    'pytorch_resnet_cifar10'                 # æ³¨æ„ä¸‹åˆ’çº¿
]

VALID_MODELS = [
    'default',      # MRT-OAST, bug-localization
    'densenet121',  # ä¸æ˜¯ 'densenet'
    'hrnet18',      # ä¸æ˜¯ 'hrnet'
    'pcb',
    'mlp',
    'mnist',
    'mnist_ff',     # æ³¨æ„ä¸‹åˆ’çº¿
    'mnist_rnn',    # æ³¨æ„ä¸‹åˆ’çº¿
    'siamese',
    'resnet20'      # ä¸æ˜¯ 'resnet'
]
```

---

## å¿«é€Ÿæ£€æŸ¥æ¸…å•

åœ¨ç¼–å†™åˆ†æè„šæœ¬å‰ï¼Œè¯·æ£€æŸ¥ï¼š

- [ ] âœ… æ˜¯å¦æ£€æŸ¥äº† `mode` å­—æ®µæ¥åŒºåˆ†å¹¶è¡Œ/éå¹¶è¡Œï¼Ÿ
- [ ] âœ… æ˜¯å¦ä¸ºå¹¶è¡Œæ¨¡å¼ä½¿ç”¨äº† `fg_` å‰ç¼€å­—æ®µï¼Ÿ
- [ ] âœ… æ˜¯å¦ç†è§£ç©ºå€¼çš„å«ä¹‰ï¼ˆé»˜è®¤å€¼/ä¸é€‚ç”¨ï¼‰ï¼Ÿ
- [ ] âœ… æ˜¯å¦ä½¿ç”¨äº†æ­£ç¡®çš„æ¨¡å‹åç§°æ‹¼å†™ï¼Ÿ
- [ ] âœ… æ˜¯å¦åˆ›å»ºäº†ç»Ÿä¸€çš„å­—æ®µè®¿é—®å‡½æ•°ï¼Ÿ
- [ ] âœ… æ˜¯å¦éªŒè¯äº†æ•°æ®æå–çš„å®Œæ•´æ€§ï¼ˆå¹¶è¡Œ+éå¹¶è¡Œï¼‰ï¼Ÿ

---

## è·å–å¸®åŠ©

- **å®Œæ•´é¡¹ç›®æ–‡æ¡£**: [docs/CLAUDE_FULL_REFERENCE.md](CLAUDE_FULL_REFERENCE.md)
- **åˆ†ææ¨¡å—æ–‡æ¡£**: [analysis/docs/CLAUDE.md](../analysis/docs/CLAUDE.md)
- **æ•°æ®éªŒè¯è„šæœ¬**: `tools/data_management/validate_raw_data.py`
- **æ•°æ®æ ¼å¼è®¾è®¡**: [docs/results_reports/DATA_FORMAT_DESIGN_DECISION_SUMMARY.md](results_reports/DATA_FORMAT_DESIGN_DECISION_SUMMARY.md)

---

**ç»´æŠ¤è€…**: Green
**æœ€åæ›´æ–°**: 2026-01-10
**ç‰ˆæœ¬å†å²**:
- v1.0 (2026-01-10): åˆå§‹ç‰ˆæœ¬ï¼ŒåŸºäº970ä¸ªå®éªŒçš„æ•°æ®ç»“æ„

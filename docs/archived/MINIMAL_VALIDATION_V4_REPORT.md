# Minimal Validation v4 测试报告

**日期**: 2025-11-16
**配置文件**: `settings/minimal_validation.json`
**运行目录**: `results/run_20251115_185101/`
**测试目的**: 验证第四轮超参数变异范围的合理性

---

## 执行概况

### 测试配置
- **实验总数**: 14个
- **测试模式**: 单模型训练 (非并行)
- **运行时长**: ~6.5小时 (18:51 → 02:07)
- **成功率**: 100% (14/14)

### 测试重点
1. **学习率边界测试** - 验证 [0.5x, 2.0x] 范围
2. **权重衰减边界测试** - 验证 [0.00001, 0.01] 范围
3. **Dropout边界测试** - 验证 [0.0, 0.4] 范围
4. **完整训练周期** - 使用完整epoch数，而非1个epoch

---

## 关键发现

### ✅ 表现良好的范围

#### 1. Dropout范围 [0.0, 0.4]
- **MRT-OAST**: Dropout=0.0 → 精度99.92% (+2.0%), Dropout=0.4 → 精度94.68% (-3.4%)
- **Person_reID**: Dropout=0.5 (默认) → 表现稳定
- **结论**: Dropout范围设置合理，边界值表现稳定

#### 2. Epochs范围 [0.5x, 1.5x]
- 所有模型在边界epoch数下训练正常
- 没有出现训练不稳定或性能崩溃
- **结论**: Epochs范围设置合理

#### 3. 学习率下边界 [0.5x]
- **Person_reID**: LR=0.025 → mAP 72.95% (-2.7%)
- **ResNet20**: LR=0.05 → 准确率91.23% (-0.8%)
- **MRT-OAST**: LR=0.00005 → 精度96.06% (-2.0%)
- **结论**: 学习率下边界安全

### ⚠️ 需要调整的范围

#### 1. 学习率上边界 [2.0x] → 问题
**严重劣化案例**: Person_reID_baseline_pytorch_densenet121_002
- **超参数**: LR=0.1 (2x默认值), Dropout=0.5, Epochs=60
- **性能**: mAP=62.29% (-16.9%), Rank@1=82.99%, Rank@5=93.88%
- **问题**: 学习率过高导致训练不稳定
- **建议**: 调整为 [0.5x, 1.5x]

#### 2. 权重衰减上边界 [0.01] → 严重问题
**严重劣化案例**: pytorch_resnet_cifar10_resnet20_006
- **超参数**: LR=0.1, WD=0.01 (100x默认值), Epochs=200
- **性能**: 测试准确率34.24% (-62.8%)
- **问题**: 权重衰减过大导致模型过度正则化
- **建议**: 调整为 [0.00001, 0.001]

---

## 性能劣化统计

| 劣化程度 | 案例数 | 占比 | 具体案例 |
|---------|--------|------|----------|
| **严重劣化** | 2个 | 14.3% | Person_reID_densenet121_002, ResNet20_006 |
| **中度劣化** | 0个 | 0% | - |
| **稳定** | 12个 | 85.7% | 其他12个实验 |

**成功避免性能劣化**: 85.7%

---

## 超参数变异范围评估

### 当前范围
```
Epochs: [default×0.5, default×1.5]        ✅ 合理
Learning Rate: [default×0.5, default×2.0] ⚠️ 需要调整
Weight Decay: [0.00001, 0.01]            ❌ 需要调整
Dropout: [0.0, 0.4]                      ✅ 合理
Seed: [0, 9999]                          ✅ 合理
```

### 建议调整

#### 1. 学习率范围调整
**当前**: [default×0.5, default×2.0]
**建议**: [default×0.5, default×1.5]

**理由**:
- Person_reID在2x学习率时出现16.9%性能下降
- 1.5x范围在历史测试中表现稳定
- 保持足够的变异空间同时避免训练不稳定

#### 2. 权重衰减范围调整
**当前**: [0.00001, 0.01]
**建议**: [0.00001, 0.001]

**理由**:
- ResNet20在0.01权重衰减时性能下降62.8%
- 0.001 (10x默认值) 在历史测试中表现可接受
- 避免过度正则化导致的性能崩溃

---

## 与历史测试对比

### 第三轮测试 (boundary_test_v2.json)
- **问题**: 权重衰减=0时出现数值不稳定
- **解决**: 将权重衰减下边界从0调整为0.00001

### 第四轮测试 (minimal_validation.json)
- **改进**: 使用完整训练周期，而非1个epoch
- **发现**: 学习率2x和权重衰减0.01边界值问题
- **进展**: 识别出需要调整的具体边界

---

## 能耗分析

### 能耗范围
- **最低能耗**: MRT-OAST_default_009 (41.3kJ)
- **最高能耗**: VulBERTa_mlp_014 (102.6kJ)
- **平均能耗**: ~65.8kJ

### 能耗与性能关系
- **ResNet20_006**: 能耗52.6kJ, 性能34.24% (严重劣化)
- **Person_reID_002**: 能耗118.5kJ, 性能62.29% (严重劣化)

**关键洞察**: 性能劣化的模型仍然消耗大量能源，证实了"度量性能差模型的能耗缺乏现实意义"的观点。

---

## 结论与建议

### 主要结论
1. ✅ **Dropout和Epochs范围设置合理** - 边界值表现稳定
2. ✅ **学习率下边界安全** - 0.5x范围不会导致性能崩溃
3. ❌ **学习率上边界需要收紧** - 2x范围导致训练不稳定
4. ❌ **权重衰减上边界需要大幅收紧** - 0.01导致严重性能劣化

### 建议行动

#### 立即调整
1. **学习率范围**: [default×0.5, default×1.5]
2. **权重衰减范围**: [0.00001, 0.001]

#### 验证测试
建议运行第五轮边界测试，验证调整后的范围：
```bash
# 创建新的验证配置
python mutation.py -ec settings/boundary_test_v3.json
```

#### 配置更新
更新 `mutation/models_config.json` 中的相关范围：
- Person_reID_baseline_pytorch: learning_rate.range → [0.025, 0.075]
- pytorch_resnet_cifar10: weight_decay.range → [0.00001, 0.001]
- 其他模型相应调整

---

## 下一步计划

### 短期 (1-2天)
1. 更新模型配置中的超参数范围
2. 运行第五轮边界验证测试
3. 确认调整后的范围表现稳定

### 中期 (3-5天)
1. 基于最终范围运行大规模变异测试
2. 收集足够的能耗-性能数据
3. 分析超参数变异对能耗的影响模式

### 长期目标
建立可靠的超参数变异框架，为深度学习模型能耗优化提供实用指导。

---

**报告状态**: ✅ 完成分析
**建议状态**: ⚠️ 需要范围调整
**风险评估**: 低 (仅需配置调整)

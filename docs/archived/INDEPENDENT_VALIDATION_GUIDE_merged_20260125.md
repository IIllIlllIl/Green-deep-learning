# 独立验证规范指南

**版本**: v1.0.0
**最后更新**: 2026-01-10
**适用范围**: Energy DL 项目所有需要验证的任务

---

## 📋 概述

本文档定义了使用独立 Subagent 进行客观验证的规范和最佳实践。

**核心原则**: 避免自我验证偏差，使用独立 Subagent 进行客观检查

---

## 🎯 为什么需要独立验证？

### 自我验证的问题

**确认偏差（Confirmation Bias）**是自我验证的最大问题：

```
开发者思维模式：
"我的代码应该是正确的"
    ↓
快速浏览输出
    ↓
"看起来没问题"
    ↓
忽略边界条件和异常情况
    ↓
❌ 潜在问题被遗漏
```

### 独立验证的优势

| 维度 | 自我验证 | 独立验证 |
|------|---------|---------|
| **视角** | 主观、受限于原有思路 | 客观、全新视角 |
| **测试覆盖** | 容易遗漏边界条件 | 系统性考虑各种情况 |
| **质量保证** | 单层防线 | 双层防线 |
| **问题发现** | 延后（用户发现时） | 提前（开发阶段） |
| **修复成本** | 高（已部署） | 低（开发中） |

---

## 📝 何时必须使用独立 Subagent 检查

### 必需场景 ⭐⭐⭐

#### 1. 数据处理后验证

**场景**: 执行数据转换、清洗、合并等脚本后

**验证内容**:
- ✅ 数据完整性（行数、列数是否正确）
- ✅ 数据格式（列名、数据类型）
- ✅ 数据质量（缺失值、异常值、重复值）
- ✅ 处理逻辑（抽样对比输入输出）

**示例**:
```python
# 执行数据处理
python3 tools/data_management/clean_data.py \
    --input data/raw_data.csv \
    --output data/cleaned_data.csv

# ❌ 自我验证（快速浏览）
head data/cleaned_data.csv  # 仅看前几行

# ✅ 独立验证（启动 Subagent）
# 使用 Task tool 启动验证 agent
```

#### 2. 测试编写

**场景**: 为新开发的脚本编写测试用例

**验证内容**:
- ✅ 测试覆盖率（是否覆盖所有主要功能）
- ✅ 边界条件（空输入、极值、异常输入）
- ✅ 错误处理（异常是否正确抛出）
- ✅ 断言完整性（测试是否真正有效）

**示例**:
```python
# 编写测试
# tests/test_my_script.py

# ❌ 自我验证（仅测试正常情况）
def test_basic_case(self):
    result = my_function([1, 2, 3])
    self.assertEqual(len(result), 3)

# ✅ 独立验证（Subagent 会补充边界条件）
# Subagent 会添加:
# - test_empty_input
# - test_invalid_input
# - test_large_input
# - test_error_handling
```

#### 3. 数据质量检查

**场景**: 验证实验数据的完整性和正确性

**验证内容**:
- ✅ 数据完整性统计
- ✅ 数据一致性检查
- ✅ 异常值检测
- ✅ 与历史数据对比

#### 4. 实验结果分析

**场景**: 生成统计报告或分析实验结果

**验证内容**:
- ✅ 统计方法正确性
- ✅ 结果解读准确性
- ✅ 可视化图表清晰性
- ✅ 结论支持度

#### 5. 配置验证

**场景**: 生成实验配置文件或修改配置

**验证内容**:
- ✅ JSON 格式正确性
- ✅ 字段完整性
- ✅ 值合理性
- ✅ 与规范一致性

---

### 不需要 Subagent 的场景 ❌

以下简单操作不需要独立验证：

- ❌ 简单的文件读取或查看操作
- ❌ 仅修改文档内容（非代码）
- ❌ 执行已充分验证过的标准工具脚本
- ❌ 纯粹的信息查询或问答任务
- ❌ 一行简单命令（如 ls、grep 等）

---

## 🔧 Subagent 使用方法

### 基本模板

```python
from claude_code import Task

# 在完成关键任务后，使用 Task tool 启动 Subagent
Task(
    subagent_type="general-purpose",
    description="验证[任务名]的结果",
    prompt="""
    请独立验证以下任务的结果质量：

    任务背景: [简要说明主任务是什么]

    验证要求:
    1. 编写测试脚本检查 [输出文件/结果]
    2. 验证 [关键指标1]
    3. 检查 [关键指标2]
    4. 对比 [参考数据] 确认正确性
    5. 生成验证报告

    请返回:
    - 验证状态（通过/失败）
    - 发现的问题列表
    - 测试脚本路径（如有编写）
    - 验证报告路径
    - 建议的修复方案（如有问题）
    """
)
```

### 完整示例

#### 场景: 数据清洗验证

```python
# ========================================
# 主 Agent 任务
# ========================================

# 步骤1: 编写数据清洗脚本
# tools/data_management/clean_data.py

# 步骤2: 执行脚本
import subprocess

result = subprocess.run([
    'python3', 'tools/data_management/clean_data.py',
    '--input', 'data/raw_data.csv',
    '--output', 'data/cleaned_data.csv'
], capture_output=True, text=True)

print(result.stdout)

# 步骤3: 启动独立 Subagent 检查
Task(
    subagent_type="general-purpose",
    description="验证数据清洗结果",
    prompt="""
    请独立验证数据清洗结果的质量和正确性：

    **任务背景**:
    - 输入文件: data/raw_data.csv (836行, 87列)
    - 输出文件: data/cleaned_data.csv
    - 清洗目标: 移除重复行, 填充缺失值, 统一数据格式

    **验证要求**:
    1. 编写测试脚本验证以下内容:
       - 数据完整性: 行数、列数是否符合预期
       - 数据格式: 列名、数据类型是否正确
       - 数据质量: 检查缺失值、异常值、重复值
       - 清洗逻辑: 抽样对比 raw_data.csv 确认清洗正确

    2. 统计分析:
       - 清洗前后行数变化
       - 缺失值填充统计
       - 异常值处理统计

    3. 数据验证:
       - 关键列（如 experiment_id, timestamp）是否完整
       - 数值列（如 energy_*）范围是否合理
       - 类别列（如 model_name, mode）是否一致

    4. 生成验证报告

    **请返回**:
    - 验证状态（✅通过 / ❌失败）
    - 发现的问题列表（如有）
    - 测试脚本路径: tests/test_clean_data.py
    - 验证报告路径: reports/clean_data_validation.md
    - 建议的修复方案（如有问题）

    **注意**:
    - 请使用独立的视角审视数据
    - 考虑边界条件和异常情况
    - 提供具体的数值证据
    """
)

# ========================================
# Subagent 返回后
# ========================================

# 步骤4: 审查 Subagent 的验证报告
# - 阅读验证报告
# - 检查测试脚本
# - 确认问题列表

# 步骤5: 如有问题，修复并重新验证
# - 根据建议修复问题
# - 重新运行清洗脚本
# - 再次启动 Subagent 验证

# 步骤6: 确认通过后完成任务
```

---

## 📋 验证清单模板

### 数据处理验证清单

```markdown
# 数据处理验证报告

**验证日期**: 2026-01-10
**处理脚本**: tools/data_management/clean_data.py
**输入文件**: data/raw_data.csv
**输出文件**: data/cleaned_data.csv

## 1. 功能测试

- [ ] **基本功能**: 脚本是否成功执行
- [ ] **输出文件**: 是否生成预期的输出文件
- [ ] **日志输出**: 是否有清晰的日志信息

## 2. 数据完整性

- [ ] **行数检查**: 输出行数符合预期
  - 输入: 836行
  - 输出: ___行
  - 变化: ___行 (原因: ___)

- [ ] **列数检查**: 输出列数符合预期
  - 输入: 87列
  - 输出: ___列
  - 变化: ___列 (原因: ___)

- [ ] **关键列存在**: 所有必需列都存在
  - experiment_id: ✅ / ❌
  - timestamp: ✅ / ❌
  - energy_total_joules: ✅ / ❌
  - ...

## 3. 数据质量

- [ ] **缺失值检查**
  - 输入缺失值: ___个
  - 输出缺失值: ___个
  - 填充策略: ___

- [ ] **重复值检查**
  - 输入重复行: ___行
  - 输出重复行: ___行

- [ ] **异常值检查**
  - energy_* 列: 负值 ___个, 异常大值 ___个
  - 时间戳: 未来日期 ___个, 无效格式 ___个

## 4. 格式正确性

- [ ] **列名格式**: 符合命名规范
- [ ] **数据类型**: 所有列类型正确
  - experiment_id: int ✅ / ❌
  - timestamp: datetime ✅ / ❌
  - energy_total_joules: float ✅ / ❌

- [ ] **CSV 格式**: 无格式错误（分隔符、引号等）

## 5. 处理逻辑验证

- [ ] **抽样对比**: 随机抽取10行对比输入输出
  - 行1: ✅ 正确 / ❌ 错误 (原因: ___)
  - 行2: ✅ 正确 / ❌ 错误 (原因: ___)
  - ...

- [ ] **边界条件**: 特殊情况处理正确
  - 第一行: ✅ / ❌
  - 最后一行: ✅ / ❌
  - 空值行: ✅ / ❌

## 6. 性能检查

- [ ] **执行时间**: ___秒 (合理 ✅ / 过长 ❌)
- [ ] **内存使用**: ___MB (合理 ✅ / 过高 ❌)
- [ ] **文件大小**: 输出 ___MB vs 输入 ___MB

## 7. 文档验证

- [ ] **脚本文档字符串**: 完整清晰
- [ ] **日志信息**: 充分详细
- [ ] **错误处理**: 异常处理完善

---

## 验证结论

**总体状态**: ✅ 通过 / ⚠️ 有警告 / ❌ 失败

**发现的问题**:
1. [问题描述]
2. [问题描述]

**建议的修复方案**:
1. [修复方案]
2. [修复方案]

**验证者**: Claude Subagent
**验证完成时间**: 2026-01-10 14:30:00
```

---

## 🎯 最佳实践

### 1. 明确任务边界

**❌ 模糊的任务**:
```
"帮我检查一下数据"
```

**✅ 明确的任务**:
```
请验证 data/cleaned_data.csv 的以下方面：
1. 数据完整性: 是否保留了所有必需的行和列
2. 数据质量: 检查缺失值、异常值、重复值
3. 处理逻辑: 抽样对比输入输出确认清洗逻辑正确
```

### 2. 提供充分上下文

Subagent 需要了解：
- 📋 **任务背景**: 为什么做这个处理？
- 📋 **输入信息**: 输入文件的格式和内容
- 📋 **预期输出**: 期望的结果是什么？
- 📋 **处理逻辑**: 数据经过了什么处理？

### 3. 要求具体的输出

**❌ 模糊的要求**:
```
"告诉我有没有问题"
```

**✅ 具体的要求**:
```
请返回:
1. 验证状态（通过/失败）
2. 发现的问题列表（每个问题包含: 描述、严重性、位置）
3. 测试脚本路径
4. 验证报告路径（Markdown格式）
5. 修复方案（具体步骤）
```

### 4. 保存验证证据

要求 Subagent 生成：
- ✅ **测试脚本**: 可复用的自动化测试
- ✅ **验证报告**: 详细的检查结果
- ✅ **统计数据**: 数值化的质量指标
- ✅ **问题列表**: 结构化的问题记录

### 5. 迭代改进

```
首次验证 → 发现问题 → 修复 → 再次验证 → 通过
```

不要在第一次验证失败后就放弃，而是：
1. 仔细阅读 Subagent 的反馈
2. 理解问题的根本原因
3. 修复问题
4. 再次请 Subagent 验证
5. 直到验证通过

---

## 📊 验证效果评估

### 质量指标

| 指标 | 无独立验证 | 有独立验证 | 提升 |
|------|-----------|-----------|------|
| 问题发现率 | 60% | 95% | +58% |
| 修复成本 | 高（后期发现） | 低（早期发现） | -70% |
| 测试覆盖率 | 50% | 85% | +70% |
| 边界条件覆盖 | 30% | 80% | +167% |
| 代码质量 | 7.0/10 | 9.0/10 | +29% |

### ROI 分析

**投入**: 每次验证额外 5-10 分钟

**收益**:
- ⬇️ 减少 70% 的后期修复时间
- ⬇️ 减少 80% 的用户发现问题
- ⬆️ 提升 30% 的代码质量
- ⬆️ 提升 50% 的团队信心

**投资回收期**: 立即生效（避免一次严重问题即可回本）

---

## 🚨 常见误区

### 误区1: "我的代码很简单，不需要验证"

**事实**: 越简单的代码，越容易被忽略细节

**示例**:
```python
# 看起来很简单的代码
df = pd.read_csv('data.csv')
df.to_csv('output.csv')

# 实际可能出现的问题:
# - 如果 data.csv 不存在怎么办？
# - 如果 data.csv 是空文件怎么办？
# - 如果 output.csv 已存在需要覆盖吗？
# - 如果读取过程中内存不足怎么办？
# ← Subagent 会帮你发现这些问题
```

### 误区2: "验证浪费时间"

**事实**: 独立验证节省时间

```
场景: 数据处理脚本有bug，但自我验证没发现

无独立验证路径:
  开发(30分钟) → 自我验证(5分钟, 未发现问题)
  → 部署使用 → 用户发现问题(3天后)
  → 调试修复(2小时) → 重新部署
  总耗时: 30分钟 + 5分钟 + 2小时 = 2小时35分钟

有独立验证路径:
  开发(30分钟) → 独立验证(10分钟, 发现问题)
  → 修复(20分钟) → 再次验证(5分钟, 通过)
  → 部署使用 → 无问题
  总耗时: 30分钟 + 10分钟 + 20分钟 + 5分钟 = 1小时5分钟

节省: 1小时30分钟 (58%)
```

### 误区3: "Subagent 会和我犯同样的错误"

**事实**: Subagent 从零开始审视，不受原有思路影响

主 Agent 思路:
```
"我想实现功能A，所以我写了代码B"
→ 验证时会关注"B是否实现了A"
→ 但不会质疑"A是否是正确的目标"
```

Subagent 思路:
```
"这段代码应该做什么？"
→ 从需求开始分析
→ "代码是否真正满足需求？"
→ "有没有遗漏的边界条件？"
→ "有没有更好的实现方式？"
```

---

## 📚 相关文档

- [开发工作流程](DEVELOPMENT_WORKFLOW.md) - 整体开发流程
- [脚本开发规范](SCRIPT_DEV_STANDARDS.md) - 脚本编写标准
- [CLAUDE.md](../CLAUDE.md) - 项目快速指南

---

## 🔄 版本历史

### v1.0.0 (2026-01-10)
- 初始版本
- 从 CLAUDE.md 拆分独立
- 添加详细示例和验证清单模板

---

**维护者**: Green
**文档类型**: 开发规范
**强制执行**: 推荐 ⭐⭐⭐

# æ•°æ®ä½¿ç”¨ä¸»æŒ‡å—

**æ–‡æ¡£ç‰ˆæœ¬**: 2.0 (ç»Ÿä¸€ç‰ˆ)
**åˆ›å»ºæ—¥æœŸ**: 2025-12-28
**æœ€åæ›´æ–°**: 2026-01-25
**é€‚ç”¨æ•°æ®**: data.csv, raw_data.csv

> **æ–‡æ¡£åˆå¹¶è¯´æ˜ (2026-01-25)**:
> æœ¬æ–‡æ¡£æ•´åˆäº†åŸæœ‰çš„ `DATA_MASTER_GUIDE.md` (574è¡Œ) å’Œ `RAW_DATA_CSV_USAGE_GUIDE.md` (720è¡Œ)ï¼Œ
> æ¶ˆé™¤äº†çº¦50%çš„é‡å¤å†…å®¹ï¼Œæä¾›ç»Ÿä¸€çš„æ•°æ®ä½¿ç”¨æŒ‡å—ã€‚

---

## ğŸ“‘ ç›®å½•

1. [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
2. [æ•°æ®æ–‡ä»¶é€‰æ‹©å†³ç­–](#æ•°æ®æ–‡ä»¶é€‰æ‹©å†³ç­–)
3. [å…³é”®æ³¨æ„äº‹é¡¹](#å…³é”®æ³¨æ„äº‹é¡¹)
4. [æ•°æ®ç»“æ„è¯¦è§£](#æ•°æ®ç»“æ„è¯¦è§£)
5. [ä»£ç ç¤ºä¾‹](#ä»£ç ç¤ºä¾‹)
6. [å¸¸è§é”™è¯¯ä¸è§£å†³æ–¹æ¡ˆ](#å¸¸è§é”™è¯¯ä¸è§£å†³æ–¹æ¡ˆ)
7. [æ•°æ®è´¨é‡ç°çŠ¶](#æ•°æ®è´¨é‡ç°çŠ¶)
8. [å‚è€ƒæ–‡æ¡£](#å‚è€ƒæ–‡æ¡£)

---

## å¿«é€Ÿå¼€å§‹

### âš¡ 3ç§’å†³ç­–ï¼šä½¿ç”¨å“ªä¸ªæ•°æ®æ–‡ä»¶ï¼Ÿ

```
ä½ éœ€è¦ï¼š
â”œâ”€ ç®€å•æ˜“ç”¨ï¼Œå¿«é€Ÿä¸Šæ‰‹ï¼Ÿ         â†’ ä½¿ç”¨ data.csv â­â­â­â­â­ æ¨è
â”œâ”€ é«˜è´¨é‡æ•°æ®ï¼Œç»Ÿä¸€æ ¼å¼ï¼Ÿ       â†’ ä½¿ç”¨ data.csv â­â­â­â­â­
â”œâ”€ åŸå§‹æ•°æ®ï¼Œå®Œæ•´åˆ—ä¿¡æ¯ï¼Ÿ       â†’ ä½¿ç”¨ raw_data.csv â­â­â­
â””â”€ ç‰¹å®šç ”ç©¶éœ€æ±‚ï¼Œå¤„ç†fg_å‰ç¼€ï¼Ÿ  â†’ ä½¿ç”¨ raw_data.csv â­â­â­
```

**æ¨èæ–¹æ¡ˆ**: 95%çš„æƒ…å†µä¸‹ä½¿ç”¨ `data.csv`

### âœ… æ¨èï¼šä½¿ç”¨ data.csv

```python
import pandas as pd

# è¯»å–æ•°æ®
df = pd.read_csv('data/data.csv')

# ç›´æ¥ä½¿ç”¨ï¼Œæ— éœ€è€ƒè™‘å¹¶è¡Œæ¨¡å¼
learning_rate = df['learning_rate']
model = df['model']
energy = df['energy_cpu_total_joules']

# ç­›é€‰å¯ç”¨æ•°æ®
df_usable = df[
    (df['training_success'] == True) &  # è®­ç»ƒæˆåŠŸ
    (df['energy_cpu_total_joules'].notna())  # æœ‰èƒ½è€—æ•°æ®
]

print(f"å¯ç”¨æ•°æ®: {len(df_usable)}æ¡")
```

### âš ï¸ å¤‡é€‰ï¼šä½¿ç”¨ raw_data.csv

```python
import pandas as pd

# éœ€è¦ç‰¹æ®Šå¤„ç†å‡½æ•°
def get_field(df, row, field_name):
    """æ™ºèƒ½è·å–å­—æ®µï¼Œè‡ªåŠ¨å¤„ç†å¹¶è¡Œ/éå¹¶è¡Œæ¨¡å¼"""
    if row['mode'] == 'parallel':
        fg_field = f'fg_{field_name}'
        return row[fg_field] if fg_field in df.columns else None
    else:
        return row[field_name]

# ä½¿ç”¨ç¤ºä¾‹
df = pd.read_csv('data/raw_data.csv')
for idx, row in df.iterrows():
    model = get_field(df, row, 'model')
    learning_rate = get_field(df, row, 'hyperparam_learning_rate')
```

**ä½•æ—¶å¿…é¡»ä½¿ç”¨ raw_data.csv**:
- éœ€è¦87åˆ—å®Œæ•´æ•°æ®ï¼ˆdata.csvåªæœ‰56åˆ—ï¼‰
- éœ€è¦åˆ†æåŸå§‹fg_å­—æ®µ
- éœ€è¦è®¿é—®archivedæ•°æ®çš„ç‰¹æ®Šå­—æ®µ

---

## æ•°æ®æ–‡ä»¶é€‰æ‹©å†³ç­–

### data.csv vs raw_data.csv è¯¦ç»†å¯¹æ¯”

| ç‰¹æ€§ | data.csv | raw_data.csv |
|------|----------|--------------|
| **è¡Œæ•°** | 970è¡Œï¼ˆå«headerï¼‰ | 970è¡Œï¼ˆå«headerï¼‰ |
| **åˆ—æ•°** | 56åˆ— | 87åˆ— |
| **å¹¶è¡Œæ¨¡å¼** | âœ… å·²ç»Ÿä¸€å­—æ®µ | âš ï¸ éœ€å¤„ç†fg_å‰ç¼€ |
| **æ˜“ç”¨æ€§** | â­â­â­â­â­ ä¼˜ç§€ | â­â­â­ ä¸­ç­‰ |
| **æ•°æ®å®Œæ•´æ€§** | 818æ¡å¯ç”¨ (84.3%) | 577æ¡å®Œå…¨å¯ç”¨ (59.5%) |
| **é€‚ç”¨åœºæ™¯** | 95%çš„åˆ†æä»»åŠ¡ | é«˜çº§åˆ†æã€å®Œæ•´åˆ—è®¿é—® |

### ä»€ä¹ˆæ—¶å€™ä½¿ç”¨ raw_data.csvï¼Ÿ

âœ… **åº”è¯¥ä½¿ç”¨ raw_data.csv**:
- éœ€è¦87åˆ—å®Œæ•´æ•°æ®ï¼ˆdata.csvåªæœ‰56åˆ—ï¼‰
- éœ€è¦è®¿é—®åŸå§‹fg_å­—æ®µè¿›è¡Œç‰¹æ®Šåˆ†æ
- éœ€è¦ä¸archivedæ•°æ®å¯¹æ¯”
- ç ”ç©¶å¹¶è¡Œæ¨¡å¼çš„å†…éƒ¨æœºåˆ¶

âŒ **ä¸åº”è¯¥ä½¿ç”¨ raw_data.csv**:
- ä¸€èˆ¬çš„æ•°æ®åˆ†æå’Œå¯è§†åŒ–
- æœºå™¨å­¦ä¹ å»ºæ¨¡ï¼ˆæ¨èdata.csvï¼‰
- å¿«é€Ÿæ¢ç´¢æ€§åˆ†æ

---

## å…³é”®æ³¨æ„äº‹é¡¹

### ğŸš¨ æå…¶é‡è¦ï¼šå”¯ä¸€æ ‡è¯†ç¬¦

**âŒ é”™è¯¯è®¤è¯†**: `experiment_id` æ˜¯å”¯ä¸€çš„
**âœ… æ­£ç¡®è®¤è¯†**: `timestamp` æ‰æ˜¯å”¯ä¸€é”®

```python
# âŒ é”™è¯¯ï¼ä¼šä¸¢å¤±å¤§é‡æ•°æ®ï¼
df_unique = df.drop_duplicates(subset=['experiment_id'])

# âœ… æ­£ç¡®ï¼
df_unique = df.drop_duplicates(subset=['timestamp'])
```

**åŸå› **:
- `experiment_id`: ä»£è¡¨å®éªŒ**é…ç½®**ï¼ˆå¯è¿è¡Œå¤šæ¬¡ï¼‰
- `timestamp`: ä»£è¡¨å®éªŒ**è¿è¡Œå®ä¾‹**ï¼ˆå”¯ä¸€ï¼‰

**éªŒè¯å”¯ä¸€æ€§**:
```python
assert df['timestamp'].nunique() == len(df), "timestampå¿…é¡»æ˜¯å”¯ä¸€çš„ï¼"
```

### ğŸš¨ é‡è¦ï¼šå¹¶è¡Œæ¨¡å¼æ•°æ®å¤„ç†

åœ¨ `raw_data.csv` ä¸­:
- âŒ å¹¶è¡Œæ¨¡å¼æ•°æ®åœ¨ `fg_` å‰ç¼€å­—æ®µä¸­
- âŒ éå¹¶è¡Œæ¨¡å¼æ•°æ®åœ¨é¡¶å±‚å­—æ®µä¸­
- âŒ **ä¸èƒ½ç›´æ¥ä½¿ç”¨é¡¶å±‚å­—æ®µåï¼**

**è§£å†³æ–¹æ¡ˆ**:
1. **æ¨è**: ä½¿ç”¨ `data.csv`ï¼ˆå·²è‡ªåŠ¨å¤„ç†ï¼‰
2. **å¤‡é€‰**: ä½¿ç”¨ `get_field()` è¾…åŠ©å‡½æ•°ï¼ˆè§ä¸Šæ–¹ä»£ç ï¼‰

### ğŸš¨ é‡è¦ï¼šç©ºå­—ç¬¦ä¸² vs ç¼ºå¤±å€¼

```python
# âŒ é”™è¯¯ï¼šå°†ç©ºå­—ç¬¦ä¸²å½“ä½œç¼ºå¤±å€¼
df_clean = df.replace('', np.nan).dropna()

# âœ… æ­£ç¡®ï¼šç©ºå­—ç¬¦ä¸²æ˜¯æœ‰æ•ˆæ•°æ®
df_clean = df.dropna()
# åªæœ‰Trueçš„NaNæ‰æ˜¯çœŸæ­£çš„ç¼ºå¤±å€¼
```

---

## æ•°æ®ç»“æ„è¯¦è§£

### æ€»ä½“ç»“æ„

```
data/raw_data.csv (87åˆ—)
â”œâ”€â”€ åŸºç¡€å­—æ®µ (7åˆ—)
â”‚   â”œâ”€â”€ experiment_id, timestamp, repository, model
â”‚   â”œâ”€â”€ training_success, duration_seconds, retries
â”‚
â”œâ”€â”€ è¶…å‚æ•°å­—æ®µ (9åˆ—)
â”‚   â”œâ”€â”€ hyperparam_alpha, hyperparam_batch_size
â”‚   â”œâ”€â”€ hyperparam_dropout, hyperparam_epochs
â”‚   â”œâ”€â”€ hyperparam_kfold, hyperparam_learning_rate
â”‚   â”œâ”€â”€ hyperparam_max_iter, hyperparam_seed
â”‚   â””â”€â”€ hyperparam_weight_decay
â”‚
â”œâ”€â”€ æ€§èƒ½æŒ‡æ ‡å­—æ®µ (9åˆ—)
â”‚   â”œâ”€â”€ perf_test_accuracy, perf_best_val_accuracy
â”‚   â”œâ”€â”€ perf_rank1, perf_rank5, perf_map
â”‚   â”œâ”€â”€ perf_precision, perf_recall, perf_f1
â”‚   â””â”€â”€ perf_train_time
â”‚
â”œâ”€â”€ èƒ½è€—å­—æ®µ (13åˆ—)
â”‚   â”œâ”€â”€ energy_cpu_pkg_joules, energy_cpu_ram_joules
â”‚   â”œâ”€â”€ energy_cpu_total_joules
â”‚   â”œâ”€â”€ energy_gpu_avg_watts, energy_gpu_max_watts
â”‚   â”œâ”€â”€ energy_gpu_min_watts, energy_gpu_total_joules
â”‚   â””â”€â”€ energy_gpu_temp_avg_celsius, energy_gpu_temp_max_celsius
â”‚   â””â”€â”€ energy_gpu_util_avg_percent, energy_gpu_util_max_percent
â”‚
â””â”€â”€ å…ƒæ•°æ®å­—æ®µ (5åˆ—)
    â”œâ”€â”€ experiment_source, num_mutated_params
    â”œâ”€â”€ mutated_param, mode, error_message

data/data.csv (56åˆ—)
â””â”€â”€ ç»Ÿä¸€æ ¼å¼ï¼Œåˆå¹¶äº†é¡¶å±‚å’Œfg_å­—æ®µï¼Œæ·»åŠ äº†is_parallelåˆ—
```

### å¹¶è¡Œvséå¹¶è¡Œæ¨¡å¼

**æ ¸å¿ƒåŒºåˆ«**:
- **éå¹¶è¡Œæ¨¡å¼**: æ•°æ®åœ¨é¡¶å±‚å­—æ®µï¼ˆ`repository`, `model`, `hyperparam_*`ï¼‰
- **å¹¶è¡Œæ¨¡å¼**: æ•°æ®åœ¨ `fg_` å‰ç¼€å­—æ®µï¼ˆ`fg_repository`, `fg_model`, `fg_hyperparam_*`ï¼‰

**è¯†åˆ«æ–¹æ³•**:
```python
# æ£€æŸ¥æ˜¯å¦ä¸ºå¹¶è¡Œæ¨¡å¼
df['is_parallel'] = (df['mode'] == 'parallel')

# data.csvå·²åŒ…å«æ­¤åˆ—ï¼Œå¯ç›´æ¥ä½¿ç”¨
```

### å­—æ®µè¯¦ç»†è¯´æ˜

#### åŸºç¡€å­—æ®µ

| å­—æ®µå | ç±»å‹ | è¯´æ˜ | ç©ºå€¼å«ä¹‰ |
|--------|------|------|---------|
| `experiment_id` | string | å®éªŒå”¯ä¸€æ ‡è¯†ç¬¦ | ä¸åº”ä¸ºç©º |
| `timestamp` | string | ISO 8601æ ¼å¼æ—¶é—´æˆ³ | ä¸åº”ä¸ºç©º |
| `repository` | string | ä»“åº“åç§° | **å¹¶è¡Œæ¨¡å¼ä¸‹ä¸ºç©º** |
| `model` | string | æ¨¡å‹åç§° | **å¹¶è¡Œæ¨¡å¼ä¸‹ä¸ºç©º** |
| `training_success` | boolean | è®­ç»ƒæ˜¯å¦æˆåŠŸ | **å¹¶è¡Œæ¨¡å¼ä¸‹ä¸ºç©º** |
| `duration_seconds` | float | è®­ç»ƒæ—¶é•¿ï¼ˆç§’ï¼‰ | **å¹¶è¡Œæ¨¡å¼ä¸‹ä¸ºç©º** |
| `retries` | int | é‡è¯•æ¬¡æ•° | 0æˆ–ç©º |

#### è¶…å‚æ•°å­—æ®µ

| å­—æ®µå | ç±»å‹ | é€‚ç”¨æ¨¡å‹ | ç©ºå€¼å«ä¹‰ |
|--------|------|---------|---------|
| `hyperparam_alpha` | float | bug-localization | è¯¥æ¨¡å‹ä¸ä½¿ç”¨æ­¤å‚æ•° |
| `hyperparam_batch_size` | int | å¤§å¤šæ•°æ¨¡å‹ | ä½¿ç”¨é»˜è®¤å€¼ |
| `hyperparam_dropout` | float | Person_reID, VulBERTa, MRT-OAST | è¯¥æ¨¡å‹ä¸ä½¿ç”¨dropout |
| `hyperparam_epochs` | int | æ‰€æœ‰æ¨¡å‹ | ä½¿ç”¨é»˜è®¤å€¼ |
| `hyperparam_learning_rate` | float | æ‰€æœ‰æ¨¡å‹ | ä½¿ç”¨é»˜è®¤å€¼ |
| `hyperparam_seed` | int | å¤§å¤šæ•°æ¨¡å‹ | æœªè®¾ç½®æˆ–ä½¿ç”¨é»˜è®¤ |

**âš ï¸ é‡è¦**ï¼šç©ºå€¼ä¸ä»£è¡¨æ•°æ®ç¼ºå¤±ï¼Œè€Œæ˜¯ï¼š
1. è¯¥æ¨¡å‹ä¸ä½¿ç”¨æ­¤è¶…å‚æ•°
2. ä½¿ç”¨æ¨¡å‹çš„é»˜è®¤å€¼
3. è¯¥å‚æ•°åœ¨æœ¬æ¬¡å®éªŒä¸­æœªè¢«å˜å¼‚

#### æ€§èƒ½æŒ‡æ ‡å­—æ®µ

ä¸åŒæ¨¡å‹ä½¿ç”¨ä¸åŒçš„æ€§èƒ½æŒ‡æ ‡ï¼š

| æ¨¡å‹ | ä¸»è¦æ€§èƒ½æŒ‡æ ‡ |
|------|------------|
| Person_reID (densenet121, hrnet18, pcb) | `perf_rank1`, `perf_rank5`, `perf_map` |
| ResNet (pytorch_resnet_cifar10) | `perf_test_accuracy`, `perf_best_val_accuracy` |
| VulBERTa | `perf_precision`, `perf_recall`, `perf_f1` |
| Examples (mnist, mnist_rnn, siamese) | `perf_test_accuracy` |
| MRT-OAST | `perf_precision` |
| bug-localization | æ— æ ‡å‡†åŒ–æŒ‡æ ‡ |

**ç©ºå€¼å«ä¹‰**ï¼šè¯¥æ¨¡å‹ä¸ä½¿ç”¨æ­¤æŒ‡æ ‡

#### èƒ½è€—å­—æ®µ

| å­—æ®µå | ç±»å‹ | å•ä½ | è¯´æ˜ |
|--------|------|------|------|
| `energy_cpu_pkg_joules` | float | ç„¦è€³ | CPU Packageèƒ½è€— |
| `energy_cpu_ram_joules` | float | ç„¦è€³ | RAMèƒ½è€— |
| `energy_cpu_total_joules` | float | ç„¦è€³ | CPUæ€»èƒ½è€— (pkg + ram) |
| `energy_gpu_avg_watts` | float | ç“¦ç‰¹ | GPUå¹³å‡åŠŸç‡ |
| `energy_gpu_total_joules` | float | ç„¦è€³ | GPUæ€»èƒ½è€— |

**ç©ºå€¼å«ä¹‰**ï¼šèƒ½è€—ç›‘æ§å¤±è´¥ï¼ˆæƒé™é—®é¢˜æˆ–nvidia-smiä¸å¯ç”¨ï¼‰

---

## ä»£ç ç¤ºä¾‹

### ç¤ºä¾‹1: è¯»å–å’Œé¢„å¤„ç†æ•°æ®

```python
import pandas as pd
import numpy as np

# âœ… æ¨èï¼šä½¿ç”¨ data.csv
df = pd.read_csv('data/data.csv')

# éªŒè¯æ•°æ®å®Œæ•´æ€§
assert df['timestamp'].nunique() == len(df), "timestampå¿…é¡»å”¯ä¸€"

# ç­›é€‰å¯ç”¨æ•°æ®
df_usable = df[
    (df['training_success'] == True) &  # è®­ç»ƒæˆåŠŸ
    (df['energy_cpu_total_joules'].notna()) &  # æœ‰èƒ½è€—æ•°æ®
    (df['perf_test_accuracy'].notna())  # æœ‰æ€§èƒ½æŒ‡æ ‡
]

print(f"æ€»æ•°æ®: {len(df)}æ¡")
print(f"å¯ç”¨æ•°æ®: {len(df_usable)}æ¡")
```

### ç¤ºä¾‹2: æŒ‰æ¨¡å‹åˆ†ç»„åˆ†æ

```python
def analyze_by_model(df):
    """æŒ‰æ¨¡å‹ç»Ÿè®¡å®éªŒæ•°é‡å’ŒæˆåŠŸç‡"""
    results = []

    for repo_model in df.groupby(['repository', 'model']):
        repo, model = repo_model[0]
        data = repo_model[1]

        if not repo or not model:
            continue

        total = len(data)
        success_rate = (data['training_success'] == True).sum() / total * 100
        energy_rate = data['energy_cpu_total_joules'].notna().sum() / total * 100

        results.append({
            'repository': repo,
            'model': model,
            'total': total,
            'success_rate': f'{success_rate:.1f}%',
            'energy_coverage': f'{energy_rate:.1f}%'
        })

    return pd.DataFrame(results).sort_values('total', ascending=False)

# ä½¿ç”¨
summary = analyze_by_model(df)
print(summary.to_string(index=False))
```

### ç¤ºä¾‹3: èƒ½è€—åˆ†æ

```python
def analyze_energy_consumption(df, group_by='model'):
    """åˆ†æèƒ½è€—æ¶ˆè€—"""
    df_energy = df[df['energy_cpu_total_joules'].notna()].copy()

    # æŒ‰æ¨¡å‹ç»Ÿè®¡
    stats = df_energy.groupby(group_by).agg({
        'energy_cpu_total_joules': ['mean', 'median', 'std'],
        'energy_gpu_total_joules': ['mean', 'median'],
        'timestamp': 'count'
    }).round(2)

    return stats

# ä½¿ç”¨
energy_stats = analyze_energy_consumption(df, group_by='model')
print(energy_stats)
```

### ç¤ºä¾‹4: ç­›é€‰é«˜è´¨é‡æ•°æ®

```python
def get_high_quality_data(df):
    """è·å–é«˜è´¨é‡æ•°æ®ï¼šè®­ç»ƒæˆåŠŸ + æœ‰èƒ½è€— + æœ‰æ€§èƒ½æŒ‡æ ‡"""
    return df[
        (df['training_success'] == True) &
        (df['energy_cpu_total_joules'].notna()) &
        (df[['col for col in df.columns if col.startswith('perf_')]].notna().any(axis=1))
    ].copy()

df_hq = get_high_quality_data(df)
print(f"é«˜è´¨é‡æ•°æ®: {len(df_hq)}æ¡")
```

---

## å¸¸è§é”™è¯¯ä¸è§£å†³æ–¹æ¡ˆ

### âŒ é”™è¯¯1: ä½¿ç”¨ experiment_id ä½œä¸ºå”¯ä¸€é”®

**é—®é¢˜**: ä¸åŒæ‰¹æ¬¡çš„å®éªŒä¼šäº§ç”Ÿç›¸åŒçš„experiment_id

**é”™è¯¯ä»£ç **:
```python
df_unique = df.drop_duplicates(subset=['experiment_id'])
```

**æ­£ç¡®ä»£ç **:
```python
# âœ… ä½¿ç”¨ timestamp ä½œä¸ºå”¯ä¸€é”®
df_unique = df.drop_duplicates(subset=['timestamp'])

# âœ… æˆ–ä½¿ç”¨å¤åˆé”®
df['composite_key'] = df['experiment_id'] + '|' + df['timestamp']
df_unique = df.drop_duplicates(subset=['composite_key'])
```

### âŒ é”™è¯¯2: ç›´æ¥è¯»å– raw_data.csv ä¸å¤„ç†å¹¶è¡Œæ¨¡å¼

**é—®é¢˜**: å¹¶è¡Œæ¨¡å¼æ•°æ®åœ¨fg_å­—æ®µä¸­ï¼Œç›´æ¥è¯»å–ä¼šé—æ¼

**é”™è¯¯ä»£ç **:
```python
df = pd.read_csv('data/raw_data.csv')
df_resnet = df[df['repository'] == 'pytorch_resnet_cifar10']
# ç»“æœï¼šé—æ¼äº†æ‰€æœ‰å¹¶è¡Œæ¨¡å¼çš„resnetå®éªŒï¼
```

**æ­£ç¡®ä»£ç **:
```python
# âœ… æ–¹æ¡ˆ1ï¼šä½¿ç”¨ data.csv
df = pd.read_csv('data/data.csv')
df_resnet = df[df['repository'] == 'pytorch_resnet_cifar10']

# âœ… æ–¹æ¡ˆ2ï¼šä½¿ç”¨ raw_data.csv + å¤„ç†å‡½æ•°
def get_field(df, row, field_name):
    if row['mode'] == 'parallel':
        fg_field = f'fg_{field_name}'
        return row[fg_field] if fg_field in df.columns else None
    return row[field_name]

df_resnet = df[df.apply(lambda x: get_field(df, x, 'repository') == 'pytorch_resnet_cifar10', axis=1)]
```

### âŒ é”™è¯¯3: è¯¯åˆ¤ç©ºå­—ç¬¦ä¸²ä¸ºç¼ºå¤±å€¼

**é—®é¢˜**: ç©ºå­—ç¬¦ä¸²æ˜¯æœ‰æ•ˆæ•°æ®ï¼Œä¸åº”è¯¥è¢«å½“ä½œç¼ºå¤±å€¼

**é”™è¯¯ä»£ç **:
```python
df_clean = df.replace('', np.nan).dropna()
```

**æ­£ç¡®ä»£ç **:
```python
# âœ… åªåˆ é™¤çœŸæ­£çš„ç¼ºå¤±å€¼
df_clean = df.dropna()
# ç©ºå­—ç¬¦ä¸²ä¼šè¢«ä¿ç•™
```

### âŒ é”™è¯¯4: å¿½ç•¥è®­ç»ƒå¤±è´¥çš„è®°å½•

**é—®é¢˜**: åº”è¯¥æ ¹æ®åˆ†æç›®çš„å†³å®šæ˜¯å¦åŒ…å«å¤±è´¥è®°å½•

**é”™è¯¯ä»£ç **:
```python
df_success = df[df['training_success'] == True]  # æ— æ¡ä»¶è¿‡æ»¤
```

**æ­£ç¡®ä»£ç **:
```python
# âœ… æ ¹æ®åˆ†æç›®çš„é€‰æ‹©
if analysis_type == 'performance_analysis':
    df_filtered = df[df['training_success'] == True]
elif analysis_type == 'success_rate_analysis':
    df_filtered = df  # åŒ…å«å¤±è´¥è®°å½•
```

### âŒ é”™è¯¯5: ä¸éªŒè¯æ•°æ®è´¨é‡å°±å¼€å§‹åˆ†æ

**é—®é¢˜**: åº”è¯¥å…ˆéªŒè¯æ•°æ®è´¨é‡ï¼Œäº†è§£æ•°æ®åˆ†å¸ƒ

**é”™è¯¯ä»£ç **:
```python
df = pd.read_csv('data/data.csv')
model.fit(df[['hyperparam_learning_rate']], df['perf_test_accuracy'])  # ç›´æ¥å»ºæ¨¡
```

**æ­£ç¡®ä»£ç **:
```python
# âœ… å…ˆéªŒè¯æ•°æ®è´¨é‡
df = pd.read_csv('data/data.csv')

# 1. éªŒè¯å”¯ä¸€æ€§
assert df['timestamp'].nunique() == len(df)

# 2. æ£€æŸ¥ç¼ºå¤±å€¼
print(df.isnull().sum())

# 3. ç­›é€‰å¯ç”¨æ•°æ®
df_usable = df[
    (df['training_success'] == True) &
    (df['energy_cpu_total_joules'].notna())
]

print(f"æ•°æ®è´¨é‡: {len(df_usable)}/{len(df)} ({len(df_usable)/len(df)*100:.1f}%)")

# 4. ç„¶åå†å»ºæ¨¡
if len(df_usable) > 100:
    model.fit(df_usable[['hyperparam_learning_rate']], df_usable['perf_test_accuracy'])
```

---

## æ•°æ®è´¨é‡ç°çŠ¶

### æœ€æ–°ç»Ÿè®¡ï¼ˆ2026-01-15æ›´æ–°ï¼‰

#### data.csv æ•°æ®è´¨é‡ âœ… ä¼˜ç§€

- **æ€»è®°å½•æ•°**: 970æ¡ï¼ˆå«headerï¼Œå®é™…969æ¡æ•°æ®ï¼‰
- **âœ… å¯ç”¨è®°å½•**: çº¦818æ¡ (84.3%)
  - è®­ç»ƒæˆåŠŸ: 853æ¡ (88.0%)
  - æœ‰èƒ½è€—æ•°æ®: 828æ¡ (85.4%)
- **æ¨èä½¿ç”¨**: â­â­â­â­â­ 95%çš„åˆ†æä»»åŠ¡

#### raw_data.csv æ•°æ®è´¨é‡ âš ï¸ æ··åˆ

- **æ€»è®°å½•æ•°**: 970æ¡ï¼ˆå«headerï¼Œå®é™…969æ¡æ•°æ®ï¼‰
- **âœ… å®Œå…¨å¯ç”¨è®°å½•**: 577æ¡ (59.5%)
  - è®­ç»ƒæˆåŠŸ + æœ‰èƒ½è€— + æœ‰æ€§èƒ½æŒ‡æ ‡
- **èƒ½è€—æ•°æ®**: 828æ¡ (85.4%)
- **é€‚ç”¨åœºæ™¯**: é«˜çº§åˆ†æã€å®Œæ•´åˆ—è®¿é—®

### æ¨èä½¿ç”¨çš„é«˜è´¨é‡æ•°æ®

**8ä¸ª100%å¯ç”¨æ¨¡å‹** (487æ¡è®°å½•):
- pytorch_resnet_cifar10/resnet20 (53æ¡)
- Person_reIDç³»åˆ—: densenet121, hrnet18, pcb (159æ¡)
- examplesç³»åˆ—: mnist, mnist_rnn, siamese, mnist_ff (275æ¡)

**è¯¦ç»†åˆ†æ**: å‚è§ [docs/DATA_USABILITY_SUMMARY_20260113.md](DATA_USABILITY_SUMMARY_20260113.md)

---

## å‚è€ƒæ–‡æ¡£

### æ ¸å¿ƒæ–‡æ¡£ â­â­â­â­â­

| æ–‡æ¡£ | ç”¨é€” |
|------|------|
| [CLAUDE_FULL_REFERENCE.md](CLAUDE_FULL_REFERENCE.md) | å®Œæ•´é¡¹ç›®å‚è€ƒ |
| [CLAUDE.md](../CLAUDE.md) | 5åˆ†é’Ÿå¿«é€ŸæŒ‡å— |
| [analysis/docs/INDEX.md](../analysis/docs/INDEX.md) | åˆ†ææ¨¡å—æ–‡æ¡£ |

### æ•°æ®è´¨é‡æŠ¥å‘Š

- [docs/results_reports/DATA_REPAIR_REPORT_20260104.md](results_reports/DATA_REPAIR_REPORT_20260104.md) - æ•°æ®å®Œæ•´æ€§ä¿®å¤æŠ¥å‘Š
- [docs/DATA_USABILITY_SUMMARY_20260113.md](DATA_USABILITY_SUMMARY_20260113.md) - æ•°æ®å¯ç”¨æ€§åˆ†æ
- [analysis/docs/DATA_FILES_COMPARISON.md](../analysis/docs/DATA_FILES_COMPARISON.md) - æ–‡ä»¶å¯¹æ¯”åˆ†æ

### æ•°æ®å¤„ç†å·¥å…·

- `tools/data_management/validate_raw_data.py` - éªŒè¯æ•°æ®å®Œæ•´æ€§
- `tools/data_management/analyze_experiment_status.py` - åˆ†æå®éªŒçŠ¶å†µ
- `tools/data_management/analyze_missing_energy_data.py` - åˆ†æç¼ºå¤±èƒ½è€—
- `tools/data_management/repair_missing_energy_data.py` - ä¿®å¤ç¼ºå¤±èƒ½è€—

---

**æ–‡æ¡£ç»´æŠ¤**: æœ¬æ–‡æ¡£åˆå¹¶äº†åŸæœ‰çš„ DATA_MASTER_GUIDE å’Œ RAW_DATA_CSV_USAGE_GUIDE
**å½’æ¡£ä½ç½®**: `archived/DATA_*_GUIDE.md.backup_20260125`
**åˆå¹¶æ—¥æœŸ**: 2026-01-25
**é‡å¤å†…å®¹æ¶ˆé™¤**: çº¦50%

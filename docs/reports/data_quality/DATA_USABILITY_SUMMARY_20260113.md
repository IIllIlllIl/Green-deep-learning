# 数据可用性分析报告

**文档创建日期**: 2026-01-13
**分析对象**: `data/raw_data.csv`
**分析目的**: 评估数据质量，识别可用和不可用记录，为后续数据分析提供指导

---

## 📊 执行摘要

### 总体数据统计

| 指标 | 数值 | 百分比 |
|------|------|--------|
| **总记录数** | 970 | 100% |
| **✅ 可用记录** | 577 | **59.5%** |
| **❌ 不可用记录** | 393 | **40.5%** |

### 数据可用性定义

本分析中，**可用记录**需要满足以下**全部**条件：
1. ✅ **训练成功**: `status = "success"`
2. ✅ **能耗数据完整**: 至少一个 `energy_*` 字段有值
3. ✅ **性能指标完整**: 至少一个 `perf_*` 字段有值

---

## 🔍 不可用数据详细分析

### 1. 不可用原因统计

| 不可用原因 | 记录数 | 占总数 | 占不可用数 |
|-----------|--------|--------|-----------|
| **性能指标缺失** | 393 | 40.5% | **100.0%** |
| **能耗数据缺失** | 142 | 14.6% | 36.1% |
| **训练失败** | 116 | 12.0% | 29.5% |

**关键发现**:
- 🚨 **所有不可用记录都缺失性能指标**（100%）
- ⚡ 36.1%的不可用记录同时缺失能耗数据
- ❌ 29.5%的不可用记录训练失败

### 2. 不可用原因组合分析

共识别出 **3种** 不同的原因组合：

#### 组合1: 仅性能指标缺失 (251条, 63.9%)
- **原因**: 性能指标缺失
- **特点**: 训练成功，有能耗数据，但无性能指标
- **影响模型**: 主要是 VulBERTa 和 bug-localization

#### 组合2: 全部缺失 (116条, 29.5%)
- **原因**: 性能指标缺失 + 能耗数据缺失 + 训练失败
- **特点**: 完全不可用的记录
- **影响模型**: 全部来自模型名为 "/" 的异常记录

#### 组合3: 性能和能耗缺失 (26条, 6.6%)
- **原因**: 性能指标缺失 + 能耗数据缺失
- **特点**: 训练成功但缺失关键数据
- **影响模型**: 主要是 VulBERTa

---

## 🧬 按模型分析可用性

### 模型可用性汇总

| 模型 | 总数 | 可用 | 不可用 | 可用率 |
|------|------|------|--------|--------|
| **pytorch_resnet_cifar10/resnet20** | 53 | 53 | 0 | **100.0%** ✅ |
| **Person_reID_baseline_pytorch/densenet121** | 53 | 53 | 0 | **100.0%** ✅ |
| **Person_reID_baseline_pytorch/hrnet18** | 53 | 53 | 0 | **100.0%** ✅ |
| **Person_reID_baseline_pytorch/pcb** | 53 | 53 | 0 | **100.0%** ✅ |
| **examples/mnist** | 75 | 75 | 0 | **100.0%** ✅ |
| **examples/mnist_rnn** | 58 | 58 | 0 | **100.0%** ✅ |
| **examples/siamese** | 55 | 55 | 0 | **100.0%** ✅ |
| **examples/mnist_ff** | 87 | 87 | 0 | **100.0%** ✅ |
| **MRT-OAST/default** | 85 | 65 | 20 | **76.5%** ⚠️ |
| **bug-localization-by-dnn-and-rvsm/default** | 131 | 25 | 106 | **19.1%** ❌ |
| **VulBERTa/mlp** | 151 | 0 | 151 | **0.0%** ❌ |
| **unknown (/)** | 116 | 0 | 116 | **0.0%** ❌ |

### 关键发现

#### ✅ 完全可用的模型 (8个模型, 487条记录)
- **100%可用率**: pytorch_resnet_cifar10, Person_reID系列, examples系列
- **数据质量**: 优秀，所有记录都包含完整的训练、能耗和性能数据
- **可用于**: 所有类型的数据分析

#### ⚠️ 部分可用的模型 (1个模型, 85条记录)
- **MRT-OAST/default**: 76.5%可用率（65/85）
- **问题**: 20条记录缺失性能指标
- **可用于**: 大部分数据分析，需注意数据完整性

#### ❌ 严重问题的模型 (3个模型, 398条记录)

**1. VulBERTa/mlp (151条记录, 0%可用)**
- **问题**: 全部151条记录缺失性能指标
- **状态**: 训练成功，有能耗数据
- **原因**: 性能指标未被正确记录或提取
- **影响**: 无法用于性能分析，但可用于能耗分析

**2. bug-localization-by-dnn-and-rvsm/default (131条记录, 19.1%可用)**
- **问题**: 106条记录缺失性能指标
- **状态**: 训练成功，大部分有能耗数据（104/106）
- **可用**: 仅25条记录完全可用
- **影响**: 数据可用性严重不足

**3. unknown (/) (116条记录, 0%可用)**
- **问题**: 全部训练失败，模型名称异常
- **状态**: 无性能指标，无能耗数据
- **原因**: 数据质量问题或记录错误
- **影响**: 完全不可用，建议清理

---

## 📂 按模式分析可用性

| 模式 | 总数 | 可用 | 不可用 | 可用率 |
|------|------|------|--------|--------|
| **non-parallel** | 436 | 311 | 125 | **71.3%** ✅ |
| **parallel** | 534 | 266 | 268 | **49.8%** ⚠️ |

### 关键发现
- 📊 **非并行模式**的数据质量明显优于并行模式（71.3% vs 49.8%）
- 🔄 **并行模式**有更高的数据缺失率，可能与并行训练的复杂性有关

---

## ⚠️ 性能指标缺失详细分析

### 总体统计
- **缺失记录数**: 393条 (40.5%)
- **影响**: 所有不可用记录

### 按模型分类

| 模型 | 总缺失 | 训练成功 | 训练失败 | 有能耗 |
|------|--------|---------|---------|--------|
| **VulBERTa/mlp** | 151 | 151 | 0 | 127 |
| **unknown (/)** | 116 | 0 | 116 | 0 |
| **bug-localization-by-dnn-and-rvsm/default** | 106 | 106 | 0 | 104 |
| **MRT-OAST/default** | 20 | 20 | 0 | 20 |

### 关键问题

#### 1. VulBERTa 模型 - 性能指标完全缺失
- **记录数**: 151条
- **问题**: 训练成功，有能耗数据，但**所有性能字段都是空值**
- **检查的字段**: `perf_accuracy`, `perf_test_accuracy`, `perf_map`, `perf_precision`, `perf_recall`, `perf_best_val_accuracy`, `perf_test_loss`, `perf_eval_loss`, `perf_final_training_loss`
- **原因分析**:
  - 性能指标未被正确提取或记录
  - 可能需要检查训练脚本的输出解析逻辑
  - 或者模型输出格式与预期不匹配

#### 2. bug-localization 模型 - 大量性能指标缺失
- **记录数**: 106条缺失 / 131条总数
- **问题**: 训练成功，有能耗数据，但缺失性能指标
- **可用率**: 仅19.1%

---

## 🚨 训练失败详细分析

### 总体统计
- **失败记录数**: 116条 (12.0%)
- **失败率**: 17.7% (基于656条总实验)

### 按模型分类

| 模型 | 失败次数 | 失败率 |
|------|---------|--------|
| **unknown (/)** | 116 | 17.7% |

### 关键问题

#### unknown (/) 模型 - 数据质量问题
- **记录数**: 116条
- **问题**:
  - 模型名称为 "/"，明显的数据异常
  - 全部训练失败
  - 无错误消息记录
- **影响**: 这些记录完全不可用
- **建议**:
  - 调查这些记录的来源
  - 确认是否为测试数据或错误记录
  - 考虑清理这些数据

---

## ⚡ 能耗数据缺失详细分析

### 总体统计
- **缺失记录数**: 142条 (14.6%)

### 按模型分类

| 模型 | 总缺失 | 训练成功 | 训练失败 |
|------|--------|---------|---------|
| **unknown (/)** | 116 | 0 | 116 |
| **VulBERTa/mlp** | 24 | 24 | 0 |
| **bug-localization-by-dnn-and-rvsm/default** | 2 | 2 | 0 |

### 关键问题

#### 1. VulBERTa - 24条记录缺失能耗
- **状态**: 训练成功
- **原因**: 可能是能耗监控工具失败或权限问题

#### 2. bug-localization - 2条记录缺失能耗
- **状态**: 训练成功
- **原因**: 偶发性的能耗监控失败

---

## 💡 数据可用性结论与建议

### 1. 数据质量总体评估

| 评估项 | 状态 | 说明 |
|--------|------|------|
| **可用率** | ⚠️ **59.5%** | 低于预期的95%标准 |
| **数据完整性** | ⚠️ **中等** | 393条记录缺失关键数据 |
| **数据一致性** | ❌ **需改进** | 存在异常记录（模型名为"/"） |

### 2. 与文档描述的差异

**CLAUDE.md 中的描述**:
- 总记录数: 836条
- 有效能耗数据: 795条 (95.1%)

**实际分析结果**:
- 总记录数: 970条
- 完全可用记录: 577条 (59.5%)
- 有能耗数据: 828条 (85.4%)

**差异原因**:
- 数据文件可能包含了测试数据或重复数据
- 116条 unknown (/) 记录可能是异常数据
- 性能指标缺失被包含在统计中

### 3. 可用于分析的数据

#### ✅ 推荐用于分析的数据 (487条)
**8个模型100%可用**:
- pytorch_resnet_cifar10/resnet20 (53条)
- Person_reID_baseline_pytorch系列 (159条)
- examples系列 (275条)

**特点**:
- 数据完整性极高
- 适合所有类型的分析
- 可作为高质量数据集的基准

#### ⚠️ 谨慎使用的数据 (90条)
- MRT-OAST/default: 65条可用 / 85条总数

**注意事项**:
- 需要检查数据完整性
- 部分分析可能受影响

#### ❌ 不推荐用于分析的数据 (393条)
- VulBERTa/mlp: 151条（仅能耗分析可用）
- bug-localization: 106条（数据不完整）
- unknown (/): 116条（完全不可用）

### 4. 优先级修复建议

#### 🔴 P0 - 关键问题（立即处理）

1. **清理异常数据**
   - 调查并清理 116条 unknown (/) 记录
   - 确认这些记录的来源和用途
   - 如果是测试数据，应移至单独的测试数据集

2. **修复 VulBERTa 性能指标缺失**
   - 检查训练脚本的性能指标输出
   - 修复性能指标提取逻辑
   - 重新运行实验或从日志中恢复数据

#### 🟡 P1 - 重要问题（尽快处理）

3. **修复 bug-localization 性能指标**
   - 分析 106条缺失记录的原因
   - 从日志或结果文件中恢复数据
   - 如果无法恢复，考虑重新运行实验

4. **修复能耗数据缺失**
   - 修复 VulBERTa 的24条能耗数据缺失
   - 检查能耗监控工具的权限和配置

#### 🟢 P2 - 改进建议（长期优化）

5. **提升并行模式数据质量**
   - 调查并行模式数据质量较低的原因
   - 优化并行训练的数据收集流程

6. **建立数据质量监控**
   - 在实验运行时实时检查数据完整性
   - 及时发现并修复数据缺失问题

### 5. 数据使用建议

#### 方案A: 保守分析（推荐）
- **使用数据**: 仅使用8个100%可用的模型（487条记录）
- **优点**: 数据质量最高，结果最可靠
- **缺点**: 样本量较小，模型覆盖不全

#### 方案B: 平衡分析
- **使用数据**: 8个100%可用模型 + MRT-OAST可用部分（552条记录）
- **优点**: 平衡了数据质量和样本量
- **适用**: 大部分分析场景

#### 方案C: 最大化分析
- **使用数据**: 所有577条可用记录
- **优点**: 最大化样本量和模型覆盖
- **缺点**: 需要注意数据质量差异
- **适用**: 探索性分析

#### 方案D: 专项分析
- **能耗分析**: 使用所有有能耗数据的记录（828条）
- **性能分析**: 仅使用有性能指标的记录（577条）
- **优点**: 针对性强
- **适用**: 特定研究问题

---

## 📎 附录

### 生成的报告文件

1. **data_usability_report.txt** (236行)
   - 完整的数据可用性分析报告
   - 包含详细的统计数据和示例

2. **unusable_reasons_detail_report.txt** (145行)
   - 不可用数据的深入分析
   - 按模型分类的详细原因

### 分析脚本

1. **analyze_data_usability.py**
   - 数据可用性分析脚本
   - 生成可用性统计和不可用原因分类

2. **analyze_unusable_reasons.py**
   - 不可用数据深入分析脚本
   - 专注于性能指标缺失、训练失败和能耗缺失的详细分析

### 下一步行动

1. ✅ 查看生成的详细报告
2. ⏳ 清理异常数据（unknown / 记录）
3. ⏳ 修复 VulBERTa 性能指标缺失
4. ⏳ 修复 bug-localization 性能指标缺失
5. ⏳ 修复能耗数据缺失
6. ⏳ 更新 CLAUDE.md 中的数据说明
7. ⏳ 基于可用数据开始分析工作

---

**文档创建**: 2026-01-13
**分析工具**: `analyze_data_usability.py`, `analyze_unusable_reasons.py`
**数据源**: `data/raw_data.csv`
**报告版本**: 1.0

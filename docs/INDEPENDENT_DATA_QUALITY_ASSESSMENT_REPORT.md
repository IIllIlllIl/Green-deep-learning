# 独立数据质量评估报告

**评估日期**: 2026-01-14
**评估对象**: `/home/green/energy_dl/nightly/data/raw_data.csv`
**评估方法**: 完全独立分析，不参考任何已有报告

---

## 执行摘要

本次独立评估对能耗研究项目的主数据文件进行了全面的质量分析。评估结果显示数据集包含1225条实验记录，其中**812条（72.50%）完全可用**，可用于综合分析。主要发现：

### 关键指标

| 指标 | 数值 | 状态 |
|------|------|------|
| **总记录数** | 1,225条 | ✅ |
| **前台训练记录** | 1,120条 | ✅ |
| **完全可用记录** | 812条 (72.50%) | ⚠️ |
| **训练成功率** | 97.50% | ✅ 优秀 |
| **能耗数据完整性** | 97.68% | ✅ 优秀 |
| **性能指标完整性** | 74.29% | ⚠️ 需改进 |

### 核心发现

✅ **优势**:
- 训练成功率极高（97.50%）
- 能耗数据完整性优秀（97.68%）
- 4个模型达到100%数据可用率

⚠️ **问题**:
- 性能指标缺失是主要瓶颈（25.71%记录缺失）
- 3个模型（VulBERTa/mlp, bug-localization, examples/mnist_ff）有系统性性能指标缺失
- 105条记录存在异常模型标识（"/"）

---

## 1. 数据集基本信息

### 1.1 规模统计

```
总记录数（含header）: 1,226
实际数据记录数: 1,225
总列数: 87
后台训练记录（fg_*字段）: 418条
```

### 1.2 数据结构

数据包含以下主要字段类别：

| 类别 | 字段数 | 关键字段示例 |
|------|--------|-------------|
| 实验元数据 | 7 | experiment_id, timestamp, repository, model |
| 训练状态 | 3 | training_success, duration_seconds, retries |
| 超参数 | 9 | batch_size, learning_rate, epochs, dropout |
| 性能指标 | 16 | perf_accuracy, perf_test_accuracy, perf_map |
| 能耗数据 | 12 | energy_cpu_total_joules, energy_gpu_total_joules |
| 前台训练(fg_*) | 38 | fg_repository, fg_training_success, fg_energy_* |
| 后台训练(bg_*) | 2 | bg_repository, bg_model |

---

## 2. 关键字段完整性分析

### 2.1 核心字段缺失统计

| 字段类别 | 字段名 | 非空数 | 缺失数 | 缺失率 |
|---------|--------|--------|--------|--------|
| **模型标识** | repository | 1,120 | 105 | 8.57% |
| **模型标识** | model | 1,120 | 105 | 8.57% |
| **训练状态** | training_success | 1,120 | 105 | 8.57% |
| **能耗数据** | energy_cpu_total_joules | 1,094 | 131 | 10.69% |
| **能耗数据** | energy_gpu_total_joules | 1,094 | 131 | 10.69% |

### 2.2 性能指标字段缺失统计

性能指标字段普遍存在较高的缺失率：

| 性能指标字段 | 非空数 | 缺失数 | 缺失率 |
|-------------|--------|--------|--------|
| perf_test_accuracy | 392 | 833 | 68.00% |
| perf_map | 183 | 1,042 | 85.06% |
| perf_rank1 | 183 | 1,042 | 85.06% |
| perf_rank5 | 183 | 1,042 | 85.06% |
| perf_accuracy | 69 | 1,156 | 94.37% |
| perf_precision | 75 | 1,150 | 93.88% |
| perf_recall | 75 | 1,150 | 93.88% |
| perf_test_loss | 92 | 1,133 | 92.49% |
| perf_top1_accuracy | 90 | 1,135 | 92.65% |

**说明**: 不同模型使用不同的性能指标。例如：
- Person_reID 模型使用 perf_map, perf_rank1, perf_rank5
- examples 模型使用 perf_test_accuracy, perf_test_loss
- ResNet 模型使用 perf_test_accuracy
- MRT-OAST 使用 perf_precision, perf_recall

因此，单个字段的高缺失率不代表记录没有性能指标。**关键是检查每条记录是否至少有一个性能指标有效值。**

---

## 3. 模型分布分析

### 3.1 模型记录数统计

数据集覆盖12个不同的模型组合（repository/model）：

| 排名 | 模型 | 记录数 | 占比 |
|-----|------|--------|------|
| 1 | VulBERTa/mlp | 164 | 13.39% |
| 2 | bug-localization-by-dnn-and-rvsm/default | 149 | 12.16% |
| 3 | examples/mnist_ff | 107 | 8.73% |
| 4 | MRT-OAST/default | 105 | 8.57% |
| 5 | **//（异常）** | **105** | **8.57%** ⚠️ |
| 6 | pytorch_resnet_cifar10/resnet20 | 87 | 7.10% |
| 7 | Person_reID_baseline_pytorch/densenet121 | 87 | 7.10% |
| 8 | Person_reID_baseline_pytorch/hrnet18 | 87 | 7.10% |
| 9 | Person_reID_baseline_pytorch/pcb | 87 | 7.10% |
| 10 | examples/mnist | 85 | 6.94% |
| 11 | examples/siamese | 81 | 6.61% |
| 12 | examples/mnist_rnn | 81 | 6.61% |

**⚠️ 异常**: 105条记录的模型标识为 "//"，这是异常数据，需要清理或修复。

---

## 4. 训练成功率分析

### 4.1 前台训练成功率

```
总前台训练记录: 1,120条
训练成功: 1,092条 (97.50%)
训练失败: 28条 (2.50%)
```

**✅ 评价**: 训练成功率极高，说明实验环境稳定，配置合理。

### 4.2 后台训练成功率

```
总后台训练记录 (fg_*): 418条
训练成功: 418条 (100.00%)
```

**说明**: 后台训练（parallel模式的foreground部分）全部成功。

---

## 5. 能耗数据完整性分析

### 5.1 前台训练能耗数据

```
总记录数: 1,120条
有能耗数据: 1,094条 (97.68%)
缺失能耗: 26条 (2.32%)
```

**✅ 评价**: 能耗数据完整性优秀，仅2.32%缺失。

### 5.2 按模型统计能耗数据完整性

| 模型 | 总数 | 有能耗 | 缺失 | 缺失率 |
|------|-----|--------|------|--------|
| **VulBERTa/mlp** | 164 | 140 | 24 | **14.63%** ⚠️ |
| bug-localization-by-dnn-and-rvsm/default | 149 | 147 | 2 | 1.34% |
| MRT-OAST/default | 105 | 105 | 0 | 0.00% ✅ |
| Person_reID_baseline_pytorch/* (3个模型) | 261 | 261 | 0 | 0.00% ✅ |
| examples/* (4个模型) | 354 | 354 | 0 | 0.00% ✅ |
| pytorch_resnet_cifar10/resnet20 | 87 | 87 | 0 | 0.00% ✅ |

**发现**:
- VulBERTa/mlp 有最高的能耗数据缺失率（14.63%）
- 其他8个模型的能耗数据完整性为100%或接近100%

---

## 6. 性能指标完整性分析

### 6.1 整体性能指标完整性

```
总记录数: 1,120条
有性能指标: 832条 (74.29%)
缺失性能指标: 288条 (25.71%)
```

**⚠️ 评价**: 性能指标缺失是数据质量的主要瓶颈。

### 6.2 按模型统计性能指标完整性

| 模型 | 总数 | 有指标 | 缺失 | 缺失率 |
|------|-----|--------|------|--------|
| **VulBERTa/mlp** | 164 | 92 | 72 | **43.90%** ❌ |
| **bug-localization-by-dnn-and-rvsm/default** | 149 | 90 | 59 | **39.60%** ❌ |
| **examples/mnist_ff** | 107 | 58 | 49 | **45.79%** ❌ |
| **MRT-OAST/default** | 105 | 75 | 30 | **28.57%** ⚠️ |
| Person_reID_baseline_pytorch/densenet121 | 87 | 61 | 26 | 29.89% |
| Person_reID_baseline_pytorch/hrnet18 | 87 | 61 | 26 | 29.89% |
| Person_reID_baseline_pytorch/pcb | 87 | 61 | 26 | 29.89% |
| **examples/mnist** | 85 | 85 | 0 | **0.00%** ✅ |
| **examples/mnist_rnn** | 81 | 81 | 0 | **0.00%** ✅ |
| **examples/siamese** | 81 | 81 | 0 | **0.00%** ✅ |
| **pytorch_resnet_cifar10/resnet20** | 87 | 87 | 0 | **0.00%** ✅ |

**关键发现**:
- **4个模型达到100%性能指标完整性**（mnist, mnist_rnn, siamese, resnet20）
- **3个模型性能指标缺失超过39%**（VulBERTa, bug-localization, mnist_ff）- 这是数据质量的主要问题

---

## 7. 数据可用性综合分析

### 7.1 可用性定义

本评估定义"完全可用记录"需同时满足以下三个条件：

1. ✅ **training_success = True**（训练成功）
2. ✅ **有能耗数据**（CPU或GPU至少一个有效值）
3. ✅ **有性能指标**（至少一个性能指标字段有有效值）

### 7.2 整体可用性

```
总前台记录数: 1,120条
✅ 完全可用: 812条 (72.50%)
❌ 不可用: 308条 (27.50%)
```

### 7.3 不可用原因详细分析

#### 主要原因统计

| 不可用原因 | 记录数 | 占总记录比例 |
|-----------|--------|------------|
| 训练失败 | 28 | 2.50% |
| 缺失能耗数据（训练成功） | 26 | 2.32% |
| **缺失性能指标（训练成功）** | **260** | **23.21%** ❌ |

#### 组合问题分析（仅统计训练成功的记录）

在1,092条训练成功的记录中：

| 问题组合 | 记录数 | 占训练成功记录比例 |
|---------|--------|------------------|
| 仅缺能耗 | 20 | 1.83% |
| **仅缺性能指标** | **254** | **23.26%** ❌ |
| 能耗和性能指标都缺 | 6 | 0.55% |

**核心结论**: **性能指标缺失是数据不可用的主要原因**，占所有不可用记录的82.5%（254/308）。

---

## 8. 按模型可用性分析

### 8.1 模型可用性排名

| 排名 | 模型 | 总数 | 可用 | 不可用 | 可用率 | 评级 |
|-----|------|-----|------|--------|--------|------|
| 1 | pytorch_resnet_cifar10/resnet20 | 87 | 87 | 0 | **100.00%** | ⭐⭐⭐ |
| 2 | examples/mnist | 85 | 85 | 0 | **100.00%** | ⭐⭐⭐ |
| 3 | examples/mnist_rnn | 81 | 81 | 0 | **100.00%** | ⭐⭐⭐ |
| 4 | examples/siamese | 81 | 81 | 0 | **100.00%** | ⭐⭐⭐ |
| 5 | MRT-OAST/default | 105 | 75 | 30 | 71.43% | ⭐⭐ |
| 6 | Person_reID_baseline_pytorch/densenet121 | 87 | 61 | 26 | 70.11% | ⭐⭐ |
| 7 | Person_reID_baseline_pytorch/hrnet18 | 87 | 61 | 26 | 70.11% | ⭐⭐ |
| 8 | Person_reID_baseline_pytorch/pcb | 87 | 61 | 26 | 70.11% | ⭐⭐ |
| 9 | bug-localization-by-dnn-and-rvsm/default | 149 | 90 | 59 | 60.40% | ⭐ |
| 10 | examples/mnist_ff | 107 | 58 | 49 | 54.21% | ⭐ |
| 11 | **VulBERTa/mlp** | 164 | 72 | 92 | **43.90%** | ❌ |

### 8.2 高质量模型（100%可用率）

✅ **4个模型达到100%数据可用率**，共计**334条高质量记录**：

1. **pytorch_resnet_cifar10/resnet20**: 87条
2. **examples/mnist**: 85条
3. **examples/mnist_rnn**: 81条
4. **examples/siamese**: 81条

**推荐**: 这些模型的数据适合用于高精度分析和论文发表。

---

## 9. 异常数据识别

### 9.1 异常模式统计

| 异常模式 | 数量 | 占比 | 严重程度 |
|---------|------|------|---------|
| 1. 空模型名或'/'模型 | 105 | 8.57% | P2 |
| 2. 训练成功但无能耗数据 | 26 | 2.32% | P1 |
| 3. **训练成功但无性能指标** | **260** | **23.21%** | **P0** ❌ |
| 4. 训练失败但有能耗数据 | 28 | 2.50% | P2（正常） |

### 9.2 训练持续时间异常检测

```
平均持续时间: 1,882.12秒 (31.37分钟)
中位数: 1,081.98秒 (18.03分钟)
最小值: 7.21秒
最大值: 9,968.05秒 (2.77小时)

异常检测:
  - 异常短(<1分钟): 111条 (9.91%)
  - 异常长(>2.78小时): 0条
```

**说明**: 111条记录的训练时间少于1分钟，可能是快速测试或早期失败，需进一步检查。

---

## 10. 数据质量问题总结

根据独立评估，识别出**3个主要数据质量问题**，按优先级排序：

### P0 - 严重问题（必须立即处理）

#### 问题1: 性能指标大量缺失

- **影响记录**: 254条（22.68%的前台记录）
- **受影响模型**: VulBERTa/mlp (72条), bug-localization (59条), mnist_ff (49条), MRT-OAST (30条), Person_reID系列 (78条)
- **影响程度**: **严重** - 直接导致数据不可用，无法进行性能分析
- **根本原因**: 代码中性能指标收集逻辑缺失或失败，但训练本身成功完成
- **修复可行性**: **困难** - 需要：
  1. 检查实验日志是否有性能输出
  2. 如果日志有数据，可以编写脚本提取
  3. 如果日志无数据，需要修复代码并重新运行实验
  4. 或在分析中排除这些记录

---

### P1 - 重要问题（应尽快处理）

#### 问题2: 能耗数据缺失

- **影响记录**: 20条（1.79%的前台记录）- 仅缺能耗，有性能指标
- **受影响模型**: 主要是 VulBERTa/mlp
- **影响程度**: **中等** - 影响能耗分析，但不影响性能分析
- **根本原因**: perf权限问题或能耗监控工具故障
- **修复可行性**: **中等** - 可能可以：
  1. 检查 `recoverable_energy_data.json` 文件
  2. 使用现有的 `repair_missing_energy_data.py` 脚本修复
  3. 如果无法恢复，在能耗分析中排除这些记录

#### 问题3: 训练失败率

- **影响记录**: 28条（2.50%的前台记录）
- **影响程度**: **中等** - 失败率相对较低，但仍需了解原因
- **修复可行性**: **中等** - 需要：
  1. 分析 `error_message` 字段
  2. 按错误类型分类
  3. 修复可修复的错误
  4. 对无法修复的，在分析中排除

---

### P2 - 次要问题（低优先级）

#### 问题4: 异常模型标识

- **影响记录**: 105条（8.57%的总记录）
- **问题描述**: 模型标识为 "/"，缺少 repository 和 model 信息
- **影响程度**: **低** - 这些记录可能是并行训练的后台记录（bg_*字段）
- **修复可行性**: **容易** - 可以：
  1. 检查这些记录是否有bg_*或fg_*字段的有效数据
  2. 如果有，可以保留用于并行分析
  3. 如果无价值，标记为无效记录

---

## 11. 修复建议（按优先级）

### 🔴 P0 修复建议

#### 建议1: 修复性能指标缺失问题

**目标**: 恢复254条训练成功但缺失性能指标的记录

**具体步骤**:

1. **第一阶段：诊断问题**
   ```bash
   # 检查受影响实验的日志目录
   ls -lh results/run_*/*/experiment.log

   # 搜索日志中的性能输出关键词
   grep -r "accuracy\|precision\|recall\|mAP" results/run_*/ | head -20
   ```

2. **第二阶段：识别系统性问题**
   - 检查 VulBERTa/mlp 的代码，确认是否输出性能指标
   - 检查 bug-localization 的代码，确认性能指标收集逻辑
   - 检查 mnist_ff 的代码，确认是否有性能评估步骤

3. **第三阶段：数据恢复**
   - 选项A（推荐）：如果日志有性能数据
     ```python
     # 编写脚本从日志中提取性能指标
     # 示例: extract_performance_from_logs.py
     ```
   - 选项B：如果日志无数据，修复代码并重新运行关键实验
   - 选项C：在分析中排除这些模型，使用其他8个高质量模型

**预期效果**:
- 选项A: 可能恢复50-100%的记录（取决于日志完整性）
- 选项B: 100%恢复但成本高（需要重新运行254个实验）
- 选项C: 数据可用率从72.50%提升到接近100%（仅使用高质量模型）

**推荐方案**: 先尝试选项A（日志提取），如果失败则采用选项C（排除法）

---

### 🟡 P1 修复建议

#### 建议2: 恢复能耗数据

**目标**: 恢复20条缺失能耗数据的记录

**具体步骤**:

1. **检查可恢复数据文件**
   ```bash
   # 检查是否存在recoverable数据
   ls -lh data/recoverable_energy_data.json
   cat data/recoverable_energy_data.json | python3 -m json.tool | head -50
   ```

2. **使用现有修复脚本**
   ```bash
   # 备份当前数据
   cp data/raw_data.csv data/raw_data.csv.backup_$(date +%Y%m%d_%H%M%S)

   # 运行修复脚本
   python3 tools/data_management/repair_missing_energy_data.py --dry-run
   python3 tools/data_management/repair_missing_energy_data.py
   ```

3. **验证修复结果**
   ```bash
   # 验证数据完整性
   python3 tools/data_management/validate_raw_data.py
   ```

**预期效果**: 可能恢复5-20条记录的能耗数据（取决于recoverable文件的覆盖范围）

---

#### 建议3: 分析训练失败原因

**目标**: 理解28条训练失败记录的原因

**具体步骤**:

1. **收集失败信息**
   ```python
   import pandas as pd
   df = pd.read_csv('data/raw_data.csv')
   failed = df[df['training_success'] != True]
   print(failed['error_message'].value_counts())
   ```

2. **按错误类型分类**
   - 配置错误（可修复）
   - 依赖缺失（可修复）
   - 数据问题（可修复）
   - 代码bug（需要调试）
   - 不可避免的失败（接受）

3. **记录分析结果**
   - 创建失败原因分类报告
   - 对于可修复的，提供修复方案
   - 对于不可修复的，在分析中排除

**预期效果**: 理解失败原因，可能修复部分可修复的错误

---

### 🟢 P2 修复建议

#### 建议4: 清理异常数据

**目标**: 处理105条异常模型标识记录

**具体步骤**:

1. **检查这些记录的实际内容**
   ```python
   import pandas as pd
   df = pd.read_csv('data/raw_data.csv')
   anomalous = df[df['model_id'] == '//']

   # 检查是否有fg_*或bg_*字段数据
   print(anomalous[['fg_repository', 'fg_model', 'bg_repository', 'bg_model']].head(10))
   ```

2. **决定处理策略**
   - 如果是并行训练的后台记录：保留（用于并行模式分析）
   - 如果是数据错误：标记为invalid
   - 如果无价值：考虑从分析数据集中排除

3. **创建清洗后的数据集**
   ```bash
   # 选项：创建一个仅包含有效记录的数据集
   python3 create_clean_dataset.py --input raw_data.csv --output clean_data.csv
   ```

**预期效果**: 数据集更加整洁，便于分析

---

## 12. 数据使用建议

根据独立评估结果，推荐以下数据使用策略：

### 📊 策略1: 高质量数据集（推荐用于论文发表）

**数据范围**: 仅使用100%可用率的4个模型

| 指标 | 数值 |
|------|------|
| 模型数 | 4个 |
| 记录数 | 334条 |
| 数据可用率 | 100.00% |
| 模型列表 | pytorch_resnet_cifar10/resnet20 (87条)<br>examples/mnist (85条)<br>examples/mnist_rnn (81条)<br>examples/siamese (81条) |

**优点**:
- ✅ 数据完整，零缺失
- ✅ 结果高度可靠
- ✅ 适合发表论文
- ✅ 涵盖CNN、RNN、Siamese网络等多种架构

**缺点**:
- ⚠️ 样本量相对较小
- ⚠️ 模型覆盖有限（缺少Transformer、NLP模型等）

**推荐场景**: 高精度因果分析、论文发表、可重复性验证

---

### 📊 策略2: 平衡数据集（推荐用于一般研究）

**数据范围**: 使用可用率≥70%的7个模型

| 指标 | 数值 |
|------|------|
| 模型数 | 7个 |
| 可用记录数 | 595条 |
| 平均可用率 | 85.17% |
| 额外模型 | MRT-OAST/default (75条, 71.43%)<br>Person_reID_baseline_pytorch/* (183条, 70.11%) |

**优点**:
- ✅ 样本量较大（595条）
- ✅ 模型覆盖更广（加入缺陷定位、行人重识别任务）
- ✅ 数据质量可接受（>70%可用率）
- ✅ 平衡了质量和覆盖面

**缺点**:
- ⚠️ 部分记录不完整（需要在分析中处理）

**推荐场景**: 综合能耗分析、跨任务比较、探索性研究

---

### 📊 策略3: 最大化数据集（用于探索性分析）

**数据范围**: 使用所有可用记录

| 指标 | 数值 |
|------|------|
| 模型数 | 11个（排除异常的"/"） |
| 可用记录数 | 812条 |
| 平均可用率 | 72.50% |
| 额外模型 | bug-localization (90条, 60.40%)<br>examples/mnist_ff (58条, 54.21%)<br>VulBERTa/mlp (72条, 43.90%) |

**优点**:
- ✅ 样本量最大（812条）
- ✅ 模型覆盖最全（11个不同任务）
- ✅ 可以进行更广泛的探索

**缺点**:
- ⚠️ 数据质量参差不齐
- ⚠️ 部分模型可用率较低（<60%）
- ⚠️ 需要仔细处理缺失数据

**推荐场景**: 初步探索、趋势发现、假设生成

---

### 📊 策略4: 特定分析数据集

根据具体研究问题选择合适的数据子集：

| 研究目标 | 推荐数据集 | 记录数 | 说明 |
|---------|-----------|--------|------|
| **能耗专项分析** | 有能耗数据的记录 | 1,094条 | 97.68%完整性，适合能耗建模 |
| **性能专项分析** | 有性能指标的记录 | 832条 | 适合性能优化研究 |
| **综合因果分析** | 完全可用的记录 | 812条 | 同时有能耗和性能，适合因果推断 |
| **并行模式分析** | 有fg_*字段的记录 | 418条 | 研究并行训练的能耗开销 |

---

### 🎯 推荐使用策略总结

根据研究目标选择合适的策略：

| 研究目标 | 推荐策略 | 预期结果质量 |
|---------|---------|-------------|
| **论文发表 - 因果推断** | 策略1（高质量） | ⭐⭐⭐⭐⭐ |
| **论文发表 - 综合分析** | 策略2（平衡） | ⭐⭐⭐⭐ |
| **探索性研究** | 策略3（最大化） | ⭐⭐⭐ |
| **能耗建模** | 策略4（能耗专项） | ⭐⭐⭐⭐ |
| **性能优化研究** | 策略4（性能专项） | ⭐⭐⭐⭐ |

---

## 13. 关键发现总结

### ✅ 数据集优势

1. **高训练成功率**: 97.50%的实验训练成功，说明实验流程稳定
2. **优秀的能耗数据**: 97.68%的记录有能耗数据，适合能耗分析
3. **存在高质量子集**: 4个模型达到100%数据可用率（334条记录）
4. **样本量充足**: 总计812条完全可用记录，足够进行统计分析

### ⚠️ 主要问题

1. **性能指标缺失是最大瓶颈**: 25.71%的记录缺失性能指标，直接导致数据不可用
2. **模型间质量差异大**: 可用率从43.90%到100%不等
3. **3个模型有系统性问题**: VulBERTa/mlp, bug-localization, mnist_ff 的性能指标缺失率>39%
4. **存在异常数据**: 105条记录的模型标识异常

### 🎯 核心建议

1. **优先修复性能指标缺失问题**（P0）- 这是提升数据可用性的关键
2. **采用分层分析策略**:
   - 高质量分析：使用334条100%可用的记录
   - 一般分析：使用595条≥70%可用率的记录
   - 探索性分析：使用所有812条可用记录
3. **记录数据质量限制**：在分析报告中明确说明使用的数据范围和质量限制
4. **建立数据质量监控**：在未来实验中加强性能指标收集的监控和验证

---

## 14. 附录

### A. 评估方法说明

本次评估采用以下方法：

1. **独立性**: 不参考任何已有分析报告，仅基于原始CSV数据
2. **全面性**: 分析了所有87个字段和1,225条记录
3. **客观性**: 使用明确的数学标准定义"可用记录"
4. **系统性**: 从基本统计、字段完整性、模型分布、可用性等多个维度分析

### B. 可用性判定标准

```python
def is_usable_record(row):
    """
    可用记录必须同时满足：
    1. training_success = True
    2. 至少有一个能耗字段有有效值（energy_cpu_total_joules 或 energy_gpu_total_joules）
    3. 至少有一个性能指标字段有有效值（perf_* 开头的16个字段之一）
    """
    training_success = row['training_success'] in [True, 'True']
    has_energy = (pd.notna(row['energy_cpu_total_joules']) and row['energy_cpu_total_joules'] not in ['', 'N/A']) or \
                 (pd.notna(row['energy_gpu_total_joules']) and row['energy_gpu_total_joules'] not in ['', 'N/A'])
    has_perf = any(pd.notna(row[col]) and row[col] not in ['', 'N/A'] for col in perf_columns)
    return training_success and has_energy and has_perf
```

### C. 与项目文档的差异说明

**重要**: 本报告的统计数据可能与项目中其他文档不同，原因包括：

1. **数据版本差异**: 本评估基于2026-01-14的数据快照
2. **定义差异**: 不同文档可能使用不同的"可用性"定义
3. **分析范围差异**: 本评估仅分析前台训练记录（repository不为空的记录）

如有差异，请以本独立评估报告为准。

---

**报告生成时间**: 2026-01-14
**评估者**: Independent Quality Assessment System
**数据文件**: /home/green/energy_dl/nightly/data/raw_data.csv
**评估脚本**: independent_data_quality_assessment.py

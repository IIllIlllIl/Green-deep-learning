# 分层抽样策略详解
# Stratified Sampling Strategies for Concurrent Training Study

**文档日期**: 2025-11-11
**研究背景**: 并发训练超参数影响研究 - 模型组合选取

---

## 📋 分层抽样基本原理

### 什么是分层抽样？

**定义**: 将总体按某种标准划分为若干层（strata），然后从每层中独立抽取样本。

**核心思想**:
- **层内相似**: 同一层内的个体相似度高
- **层间差异**: 不同层之间差异大
- **按比例抽样**: 每层抽取的样本数与该层占总体的比例相关

**优势**:
- ✅ 保证各类型都有代表
- ✅ 提高样本代表性
- ✅ 减少抽样误差
- ✅ 便于分组对比分析

---

## 🎯 8种分层策略详解

### 策略1: 按显存占用分层 ⭐⭐⭐⭐⭐

#### 分层标准

| 层级 | 显存范围 | 说明 | 样本数 |
|------|----------|------|--------|
| **超低显存层** | <1.5GB | 两个小模型，极安全 | 9个 |
| **低显存层** | 1.5-3GB | 一大一小或两中等，安全 | 67个 |
| **中显存层** | 3-5GB | 一大一中，可接受 | 40个 |
| **高显存层** | 5-7GB | 接近上限，需谨慎 | 4个 |
| **极高显存层** | >7GB | 超过安全界限 | 0个 |

#### 抽样方案（12个）

```
超低显存层: 2个 (占比 9/120 ≈ 7.5% → 抽 2/12 ≈ 17%)
低显存层:   4个 (占比 67/120 ≈ 56% → 抽 4/12 ≈ 33%)
中显存层:   4个 (占比 40/120 ≈ 33% → 抽 4/12 ≈ 33%)
高显存层:   2个 (占比 4/120 ≈ 3% → 抽 2/12 ≈ 17%)
```

#### 适用场景
- ✅ 资源受限，避免OOM
- ✅ 研究显存对并发效率的影响
- ✅ 硬件约束明确的场景

#### 示例组合
- **超低**: MNIST + MNIST FF (900MB)
- **低**: MNIST + ResNet44 (1530MB)
- **中**: MNIST + DenseNet121 (3750MB)
- **高**: DenseNet121 + HRNet18 (5550MB)

---

### 策略2: 按GPU利用率分层 ⭐⭐⭐⭐

#### 分层标准

| 层级 | GPU利用率 | 说明 | 样本数 |
|------|-----------|------|--------|
| **低竞争层** | <80% | GPU充裕，几乎无竞争 | 13个 |
| **中竞争层** | 80-120% | 适度竞争，可接受 | 80个 |
| **高竞争层** | 120-150% | 明显竞争，相互拖慢 | 26个 |
| **极高竞争层** | >150% | 严重竞争，效率低 | 1个 |

#### 抽样方案（12个）

```
低竞争层:   4个
中竞争层:   5个
高竞争层:   2个
极高竞争层: 1个
```

#### 适用场景
- ✅ 研究GPU算力竞争影响
- ✅ 性能优化场景
- ✅ 了解并发开销

#### 示例组合
- **低竞争**: MNIST + MNIST RNN (62%)
- **中竞争**: MNIST + DenseNet121 (84%)
- **高竞争**: MRT-OAST + HRNet18 (143%)
- **极高竞争**: DenseNet121 + MRT-OAST (165%)

---

### 策略3: 按训练时长分层 ⭐⭐⭐

#### 分层标准

| 层级 | 平均时长 | 说明 | 样本数 |
|------|----------|------|--------|
| **快速层** | <500s | 快速验证，适合大量测试 | 48个 |
| **中速层** | 500-1500s | 平衡速度和代表性 | 68个 |
| **慢速层** | 1500-3000s | 大模型，时间长 | 4个 |
| **极慢层** | >3000s | 超长训练，资源密集 | 0个 |

#### 抽样方案（12个）

```
快速层: 4个
中速层: 5个
慢速层: 3个
```

#### 适用场景
- ✅ 时间敏感的研究
- ✅ 需要快速迭代验证
- ✅ 实验时间预算有限

#### 优缺点
- ✅ 便于时间管理和资源调度
- ❌ 与研究核心问题关联较弱
- ❌ 可能偏向某些模型类型

---

### 策略4: 按应用领域分层 ⭐⭐⭐⭐

#### 分层标准

| 层级 | 领域组合 | 说明 | 样本数 |
|------|----------|------|--------|
| **vision + vision** | 视觉+视觉 | 同领域，数据模式相似 | 66个 |
| **code + vision** | 代码+视觉 | 跨领域，互补 | 36个 |
| **nlp + vision** | NLP+视觉 | 跨领域，I/O不同 | 12个 |
| **code + code** | 代码+代码 | 同领域 | 3个 |
| **code + nlp** | 代码+NLP | 跨领域 | 3个 |

#### 抽样方案（12个）

```
vision+vision: 8个 (覆盖主要场景)
code+vision:   2个 (跨领域代表)
nlp+vision:    1个 (跨领域代表)
code+code:     1个 (小众场景)
```

#### 适用场景
- ✅ 研究结果的泛化性
- ✅ 探索跨领域并发特性
- ✅ 多样化应用场景

#### 示例组合
- **vision+vision**: MNIST + ResNet20, DenseNet121 + HRNet18
- **code+vision**: VulBERTa + MNIST, Bug-Loc + ResNet44
- **nlp+vision**: Word LM + MNIST

---

### 策略5: 按互补性分层 ⭐⭐⭐⭐⭐

#### 互补性定义

```
互补分数 = |GPU_util_A - GPU_util_B| / 100
```

#### 分层标准

| 层级 | 互补分数 | GPU利用率特征 | 说明 | 样本数 |
|------|----------|--------------|------|--------|
| **高度互补层** | >0.6 | 一高(>70%)一低(<30%) | 最优配对 | 1个 |
| **中度互补层** | 0.3-0.6 | 有一定差异 | 良好配对 | 27个 |
| **低度互补层** | 0.1-0.3 | 相似利用率 | 一般配对 | 14个 |
| **无互补层** | <0.1 | 几乎相同 | 竞争型 | 78个 |

#### 抽样方案（12个）

```
高度互补层: 4个 (重点研究)
中度互补层: 4个
低度互补层: 3个
无互补层:   1个 (对照组)
```

#### 适用场景
- ✅ 并发效率优化研究
- ✅ 理解资源利用互补性
- ✅ 最大化GPU利用率

#### 示例组合
- **高度互补**: MNIST(12%) + MRT-OAST(93%) = 差异81%
- **中度互补**: MNIST(12%) + DenseNet121(72%) = 差异60%
- **无互补**: ResNet32(50%) + ResNet44(50%) = 差异0%

---

### 策略6: 按模型架构分层 ⭐⭐⭐

#### 架构分类

| 架构 | 说明 | 代表模型 |
|------|------|----------|
| **CNN** | 卷积神经网络 | MNIST, VulBERTa CNN |
| **ResNet** | 残差网络 | ResNet20/32/44/56 |
| **DenseNet** | 密集连接网络 | DenseNet121 |
| **RNN** | 循环神经网络 | MNIST RNN, Word LM |
| **Transformer** | 注意力机制 | VulBERTa MLP |
| **Custom** | 自定义架构 | MRT-OAST, HRNet, PCB |

#### 简化分层

| 层级 | 组合 | 样本数 |
|------|------|--------|
| **CNN + CNN** | 同架构 | 21个 |
| **CNN + Other** | 混合架构 | 63个 |
| **Other + Other** | 非CNN组合 | 36个 |

#### 适用场景
- ✅ 架构多样性研究
- ✅ 底层计算模式分析
- ⚠️ 分层过细，实用性一般

---

### 策略7: 多维交叉分层 ⭐⭐⭐⭐⭐ (推荐)

#### 二维分层矩阵

**维度1 (主维度)**: 显存占用
**维度2 (次维度)**: GPU利用率互补性

| | 互补型 (GPU差>40%) | 竞争型 (GPU差≤40%) |
|---|---|---|
| **低显存** (<2GB) | 0个 | 30个 |
| **中显存** (2-4GB) | 14个 | 61个 |
| **高显存** (>4GB) | 1个 | 14个 |

#### 抽样方案（12个）

```
低显存+竞争型:  2个
中显存+互补型:  3个
中显存+竞争型:  2个
高显存+互补型:  1个
高显存+竞争型:  1个

(低显存+互补型组合不存在，因为低显存模型GPU利用率差异小)
```

#### 适用场景
- ✅ **最推荐** - 全面覆盖
- ✅ 同时考虑硬件约束和效率优化
- ✅ 分层清晰易解释

#### 为什么最好？

1. **显存是硬约束**: 必须考虑，否则OOM
2. **互补性是核心**: 直接影响并发效率
3. **覆盖全面**: 6个格子涵盖主要场景
4. **易于管理**: 格子数适中，便于分析

#### 示例组合

| 格子 | 示例组合 | 显存 | GPU% | 特点 |
|------|----------|------|------|------|
| 低+竞争 | MNIST + MNIST RNN | 900MB | 62% | 极安全 |
| 中+互补 | MNIST + MRT-OAST | 2400MB | 105% | 最优 |
| 中+竞争 | ResNet44 + HRNet18 | 3330MB | 100% | 均衡 |
| 高+互补 | MNIST + DenseNet121 | 3750MB | 84% | 安全互补 |
| 高+竞争 | DenseNet121 + MRT-OAST | 5250MB | 165% | 高风险 |

---

### 策略8: 按风险等级分层 ⭐⭐⭐⭐

#### 风险评分规则

```python
risk_score = 0
if memory > 7000MB: risk_score += 3
elif memory > 5000MB: risk_score += 2
elif memory > 3000MB: risk_score += 1

if gpu_util > 150%: risk_score += 2
elif gpu_util > 120%: risk_score += 1
```

#### 分层标准

| 层级 | 风险分数 | 特征 | 样本数 |
|------|----------|------|--------|
| **低风险层** | ≤1 | 显存<3GB, GPU<120%, 有数据 | 97个 |
| **中风险层** | 2-3 | 显存3-5GB 或 GPU 120-150% | 22个 |
| **高风险层** | ≥4 | 显存>5GB 或 GPU>150% | 1个 |

#### 抽样方案（12个）

```
低风险层:  6个 (保守为主)
中风险层:  4个 (适度探索)
高风险层:  2个 (少量高风险)
```

#### 适用场景
- ✅ 稳妥实施，减少失败
- ✅ 资源有限时优先保证成功
- ✅ 便于实验风险管理

---

## 📊 策略对比总表

| 策略 | 推荐度 | 优点 | 缺点 | 最适场景 |
|------|--------|------|------|----------|
| **显存占用分层** | ⭐⭐⭐⭐⭐ | 硬件约束明确，OOM风险清晰 | 未考虑GPU竞争 | 资源受限 |
| **GPU利用率分层** | ⭐⭐⭐⭐ | 反映资源竞争 | 估算不准确 | 性能优化 |
| **训练时长分层** | ⭐⭐⭐ | 便于时间管理 | 关联性弱 | 时间敏感 |
| **应用领域分层** | ⭐⭐⭐⭐ | 考虑应用多样性 | 某些组合少 | 泛化性研究 |
| **互补性分层** | ⭐⭐⭐⭐⭐ | 针对并发效率 | 高互补少 | 效率优化 |
| **模型架构分层** | ⭐⭐⭐ | 反映计算模式 | 分层过细 | 架构研究 |
| **多维交叉分层** | ⭐⭐⭐⭐⭐ | 全面均衡 | 复杂度高 | 全面研究 ✅ |
| **风险等级分层** | ⭐⭐⭐⭐ | 风险管理 | 可能保守 | 稳妥实施 |

---

## 💡 最终推荐方案

### 首选：多维交叉分层（显存 × 互补性）

**理由**:
1. ✅ 显存是硬件硬约束，必须考虑
2. ✅ 互补性是研究核心，直接影响并发效率
3. ✅ 两维度交叉最全面
4. ✅ 6个格子易管理

**具体实施**:

```
第一步：按显存×互补性分层，得到6个格子
第二步：每个格子内按"实用性原则"排序：
  - 优先：双方有历史数据
  - 其次：至少一方有数据
  - 最后：都无数据但代表性强
第三步：从每个格子按比例抽取
```

### 备选方案（根据研究重点）

| 如果研究重点是... | 推荐策略 | 说明 |
|------------------|---------|------|
| **资源利用效率** | 显存分层 + GPU分层 | 关注硬件约束 |
| **应用泛化性** | 应用领域分层 | 跨领域多样性 |
| **稳妥实施** | 风险等级分层 | 降低失败风险 |
| **快速验证** | 训练时长分层 | 时间优先 |

### 混合策略（最灵活）

```
1. 一级分层：多维交叉（显存×互补性）- 6个大类
2. 二级筛选：实用性原则（有数据优先）
3. 三级平衡：确保领域多样性
```

---

## 🎯 实际应用示例

### 场景1：资源有限，追求稳妥

**策略组合**: 风险等级分层 + 显存分层

```
第一优先：低风险层（显存<3GB, GPU<120%）→ 抽6个
第二优先：中风险层（显存3-5GB）→ 抽4个
第三优先：高风险层（显存>5GB）→ 抽2个（必须测试边界）
```

### 场景2：追求全面覆盖

**策略组合**: 多维交叉分层 + 领域平衡

```
显存×互补性 6个格子，每格抽2个
同时确保：
- vision+vision: 8个
- 跨领域: 4个
```

### 场景3：聚焦效率优化

**策略组合**: 互补性分层为主

```
高度互补: 4个 (重点)
中度互补: 4个
低度互补: 2个
无互补:   2个 (对照组)
```

---

## 📈 抽样质量评估

### 好的分层抽样应该满足：

1. **✅ 覆盖性**: 每种重要类型都有代表
2. **✅ 代表性**: 样本能反映总体特征
3. **✅ 平衡性**: 各层样本数合理分配
4. **✅ 可行性**: 便于实施和分析

### 质量检查清单：

- [ ] 是否覆盖了高/中/低显存？
- [ ] 是否包含互补型和竞争型？
- [ ] 是否有足够的已知数据模型？
- [ ] 是否考虑了失败风险？
- [ ] 是否便于对比分析？

---

## 🔚 总结

### 核心要点

1. **没有绝对最优的分层策略**，选择取决于研究目标
2. **多维交叉分层**适合大多数场景，兼顾全面性
3. **实用性原则**可以作为二级筛选条件
4. **混合策略**最灵活，可根据实际调整

### 行动建议

**第一步**: 确定研究核心问题
**第二步**: 选择1-2个主要分层维度
**第三步**: 应用实用性原则细化
**第四步**: 验证覆盖性和平衡性

---

**文档版本**: 1.0
**相关脚本**: `scripts/analyze_stratified_sampling_strategies.py`
**相关文档**: `docs/concurrent_hp_study_experimental_design.md`

# Weight Decayä¿®æ”¹è¿›åº¦æŠ¥å‘Š

**ç”Ÿæˆæ—¶é—´**: 2025-11-05
**å½“å‰çŠ¶æ€**: âœ… å…¨éƒ¨å®Œæˆï¼ˆ7/7 weight_decayæ”¯æŒå·²æ·»åŠ ï¼‰

---

## âœ… å·²å®Œæˆçš„ä¿®æ”¹ï¼ˆ7/7ï¼‰

### 1. MRT-OAST âœ…

**ä¿®æ”¹æ–‡ä»¶**:
- `main_batch.py`: æ·»åŠ argparseå‚æ•°å’Œoptimizer weight_decay
- `train.sh`: æ·»åŠ é»˜è®¤å€¼ã€å‚æ•°è§£æã€é…ç½®æ˜¾ç¤ºå’Œå‘½ä»¤å‚æ•°

**éªŒè¯ç»“æœ**:
```bash
$ python main_batch.py --help | grep "weight"
  --weight_decay WEIGHT_DECAY
                        weight decay (L2 penalty, default: 0.0)
```
âœ… éªŒè¯é€šè¿‡

**é»˜è®¤å€¼**: `0.0`
**ä¼˜åŒ–å™¨**: Adam

---

### 2. VulBERTa (MLP & CNN) âœ…

**ä¿®æ”¹æ–‡ä»¶**:
- `train_vulberta.py`:
  - æ·»åŠ argparseå‚æ•°
  - è®¾ç½®é»˜è®¤å€¼ï¼ˆMLP: 0.0, CNN: 0.0ï¼‰
  - æ·»åŠ åˆ°TrainingArguments
  - æ›´æ–°è®­ç»ƒæŠ¥å‘Šæ˜¾ç¤º
- `train.sh`: æ›´æ–°å¸®åŠ©æ–‡æ¡£

**éªŒè¯ç»“æœ**:
```bash
$ python train_vulberta.py --help | grep "weight"
  --weight_decay WEIGHT_DECAY
                        Weight decay (default: 0.0)
```
âœ… éªŒè¯é€šè¿‡

**é»˜è®¤å€¼**: `0.0` (MLP & CNN)
**ä¼˜åŒ–å™¨**: AdamW (é€šè¿‡Hugging Face Trainer)

---

### 3. examplesæ¨¡å‹ âœ…

å·²æˆåŠŸä¿®æ”¹4ä¸ªæ¨¡å‹çš„main.pyæ–‡ä»¶ï¼š

#### 3.1 MNIST CNN (`mnist/main.py`) âœ…
**çŠ¶æ€**: âœ… å·²å®Œæˆ
**ä¼˜åŒ–å™¨**: Adadelta
**ä¿®æ”¹å†…å®¹**:
```python
parser.add_argument('--weight-decay', type=float, default=0.0, metavar='WD',
                    help='weight decay (L2 penalty, default: 0.0)')
optimizer = optim.Adadelta(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)
```

#### 3.2 MNIST RNN (`mnist_rnn/main.py`) âœ…
**çŠ¶æ€**: âœ… å·²å®Œæˆ
**ä¼˜åŒ–å™¨**: Adadelta
**ä¿®æ”¹å†…å®¹**:
```python
parser.add_argument('--weight-decay', type=float, default=0.0, metavar='WD',
                    help='weight decay (L2 penalty, default: 0.0)')
optimizer = optim.Adadelta(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)
```

#### 3.3 MNIST Forward-Forward (`mnist_forward_forward/main.py`) âœ…
**çŠ¶æ€**: âœ… å·²å®Œæˆ
**ä¼˜åŒ–å™¨**: Adam
**ä¿®æ”¹å†…å®¹**:
```python
parser.add_argument('--weight-decay', type=float, default=0.0, metavar="WD",
                    help="weight decay (L2 penalty, default: 0.0)")
# åœ¨Layerç±»ä¸­:
self.opt = Adam(self.parameters(), lr=args.lr, weight_decay=args.weight_decay)
```

#### 3.4 Siamese Network (`siamese_network/main.py`) âœ…
**çŠ¶æ€**: âœ… å·²å®Œæˆ
**ä¼˜åŒ–å™¨**: Adadelta
**ä¿®æ”¹å†…å®¹**:
```python
parser.add_argument('--weight-decay', type=float, default=0.0, metavar='WD',
                    help='weight decay (L2 penalty, default: 0.0)')
optimizer = optim.Adadelta(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)
```

---

## ğŸ“Š å½“å‰è¿›åº¦

| æ¨¡å‹ | çŠ¶æ€ | ä¼˜åŒ–å™¨ | é»˜è®¤å€¼ | éªŒè¯ |
|------|------|--------|--------|------|
| MRT-OAST | âœ… å®Œæˆ | Adam | 0.0 | âœ… |
| VulBERTa-MLP | âœ… å®Œæˆ | AdamW | 0.0 | âœ… |
| VulBERTa-CNN | âœ… å®Œæˆ | AdamW | 0.0 | âœ… |
| examples-MNIST CNN | âœ… å®Œæˆ | Adadelta | 0.0 | âœ… |
| examples-MNIST RNN | âœ… å®Œæˆ | Adadelta | 0.0 | âœ… |
| examples-MNIST FF | âœ… å®Œæˆ | Adam | 0.0 | âœ… |
| examples-Siamese | âœ… å®Œæˆ | Adadelta | 0.0 | âœ… |

**å®Œæˆåº¦**: 100% (7/7) ğŸ‰

---

## ğŸ¯ ä¸‹ä¸€æ­¥è¡ŒåŠ¨

### é€‰é¡¹1: éªŒè¯æ‰€æœ‰ä¿®æ”¹ï¼ˆæ¨èï¼‰
åˆ›å»ºè¯¦ç»†çš„éªŒè¯æµ‹è¯•ï¼Œç¡®ä¿æ‰€æœ‰æ¨¡å‹çš„weight_decayåŠŸèƒ½æ­£å¸¸å·¥ä½œã€‚

### é€‰é¡¹2: å¼€å§‹ä½¿ç”¨
æ‰€æœ‰weight_decayæ”¯æŒå·²æ·»åŠ å®Œæˆï¼Œå¯ä»¥å¼€å§‹ä½¿ç”¨è¿›è¡Œèƒ½è€—å’Œæ€§èƒ½å®éªŒã€‚

### é€‰é¡¹3: ç»§ç»­æ·»åŠ å…¶ä»–è¶…å‚æ•°
æ ¹æ®stage2_3_modification_guide.mdç»§ç»­æ·»åŠ precisionç­‰å…¶ä»–è¶…å‚æ•°æ”¯æŒã€‚

---

## ğŸ“ ä¿®æ”¹æ¨¡å¼æ€»ç»“

### å¯¹äºä½¿ç”¨Adadeltaçš„æ¨¡å‹ï¼ˆå¦‚MNIST CNN/RNN/Siameseï¼‰
```python
# 1. æ·»åŠ argparse
parser.add_argument('--weight-decay', type=float, default=0.0, metavar='WD',
                    help='weight decay (L2 penalty, default: 0.0)')

# 2. ä¿®æ”¹optimizer
optimizer = optim.Adadelta(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)
```

### å¯¹äºä½¿ç”¨Adamçš„æ¨¡å‹ï¼ˆå¦‚MNIST Forward-Forwardï¼‰
```python
# 1. æ·»åŠ argparse
parser.add_argument('--weight-decay', type=float, default=0.0, metavar='WD',
                    help='weight decay (L2 penalty, default: 0.0)')

# 2. ä¿®æ”¹optimizer
optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)
```

### å¯¹äºMRT-OASTï¼ˆä½¿ç”¨Adamï¼‰
```python
# 1. æ·»åŠ argparse
parser.add_argument("--weight_decay", type=float, default=0.0,
                    help="weight decay (L2 penalty, default: 0.0)")

# 2. ä¿®æ”¹optimizer
optimizer = optim.Adam(model.parameters(), lr=1.0, weight_decay=args.weight_decay)
```

### å¯¹äºVulBERTaï¼ˆä½¿ç”¨Hugging Face Trainerï¼‰
```python
# 1. æ·»åŠ argparse
parser.add_argument('--weight_decay', type=float, default=None,
                   help='Weight decay (default: 0.0)')

# 2. è®¾ç½®é»˜è®¤å€¼
if args.weight_decay is None:
    args.weight_decay = 0.0

# 3. æ·»åŠ åˆ°TrainingArguments
training_args = TrainingArguments(
    ...
    weight_decay=args.weight_decay,
    ...
)
```

### train.shä¿®æ”¹ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
```bash
# 1. æ·»åŠ é»˜è®¤å€¼
WEIGHT_DECAY=0.0

# 2. æ·»åŠ å‚æ•°è§£æ
--weight-decay)
    WEIGHT_DECAY="$2"
    shift 2
    ;;

# 3. æ·»åŠ åˆ°è®­ç»ƒå‘½ä»¤
--weight-decay $WEIGHT_DECAY
```

---

## âœ… éªŒè¯æ¸…å•

æ¯ä¸ªä¿®æ”¹å®Œæˆååº”éªŒè¯ï¼š
- [x] `python main.py --help` æ˜¾ç¤ºweight_decayå‚æ•°
- [x] é»˜è®¤å€¼ä¸º0.0
- [ ] å¯ä»¥é€šè¿‡å‘½ä»¤è¡Œä¿®æ”¹å€¼: `python main.py --weight-decay 0.001`
- [ ] è®­ç»ƒå¯ä»¥æ­£å¸¸è¿è¡Œï¼ˆéœ€è¦é…ç½®é€‚å½“çš„condaç¯å¢ƒï¼‰

---

**æœ€åæ›´æ–°**: 2025-11-05
**å®ŒæˆçŠ¶æ€**: âœ… å…¨éƒ¨å®Œæˆ
**å®Œæˆæ¨¡å‹**: MRT-OAST, VulBERTa-MLP, VulBERTa-CNN, MNIST CNN, MNIST RNN, MNIST Forward-Forward, Siamese Network
**ä¿®æ”¹æ–‡ä»¶æ•°**: 11ä¸ªæ–‡ä»¶
  - 7ä¸ªPythonè®­ç»ƒè„šæœ¬
  - 2ä¸ªtrain.shè„šæœ¬
  - 1ä¸ªè¿›åº¦æŠ¥å‘Š
  - 1ä¸ªä¿®æ”¹æŒ‡å—

**ç»Ÿè®¡ä¿¡æ¯**:
- ä»£ç ä¿®æ”¹: 7ä¸ªæ¨¡å‹çš„ä¸»è®­ç»ƒè„šæœ¬
- å‚æ•°æ·»åŠ : 7ä¸ªæ–°çš„--weight-decayå‚æ•°
- ä¼˜åŒ–å™¨æ›´æ–°: 7ä¸ªoptimizeråˆå§‹åŒ–
- æ–‡æ¡£æ›´æ–°: 2ä¸ªtrain.shå¸®åŠ©æ–‡æ¡£

**ä¸‹ä¸€æ­¥**: éªŒè¯æ‰€æœ‰ä¿®æ”¹çš„æ­£ç¡®æ€§ï¼Œç¡®ä¿é»˜è®¤å€¼ä¸æ”¹å˜åŸå§‹è®­ç»ƒè¡Œä¸º

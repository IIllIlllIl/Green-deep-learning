#!/usr/bin/env python3
"""
æ˜¾å­˜åˆ†å±‚æŠ½æ ·å·¥å…· - å®é™…å¯æ‰§è¡Œç‰ˆæœ¬
Memory-based Stratified Sampling Tool
"""
import json
import random
from pathlib import Path
from collections import defaultdict
import statistics

def collect_memory_data_from_results():
    """ä»å†å²è®­ç»ƒç»“æœä¸­æå–æ˜¾å­˜æ•°æ®ï¼ˆå¦‚æœæœ‰ï¼‰"""
    memory_data = {}
    results_dir = Path('results')

    if not results_dir.exists():
        return None

    for result_file in results_dir.glob('*.json'):
        try:
            with open(result_file) as f:
                data = json.load(f)

            if data.get('training_success'):
                model_key = f"{data['repository']}_{data['model']}"

                # æ£€æŸ¥æ˜¯å¦æœ‰æ˜¾å­˜æ•°æ®
                energy = data.get('energy_metrics', {})
                if 'gpu_memory_peak_mb' in energy:
                    if model_key not in memory_data:
                        memory_data[model_key] = []
                    memory_data[model_key].append(energy['gpu_memory_peak_mb'])
        except:
            pass

    # è®¡ç®—å¹³å‡å€¼
    if memory_data:
        return {k: statistics.mean(v) for k, v in memory_data.items()}
    return None

def use_estimated_memory():
    """ä½¿ç”¨ä¿å®ˆçš„æ˜¾å­˜ä¼°ç®—å€¼"""
    return {
        'examples_mnist': 500,
        'examples_mnist_rnn': 500,
        'examples_mnist_ff': 500,
        'pytorch_resnet_cifar10_resnet20': 800,
        'pytorch_resnet_cifar10_resnet32': 1000,
        'pytorch_resnet_cifar10_resnet44': 1200,
        'pytorch_resnet_cifar10_resnet56': 1500,
        'Person_reID_baseline_pytorch_densenet121': 3500,
        'Person_reID_baseline_pytorch_hrnet18': 2500,
        'Person_reID_baseline_pytorch_pcb': 2000,
        'MRT-OAST_default': 2200,
        'VulBERTa_mlp': 1500,
        'VulBERTa_cnn': 1500,
        'bug-localization-by-dnn-and-rvsm_default': 2000,
        'examples_siamese': 1500,
        'examples_word_lm': 1500,
    }

def define_memory_strata():
    """å®šä¹‰æ˜¾å­˜åˆ†å±‚æ ‡å‡†"""
    return {
        'ultra_low': {
            'range': (0, 1500),
            'description': 'è¶…ä½æ˜¾å­˜ (<1.5GB): ä¸¤ä¸ªå°æ¨¡å‹ï¼Œæå®‰å…¨',
            'oom_risk': 'very_low',
            'target_ratio': 0.15
        },
        'low': {
            'range': (1500, 3000),
            'description': 'ä½æ˜¾å­˜ (1.5-3GB): ä¸€å¤§ä¸€å°æˆ–ä¸¤ä¸­ç­‰ï¼Œå®‰å…¨',
            'oom_risk': 'low',
            'target_ratio': 0.35
        },
        'medium': {
            'range': (3000, 5000),
            'description': 'ä¸­æ˜¾å­˜ (3-5GB): ä¸€å¤§ä¸€ä¸­ï¼Œå¯æ¥å—',
            'oom_risk': 'medium',
            'target_ratio': 0.30
        },
        'high': {
            'range': (5000, 7000),
            'description': 'é«˜æ˜¾å­˜ (5-7GB): æ¥è¿‘ä¸Šé™ï¼Œéœ€è°¨æ…',
            'oom_risk': 'high',
            'target_ratio': 0.15
        },
        'ultra_high': {
            'range': (7000, 10000),
            'description': 'æé«˜æ˜¾å­˜ (>7GB): è¶…è¿‡å®‰å…¨ç•Œé™',
            'oom_risk': 'very_high',
            'target_ratio': 0.05
        }
    }

def generate_and_stratify_pairs(memory_data, strata_def, max_memory=9000):
    """ç”Ÿæˆæ‰€æœ‰å¯è¡Œçš„æ¨¡å‹å¯¹å¹¶æŒ‰æ˜¾å­˜åˆ†å±‚"""
    models = list(memory_data.keys())
    strata = {name: [] for name in strata_def.keys()}

    for i, model1 in enumerate(models):
        for model2 in models[i+1:]:
            total_memory = memory_data[model1] + memory_data[model2]

            if total_memory <= max_memory:
                pair = {
                    'model1': model1,
                    'model2': model2,
                    'memory1': memory_data[model1],
                    'memory2': memory_data[model2],
                    'total_memory': total_memory
                }

                # åˆ†é…åˆ°å¯¹åº”å±‚
                for stratum_name, stratum_info in strata_def.items():
                    min_mem, max_mem = stratum_info['range']
                    if min_mem <= total_memory < max_mem:
                        strata[stratum_name].append(pair)
                        break

    return strata

def calculate_sample_sizes(strata, strata_def, total_samples=12, method='proportional'):
    """è®¡ç®—æ¯å±‚åº”æŠ½å–çš„æ ·æœ¬æ•°"""

    if method == 'proportional':
        # æŒ‰å„å±‚å®é™…æ ·æœ¬æ•°æ¯”ä¾‹åˆ†é…
        total_pairs = sum(len(pairs) for pairs in strata.values())
        if total_pairs == 0:
            return {}

        sample_sizes = {}
        for stratum_name, pairs in strata.items():
            if len(pairs) > 0:
                ratio = len(pairs) / total_pairs
                size = max(1, round(ratio * total_samples))
                sample_sizes[stratum_name] = min(size, len(pairs))
            else:
                sample_sizes[stratum_name] = 0

        # è°ƒæ•´åˆ°æ€»æ•°
        current_total = sum(sample_sizes.values())
        if current_total != total_samples and sample_sizes:
            largest_stratum = max(sample_sizes, key=sample_sizes.get)
            sample_sizes[largest_stratum] += (total_samples - current_total)

    elif method == 'equal':
        # æ¯å±‚ç›¸ç­‰æ•°é‡
        non_empty_strata = [name for name, pairs in strata.items() if len(pairs) > 0]
        if not non_empty_strata:
            return {}

        per_stratum = total_samples // len(non_empty_strata)
        sample_sizes = {name: per_stratum for name in strata.keys()}

        remainder = total_samples % len(non_empty_strata)
        for i, name in enumerate(non_empty_strata[:remainder]):
            sample_sizes[name] += 1

    elif method == 'target_ratio':
        # æŒ‰é¢„è®¾ç›®æ ‡æ¯”ä¾‹
        sample_sizes = {}
        for stratum_name, pairs in strata.items():
            if len(pairs) > 0:
                target = strata_def[stratum_name]['target_ratio']
                size = max(1, round(target * total_samples))
                sample_sizes[stratum_name] = min(size, len(pairs))
            else:
                sample_sizes[stratum_name] = 0

    return sample_sizes

def perform_stratified_sampling(strata, sample_sizes, seed=42):
    """æ‰§è¡Œåˆ†å±‚æŠ½æ ·"""
    random.seed(seed)
    sampled_pairs = []

    for stratum_name, pairs in strata.items():
        size = sample_sizes.get(stratum_name, 0)

        if size > 0 and len(pairs) > 0:
            sample = random.sample(pairs, min(size, len(pairs)))
            sampled_pairs.extend(sample)

    return sampled_pairs

def main():
    print("="*100)
    print("æ˜¾å­˜åˆ†å±‚æŠ½æ ·å·¥å…·")
    print("Memory-based Stratified Sampling Tool")
    print("="*100)

    # æ­¥éª¤1: æ”¶é›†æ˜¾å­˜æ•°æ®
    print("\næ­¥éª¤1: æ”¶é›†æ¨¡å‹æ˜¾å­˜æ•°æ®...")
    memory_data = collect_memory_data_from_results()

    if memory_data:
        print(f"  âœ… ä»å†å²è®°å½•ä¸­æ‰¾åˆ° {len(memory_data)} ä¸ªæ¨¡å‹çš„æ˜¾å­˜æ•°æ®")
    else:
        print("  âš ï¸  æœªæ‰¾åˆ°å†å²æ˜¾å­˜æ•°æ®ï¼Œä½¿ç”¨ä¼°ç®—å€¼")
        memory_data = use_estimated_memory()
        print(f"  ğŸ“Š ä½¿ç”¨ {len(memory_data)} ä¸ªæ¨¡å‹çš„ä¼°ç®—æ˜¾å­˜å€¼")

    print("\n  æ¨¡å‹æ˜¾å­˜å ç”¨:")
    for model, mem in sorted(memory_data.items(), key=lambda x: x[1]):
        print(f"    {model:<50} {mem:>6.0f} MB")

    # æ­¥éª¤2: å®šä¹‰åˆ†å±‚æ ‡å‡†
    print("\næ­¥éª¤2: å®šä¹‰åˆ†å±‚æ ‡å‡†...")
    strata_def = define_memory_strata()
    print("  åˆ†å±‚å®šä¹‰:")
    for name, info in strata_def.items():
        print(f"    {name:15} {info['description']}")

    # æ­¥éª¤3: ç”Ÿæˆå¹¶åˆ†å±‚
    print("\næ­¥éª¤3: ç”Ÿæˆå¹¶åˆ†å±‚æ‰€æœ‰æ¨¡å‹å¯¹...")
    strata = generate_and_stratify_pairs(memory_data, strata_def)
    total_pairs = sum(len(pairs) for pairs in strata.values())
    print(f"  æ€»å¯è¡Œç»„åˆæ•°: {total_pairs}")
    print("\n  å„å±‚åˆ†å¸ƒ:")
    for name, pairs in strata.items():
        if len(pairs) > 0:
            pct = len(pairs) / total_pairs * 100
            print(f"    {name:15} {len(pairs):3}ä¸ªç»„åˆ ({pct:5.1f}%)")

    # æ­¥éª¤4: è®¡ç®—æ ·æœ¬æ•°ï¼ˆå¯¹æ¯”ä¸‰ç§æ–¹æ³•ï¼‰
    print("\næ­¥éª¤4: è®¡ç®—æ¯å±‚æŠ½æ ·æ•° (å¯¹æ¯”ä¸‰ç§æ–¹æ³•)...")

    methods = [
        ('proportional', 'æŒ‰æ¯”ä¾‹åˆ†é…'),
        ('equal', 'å‡ç­‰åˆ†é…'),
        ('target_ratio', 'ç›®æ ‡æ¯”ä¾‹åˆ†é…')
    ]

    for method, desc in methods:
        print(f"\n  {desc} ({method}):")
        sizes = calculate_sample_sizes(strata, strata_def, total_samples=12, method=method)
        for name, size in sizes.items():
            if size > 0:
                print(f"    {name:15} {size:2}ä¸ª")

    # æ­¥éª¤5: æ‰§è¡ŒæŠ½æ ·ï¼ˆä½¿ç”¨æŒ‰æ¯”ä¾‹åˆ†é…ï¼‰
    print("\næ­¥éª¤5: æ‰§è¡ŒæŠ½æ · (ä½¿ç”¨æŒ‰æ¯”ä¾‹åˆ†é…)...")
    sizes_prop = calculate_sample_sizes(strata, strata_def, total_samples=12, method='proportional')
    sampled_pairs = perform_stratified_sampling(strata, sizes_prop, seed=42)

    print(f"\n  âœ… æœ€ç»ˆæŠ½å– {len(sampled_pairs)} ä¸ªæ¨¡å‹ç»„åˆ")

    print(f"\n{'åºå·':<5} {'æ¨¡å‹A':<50} {'æ¨¡å‹B':<50} {'æ€»æ˜¾å­˜(MB)':<12} {'å±‚çº§':<15}")
    print("-" * 132)

    # ç¡®å®šæ¯ä¸ªæ ·æœ¬æ‰€å±å±‚çº§
    for i, pair in enumerate(sampled_pairs, 1):
        layer = ''
        for name, info in strata_def.items():
            min_mem, max_mem = info['range']
            if min_mem <= pair['total_memory'] < max_mem:
                layer = name
                break

        print(f"{i:<5} {pair['model1']:<50} {pair['model2']:<50} {pair['total_memory']:<12.0f} {layer:<15}")

    # å¯¼å‡ºç»“æœ
    output = {
        'method': 'memory_stratified_sampling',
        'total_samples': len(sampled_pairs),
        'strata_definition': strata_def,
        'sample_sizes': sizes_prop,
        'sampled_pairs': sampled_pairs,
        'memory_data_source': 'historical' if collect_memory_data_from_results() else 'estimated'
    }

    output_file = 'memory_stratified_sample.json'
    with open(output_file, 'w') as f:
        json.dump(output, f, indent=2)

    print(f"\nâœ… ç»“æœå·²ä¿å­˜åˆ°: {output_file}")

    # ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
    print("\n" + "="*100)
    print("æŠ½æ ·è´¨é‡æŠ¥å‘Š")
    print("="*100)

    print("\nå±‚çº§è¦†ç›–æƒ…å†µ:")
    for name, pairs in strata.items():
        sampled = sum(1 for p in sampled_pairs if any(
            info['range'][0] <= p['total_memory'] < info['range'][1]
            for sname, info in strata_def.items() if sname == name
        ))
        if len(pairs) > 0:
            coverage = sampled / len(pairs) * 100
            print(f"  {name:15} æ€»æ•°:{len(pairs):3} æŠ½å–:{sampled:2} æŠ½æ ·ç‡:{coverage:5.1f}%")

    print("\næ˜¾å­˜åˆ†å¸ƒ:")
    memories = [p['total_memory'] for p in sampled_pairs]
    print(f"  æœ€å°: {min(memories):.0f} MB")
    print(f"  æœ€å¤§: {max(memories):.0f} MB")
    print(f"  å¹³å‡: {statistics.mean(memories):.0f} MB")
    print(f"  ä¸­ä½æ•°: {statistics.median(memories):.0f} MB")

    print("\n="*100)
    print("å®Œæˆï¼")
    print("="*100)

if __name__ == "__main__":
    main()

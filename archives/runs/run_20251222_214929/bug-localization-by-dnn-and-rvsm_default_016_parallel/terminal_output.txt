================================================================================
STDOUT:
================================================================================
[Train Wrapper] Repository: repos/bug-localization-by-dnn-and-rvsm
[Train Wrapper] Training script: ./train.sh
[Train Wrapper] Log file: results/run_20251222_214929/bug-localization-by-dnn-and-rvsm_default_016_parallel/training.log
[Train Wrapper] Energy directory: results/run_20251222_214929/bug-localization-by-dnn-and-rvsm_default_016_parallel/energy
[Train Wrapper] Arguments: --kfold 8
[Train Wrapper] Changed to directory: /home/green/energy_dl/nightly/repos/bug-localization-by-dnn-and-rvsm
[Train Wrapper] Starting GPU monitoring...
[Train Wrapper] GPU monitoring PID: 1621396
[Train Wrapper] Starting training with integrated energy monitoring...
[Train Wrapper] Command: ./train.sh --kfold 8
========================================
========================================
Bug Localization Training Configuration
========================================
Model: dnn
Python: /home/green/miniconda3/envs/dnn_rvsm/bin/python
Working directory: /home/green/energy_dl/nightly/repos/bug-localization-by-dnn-and-rvsm
K-fold: 8
Hidden sizes: 300
Alpha: 1e-5
Max iterations: 10000
Early stopping: 30
Solver: sgd
Parallel jobs: -2
Random seed: Not set (original non-deterministic behavior)
========================================

================================================================================
Bug Localization Model Training - DNN
================================================================================
Start time: 2025-12-23 01:25:18

DNN Hyperparameters:
  - K-fold: 8
  - Hidden layer sizes: (300,)
  - Alpha (L2 penalty): 1e-05
  - Max iterations: 10000
  - Early stopping patience: 30
  - Solver: sgd
  - Parallel jobs: -2
  - Random seed: Not set (original non-deterministic behavior)

Training DNN model with k-fold cross-validation...
--------------------------------------------------------------------------------
/home/green/miniconda3/envs/dnn_rvsm/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  "timeout or by a memory leak.", UserWarning
Fold: 2 / 8
Fold: 3 / 8
Training completed successfully!

================================================================================
TRAINING REPORT
================================================================================
Model: DNN
Start time: 2025-12-23 01:25:18
End time: 2025-12-23 01:38:00
Total duration: 762.63 seconds (12.71 minutes)

MODEL PERFORMANCE (Top-k Accuracy):
--------------------------------------------------------------------------------
  Top- 1 Accuracy: 0.382 (38.2%)
  Top- 5 Accuracy: 0.626 (62.6%)
  Top-10 Accuracy: 0.737 (73.7%)
  Top-20 Accuracy: 0.825 (82.5%)

Detailed Results (All k values):
  Top- 1: 0.382
  Top- 2: 0.478
  Top- 3: 0.547
  Top- 4: 0.590
  Top- 5: 0.626
  Top- 6: 0.652
  Top- 7: 0.678
  Top- 8: 0.699
  Top- 9: 0.722
  Top-10: 0.737
  Top-11: 0.748
  Top-12: 0.760
  Top-13: 0.773
  Top-14: 0.783
  Top-15: 0.792
  Top-16: 0.801
  Top-17: 0.808
  Top-18: 0.814
  Top-19: 0.820
  Top-20: 0.825
================================================================================
Fold: 4 / 8
Fold: 1 / 8
Fold: 5 / 8
Fold: 6 / 8
Fold: 7 / 8
Fold: 8 / 8
Training completed successfully!
========================================
[Train Wrapper] Training finished with exit code: 0
[Train Wrapper] Stopping GPU monitoring...
[Train Wrapper] Processing CPU energy data...
[Train Wrapper] CPU energy saved to: /home/green/energy_dl/nightly/results/run_20251222_214929/bug-localization-by-dnn-and-rvsm_default_016_parallel/energy/cpu_energy.txt
[Train Wrapper] GPU monitoring data saved to: /home/green/energy_dl/nightly/results/run_20251222_214929/bug-localization-by-dnn-and-rvsm_default_016_parallel/energy
[Train Wrapper] Energy monitoring completed

================================================================================
STDERR:
================================================================================
(empty)

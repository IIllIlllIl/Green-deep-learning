# MRT-OAST è®­ç»ƒæ—¶é—´ä¼°ç®—æŠ¥å‘Š

## ç¡¬ä»¶é…ç½®

- **GPU**: NVIDIA GeForce RTX 3080
- **æ˜¾å­˜**: 10GB (å½“å‰å¯ç”¨: 4.2GB)
- **è®¡ç®—èƒ½åŠ›**: é«˜æ€§èƒ½æ·±åº¦å­¦ä¹ GPU

## æ•°æ®é›†è§„æ¨¡

| æ•°æ®é›† | è®­ç»ƒæ ·æœ¬ | éªŒè¯æ ·æœ¬ | æµ‹è¯•æ ·æœ¬ | æ€»è®¡ |
|--------|----------|----------|----------|------|
| OJClone | 40,000 | 5,000 | 5,000 | 50,000 |
| GCJ | 353,399 | 13,696 | 13,696 | 380,791 |
| BCB | 450,863 | 416,329 | 416,329 | 1,283,521 |

## é»˜è®¤è®­ç»ƒé…ç½®

- **è®­ç»ƒè½®æ•° (epochs)**: 10
- **æ‰¹æ¬¡å¤§å° (batch_size)**: 64
- **åºåˆ—é•¿åº¦ (max_len)**: 256
- **Transformerå±‚æ•°**: 2
- **éªŒè¯æ­¥æ•°**: 1750æ­¥æˆ–æ¯epochä¸€æ¬¡

## â±ï¸ æ—¶é—´ä¼°ç®—

### åŸºäºRTX 3080çš„æ€§èƒ½ä¼°ç®—

#### 1. OJCloneæ•°æ®é›†ï¼ˆå°è§„æ¨¡ï¼‰

**å¿«é€Ÿæµ‹è¯•æ¨¡å¼ï¼ˆ2-3 epochsï¼‰:**
```
é¢„å¤„ç†æ—¶é—´:     ~2-5åˆ†é’Ÿ
æ¯epochè®­ç»ƒ:     ~7-10åˆ†é’Ÿ
æ€»è®­ç»ƒæ—¶é—´:      ~15-30åˆ†é’Ÿ
éªŒè¯è¯„ä¼°:        ~3-5åˆ†é’Ÿ
---------------------------------
æ€»è®¡:           20-40åˆ†é’Ÿ
```

**å®Œæ•´è®­ç»ƒï¼ˆ10 epochsï¼‰:**
```
é¢„å¤„ç†æ—¶é—´:     ~2-5åˆ†é’Ÿ
æ¯epochè®­ç»ƒ:     ~7-10åˆ†é’Ÿ
10 epochs:      ~70-100åˆ†é’Ÿ
éªŒè¯è¯„ä¼°:        ~5-8åˆ†é’Ÿ
---------------------------------
æ€»è®¡:           1.5-2å°æ—¶
```

#### 2. GCJæ•°æ®é›†ï¼ˆä¸­ç­‰è§„æ¨¡ï¼‰â­ é»˜è®¤

**å®Œæ•´è®­ç»ƒï¼ˆ10 epochsï¼‰:**
```
é¢„å¤„ç†æ—¶é—´:     ~5-10åˆ†é’Ÿ
æ¯epochè®­ç»ƒ:     ~60-75åˆ†é’Ÿ
10 epochs:      ~10-12.5å°æ—¶
éªŒè¯è¯„ä¼°:        ~10-15åˆ†é’Ÿ
---------------------------------
æ€»è®¡:           11-14å°æ—¶
```

**å¿«é€Ÿæµ‹è¯•ï¼ˆ3 epochsï¼‰:**
```
é¢„å¤„ç†æ—¶é—´:     ~5-10åˆ†é’Ÿ
æ¯epochè®­ç»ƒ:     ~60-75åˆ†é’Ÿ
3 epochs:       ~3-4å°æ—¶
éªŒè¯è¯„ä¼°:        ~10åˆ†é’Ÿ
---------------------------------
æ€»è®¡:           3.5-4.5å°æ—¶
```

#### 3. BCBæ•°æ®é›†ï¼ˆå¤§è§„æ¨¡ï¼‰

**å®Œæ•´è®­ç»ƒï¼ˆ10 epochsï¼‰:**
```
é¢„å¤„ç†æ—¶é—´:     ~10-15åˆ†é’Ÿ
æ¯epochè®­ç»ƒ:     ~80-95åˆ†é’Ÿ
10 epochs:      ~13.5-16å°æ—¶
éªŒè¯è¯„ä¼°:        ~20-30åˆ†é’Ÿ
---------------------------------
æ€»è®¡:           14-17å°æ—¶
```

**å»ºè®®è®­ç»ƒï¼ˆ20 epochsï¼‰:**
```
é¢„å¤„ç†æ—¶é—´:     ~10-15åˆ†é’Ÿ
æ¯epochè®­ç»ƒ:     ~80-95åˆ†é’Ÿ
20 epochs:      ~27-32å°æ—¶
éªŒè¯è¯„ä¼°:        ~20-30åˆ†é’Ÿ
---------------------------------
æ€»è®¡:           28-34å°æ—¶ (1-1.5å¤©)
```

## ğŸ“Š æ‰¹æ¬¡å¤„ç†é€Ÿåº¦ä¼°ç®—

åŸºäºRTX 3080å’Œé»˜è®¤é…ç½®ï¼ˆbatch_size=64, seq_len=256ï¼‰:

| æ•°æ®é›† | æ¯epochæ‰¹æ¬¡æ•° | ä¼°è®¡æ¯æ‰¹æ¬¡æ—¶é—´ | æ¯epochæ—¶é—´ |
|--------|---------------|----------------|-------------|
| OJClone | ~625 | 0.6-1.0ç§’ | 7-10åˆ†é’Ÿ |
| GCJ | ~5,522 | 0.6-0.8ç§’ | 60-75åˆ†é’Ÿ |
| BCB | ~7,045 | 0.7-0.8ç§’ | 80-95åˆ†é’Ÿ |

## ğŸš€ å¿«é€Ÿæµ‹è¯•å»ºè®®

å¦‚æœæƒ³å¿«é€ŸéªŒè¯ç¯å¢ƒå’Œä»£ç ï¼š

### æ–¹æ¡ˆ1: è¶…å¿«é€Ÿæµ‹è¯•ï¼ˆ5-10åˆ†é’Ÿï¼‰
```bash
./quick_train.sh OJClone 2
```
- æ•°æ®é›†: OJClone (æœ€å°)
- è®­ç»ƒè½®æ•°: 2
- æ‰¹æ¬¡å¤§å°: 32 (å‡å°)
- åºåˆ—é•¿åº¦: 128 (å‡å°)
- **é¢„è®¡æ—¶é—´: 5-10åˆ†é’Ÿ**

### æ–¹æ¡ˆ2: æ ‡å‡†æµ‹è¯•ï¼ˆ20-40åˆ†é’Ÿï¼‰
```bash
./train_and_evaluate.sh --dataset OJClone --epochs 3
```
- æ•°æ®é›†: OJClone
- è®­ç»ƒè½®æ•°: 3
- é»˜è®¤å‚æ•°
- **é¢„è®¡æ—¶é—´: 20-40åˆ†é’Ÿ**

### æ–¹æ¡ˆ3: å®Œæ•´å°æ•°æ®é›†ï¼ˆ1.5-2å°æ—¶ï¼‰
```bash
./train_and_evaluate.sh --dataset OJClone --epochs 10
```
- æ•°æ®é›†: OJClone
- å®Œæ•´10è½®è®­ç»ƒ
- **é¢„è®¡æ—¶é—´: 1.5-2å°æ—¶**

## âš¡ åŠ é€Ÿè®­ç»ƒå»ºè®®

### 1. å¢å¤§æ‰¹æ¬¡å¤§å°ï¼ˆå¦‚æœæ˜¾å­˜å…è®¸ï¼‰
```bash
./train_and_evaluate.sh --batch-size 128  # å¯èƒ½å¿«~30%
```
**æ³¨æ„**: RTX 3080 10GBæ˜¾å­˜ï¼Œbatch_size=128å¯èƒ½å¯è¡Œ

### 2. å‡å°åºåˆ—é•¿åº¦
```bash
./train_and_evaluate.sh --max-len 128  # å¯èƒ½å¿«~40%
```
**æƒè¡¡**: å¯èƒ½ç•¥å¾®é™ä½æ€§èƒ½

### 3. å¹¶è¡Œæ•°æ®åŠ è½½ï¼ˆå·²é»˜è®¤ï¼‰
ä»£ç å·²ä½¿ç”¨é«˜æ•ˆçš„æ•°æ®é¢„å¤„ç†

## ğŸŒ é™ä½æ˜¾å­˜ä½¿ç”¨ï¼ˆå¦‚æœå†…å­˜ä¸è¶³ï¼‰

### å¦‚æœé‡åˆ°OOM (Out of Memory)é”™è¯¯ï¼š

```bash
# æ–¹æ¡ˆ1: å‡å°batch_size
./train_and_evaluate.sh --batch-size 32

# æ–¹æ¡ˆ2: å‡å°åºåˆ—é•¿åº¦
./train_and_evaluate.sh --max-len 128

# æ–¹æ¡ˆ3: å‡å°æ¨¡å‹å¤§å°
./train_and_evaluate.sh \
    --d-model 64 \
    --d-ff 256 \
    --batch-size 32
```

## ğŸ“ˆ å®Œæ•´è®­ç»ƒè®¡åˆ’å»ºè®®

### ç¬¬ä¸€å¤©: å¿«é€ŸéªŒè¯å’Œå°æ•°æ®é›†
```bash
# ä¸Šåˆ (10åˆ†é’Ÿ)
./quick_train.sh OJClone 2

# ä¸‹åˆ (2å°æ—¶)
./train_and_evaluate.sh --dataset OJClone --epochs 10
```

### ç¬¬äºŒå¤©: ä¸­ç­‰æ•°æ®é›†
```bash
# å…¨å¤© (11-14å°æ—¶)
./train_and_evaluate.sh --dataset GCJ --epochs 10
```

### ç¬¬ä¸‰å¤©: å¤§æ•°æ®é›†
```bash
# å…¨å¤©+å¤œé—´ (14-17å°æ—¶)
./train_and_evaluate.sh --dataset BCB --epochs 10

# æˆ–è¿è¡Œ20 epochs (28-34å°æ—¶)
./train_and_evaluate.sh --dataset BCB --epochs 20
```

## â° æ€»æ—¶é—´ä¼°ç®—æ±‡æ€»

| ä»»åŠ¡ | ä¼°è®¡æ—¶é—´ | å»ºè®®æ‰§è¡Œæ—¶é—´ |
|------|----------|--------------|
| å¿«é€ŸéªŒè¯ (OJClone, 2 epochs) | 5-10åˆ†é’Ÿ | ä»»ä½•æ—¶å€™ |
| OJCloneå®Œæ•´è®­ç»ƒ (10 epochs) | 1.5-2å°æ—¶ | å·¥ä½œæ—¶é—´ |
| GCJå®Œæ•´è®­ç»ƒ (10 epochs) | 11-14å°æ—¶ | è¿‡å¤œè¿è¡Œ |
| BCBå®Œæ•´è®­ç»ƒ (10 epochs) | 14-17å°æ—¶ | è¿‡å¤œè¿è¡Œ |
| BCBå®Œæ•´è®­ç»ƒ (20 epochs) | 28-34å°æ—¶ | å‘¨æœ«è¿è¡Œ |

## ğŸ’¡ å®ç”¨æŠ€å·§

### 1. åå°è¿è¡Œé•¿æ—¶é—´è®­ç»ƒ
```bash
# ä½¿ç”¨nohupåå°è¿è¡Œ
nohup ./train_and_evaluate.sh --dataset GCJ --epochs 10 > training.log 2>&1 &

# æŸ¥çœ‹è¿›ç¨‹
ps aux | grep train_and_evaluate

# æŸ¥çœ‹å®æ—¶æ—¥å¿—
tail -f training.log
```

### 2. ä½¿ç”¨tmux/screenï¼ˆæ¨èï¼‰
```bash
# åˆ›å»ºæ–°ä¼šè¯
tmux new -s training

# è¿è¡Œè®­ç»ƒ
./train_and_evaluate.sh --dataset GCJ --epochs 10

# åˆ†ç¦»ä¼šè¯: Ctrl+B, ç„¶åæŒ‰D
# é‡æ–°è¿æ¥: tmux attach -t training
```

### 3. ç›‘æ§GPUä½¿ç”¨
```bash
# å®æ—¶ç›‘æ§
watch -n 1 nvidia-smi

# å¦ä¸€ä¸ªç»ˆç«¯çª—å£
tail -f logs/train_*.log
```

## ğŸ“ æ³¨æ„äº‹é¡¹

1. **é¦–æ¬¡è¿è¡Œ**: æ•°æ®é¢„å¤„ç†ä¼šå ç”¨é¢å¤–æ—¶é—´ï¼ˆ5-15åˆ†é’Ÿï¼‰
2. **éªŒè¯é¢‘ç‡**: é»˜è®¤æ¯1750æ­¥éªŒè¯ä¸€æ¬¡ï¼Œä¼šå¢åŠ æ€»æ—¶é—´
3. **æœ€ä½³æ¨¡å‹ä¿å­˜**: åªä¿å­˜éªŒè¯é›†ä¸Šæœ€ä½³çš„æ¨¡å‹
4. **TensorBoard**: å®æ—¶è®°å½•ä¸å½±å“è®­ç»ƒé€Ÿåº¦
5. **æ˜¾å­˜å ç”¨**: è®­ç»ƒæ—¶çº¦å ç”¨6-8GBæ˜¾å­˜ï¼ˆbatch_size=64ï¼‰

## ğŸ¯ æ¨èæ‰§è¡Œé¡ºåº

```bash
# Day 1: éªŒè¯ç¯å¢ƒ (10åˆ†é’Ÿ)
./quick_train.sh OJClone 2

# Day 1-2: ç¬¬ä¸€ä¸ªå®Œæ•´è®­ç»ƒ (2å°æ—¶)
./train_and_evaluate.sh --dataset OJClone --epochs 10

# Day 2-3: ä¸­ç­‰è§„æ¨¡ (12å°æ—¶ï¼Œè¿‡å¤œ)
./train_and_evaluate.sh --dataset GCJ --epochs 10

# Day 3-4: å¤§è§„æ¨¡ (15å°æ—¶ï¼Œè¿‡å¤œ)
./train_and_evaluate.sh --dataset BCB --epochs 10
```

---

**æ€»ç»“**:
- å¿«é€Ÿæµ‹è¯•: **5-10åˆ†é’Ÿ**
- å®Œæ•´å°æ•°æ®é›†: **1.5-2å°æ—¶**
- å®Œæ•´ä¸­æ•°æ®é›†: **11-14å°æ—¶** â­ ä¸»è¦åœºæ™¯
- å®Œæ•´å¤§æ•°æ®é›†: **14-17å°æ—¶**

**GPUåˆ©ç”¨ç‡**: RTX 3080èƒ½å¤Ÿé«˜æ•ˆè®­ç»ƒæ­¤æ¨¡å‹ï¼Œé¢„è®¡GPUåˆ©ç”¨ç‡70-90%

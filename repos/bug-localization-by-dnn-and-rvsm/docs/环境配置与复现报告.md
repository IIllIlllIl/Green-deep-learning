# Bug Localization DNN+rVSM 模型复现报告

## 1. 仓库模型训练类型分析

### 1.1 模型类型
该仓库包含两个模型的本地训练实现：

1. **rVSM模型** (Information Retrieval Model)
   - 位置: `src/rvsm_model.py`
   - 类型: 基于余弦相似度的信息检索模型
   - 训练方式: 无需训练，直接使用rVSM相似度特征进行预测

2. **DNN模型** (Deep Neural Network)
   - 位置: `src/dnn_model.py`
   - 类型: 多层感知器回归模型 (MLPRegressor)
   - 训练方式: 本地训练，使用scikit-learn的MLPRegressor
   - 网络结构:
     - 输入层: 5个特征 (rVSM_similarity, collab_filter, classname_similarity, bug_recency, bug_frequency)
     - 隐藏层: 1层，300个神经元
     - 优化器: SGD
     - 最大迭代次数: 10000
     - 早停策略: 30次迭代无改善

### 1.2 训练流程
- **主程序**: `src/main.py`
  - 执行10折交叉验证的DNN模型训练
  - 执行rVSM基线模型评估
- **特征提取**: `src/feature_extraction.py` (可选，已有预提取特征)
  - 从Eclipse源码仓库提取特征
  - 并行处理加速特征提取

## 2. Conda环境配置

### 2.1 环境创建
已创建conda环境 `dnn_rvsm`，配置如下：

```bash
环境名称: dnn_rvsm
Python版本: 3.7.12
```

### 2.2 依赖包安装
已安装以下依赖包（来自requirements.txt）：

| 包名 | 版本 | 用途 |
|------|------|------|
| joblib | 0.13.2 | 并行处理 |
| nltk | 3.4.3 | 自然语言处理 |
| numpy | 1.16.4 | 数值计算 |
| scikit-learn | 0.21.2 | 机器学习模型 |
| scipy | 1.5.4 | 科学计算（依赖） |

### 2.3 NLTK数据配置
**状态**: 部分配置
- **punkt tokenizer**: ✓ 已存在 (位于 ~/nltk_data/tokenizers/punkt)
- **stopwords**: ✗ 需要手动配置（由于网络/SSL问题）

**解决方案**:
NLTK stopwords数据由于网络问题无法自动下载，但这不会影响模型训练，因为：
1. 已提取的特征文件 (`data/features.csv`) 已经包含所有处理后的特征
2. 只有在重新提取特征时才需要stopwords
3. 如需重新提取特征，可以手动下载stopwords数据或在网络稳定时重试

## 3. 数据集和模型检查

### 3.1 现有数据集
以下数据集已存在于 `data/` 目录：

| 文件名 | 大小 | 用途 | 状态 |
|--------|------|------|------|
| Eclipse_Platform_UI.txt | 9.7 MB | Bug报告数据集（TSV格式） | ✓ 完整 |
| features.csv | 38.7 MB | 预提取特征（262,600行） | ✓ 完整 |

### 3.2 数据集内容
- **Bug报告数据集**: Eclipse Platform UI项目的bug报告
  - 来源: https://github.com/logpai/bugrepo/tree/master/EclipsePlatform
  - 格式: Tab分隔值文件
  - 包含字段: bug_id, summary, description, report_time, files等

- **特征数据集**: 已提取的特征向量
  - 每个bug报告对应51个样本（1个正样本 + 50个负样本）
  - 特征维度: 5 (rVSM相似度, 协同过滤, 类名相似度, bug修复时间, bug修复频率)
  - 标签: match (0或1)

### 3.3 缺失数据
**Eclipse源码仓库**: 未克隆
- 仓库URL: https://github.com/eclipse/eclipse.platform.ui.git
- 用途: 仅在重新提取特征时需要
- **当前状态**: 不影响模型训练，因为features.csv已包含所有特征

**结论**: 无需下载额外数据，可以直接使用现有数据进行模型训练。

## 4. 设备规格

### 4.1 硬件配置
```
CPU: Intel Xeon Silver 4210R @ 2.40GHz
  - 核心数: 10核/插槽 × 2线程 = 20逻辑核心
  - 主频: 2.40GHz
内存: 30 GB
GPU: NVIDIA GeForce RTX 3080 (10GB VRAM)
```

### 4.2 训练资源利用
- **DNN训练**: 主要使用CPU（scikit-learn不支持GPU加速）
- **并行处理**: 利用19个CPU核心（n_jobs=-2，保留1核）
- **内存占用**: 预计2-5 GB（特征数据集38.7 MB + 模型训练）

## 5. 训练时长估计

### 5.1 DNN模型（10折交叉验证）

基于以下参数估计：
- 训练样本数: 约236,340样本（90%数据，含过采样）
- 特征维度: 5
- 网络结构: 300隐藏单元
- 最大迭代: 10,000次
- 并行折数: 19个核心同时训练

**预计单折训练时间**: 3-8分钟
**预计总训练时间**: 5-15分钟（由于并行训练）

### 5.2 rVSM模型
**预计训练时间**: < 1分钟（无需训练，仅计算相似度）

### 5.3 总体评估
**总训练时间**: 约10-20分钟（远低于2小时阈值）

**结论**: ✓ 训练时间在可接受范围内，无需优化

## 6. 训练时间优化建议（备选）

虽然当前训练时间已经很短，但如果需要进一步加速，可以考虑以下策略：

### 6.1 减少交叉验证折数
```python
# 当前: 10折交叉验证
dnn_model_kfold(10)

# 优化: 5折交叉验证（减少50%训练时间）
dnn_model_kfold(5)
```
影响: 可能略微降低评估精度，但训练速度提升约50%

### 6.2 减少最大迭代次数
```python
# 当前设置
MLPRegressor(max_iter=10000, n_iter_no_change=30)

# 优化设置
MLPRegressor(max_iter=5000, n_iter_no_change=20)
```
影响: 由于已有早停机制，实际影响较小

### 6.3 调整并行核心数
```python
# 当前: 使用所有核心-2 (即19核)
Parallel(n_jobs=-2)

# 无需调整，已经是最优配置
```

### 6.4 减少训练样本（不推荐）
```python
# 可以减少负样本数量，但会影响模型性能
def top_k_wrong_files(..., k=50):  # 当前50个负样本
    # 改为 k=25 可以减少训练数据量
```
影响: 显著降低模型性能，不建议使用

## 7. 使用指南

### 7.1 激活环境
```bash
conda activate dnn_rvsm
```

### 7.2 运行训练
```bash
cd /home/green/energy_dl/test/bug-localization-by-dnn-and-rvsm/src
python main.py
```

### 7.3 预期输出
```
DNN模型 (10折交叉验证):
{1: 0.XXX, 5: 0.XXX, 10: 0.XXX, 20: 0.XXX, ...}

rVSM模型:
{1: 0.XXX, 5: 0.XXX, 10: 0.XXX, 20: 0.XXX, ...}
```

其中，数字表示Top-K准确率（K=1, 5, 10, 20）

## 8. 注意事项

1. **NLTK Stopwords警告**: 运行时可能会出现stopwords相关警告，但不影响训练，因为使用的是预提取的特征数据
2. **训练进度**: 控制台会显示当前训练的折数（Fold: X / 10）
3. **内存使用**: 并行训练会占用较多内存，建议关闭其他占用内存的程序
4. **结果保存**: 当前代码只输出结果到控制台，如需保存结果，建议使用重定向: `python main.py > results.txt`

## 9. 故障排除

### 9.1 导入错误
```bash
# 确保环境已激活
conda activate dnn_rvsm

# 验证包安装
python -c "import sklearn; import numpy; import nltk; import joblib; print('OK')"
```

### 9.2 文件路径错误
确保在 `src/` 目录下运行脚本，因为代码使用相对路径 `../data/`

### 9.3 内存不足
如果出现内存错误，可以减少并行核心数：
```python
# 在 dnn_model.py 中修改
Parallel(n_jobs=10)  # 从-2改为10
```

## 10. 总结

- ✓ 环境配置完成（conda环境 + 依赖包）
- ✓ 数据集完整（无需额外下载）
- ✓ 训练时间合理（预计10-20分钟）
- ✓ 硬件资源充足（20核CPU + 30GB内存 + RTX 3080）
- ⚠ NLTK stopwords缺失（不影响当前训练）

**可以开始模型训练！**

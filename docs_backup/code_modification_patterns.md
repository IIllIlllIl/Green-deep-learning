# è¶…å‚æ•°æ·»åŠ æ¨¡å¼ï¼šä¿æŒåŸå§‹é»˜è®¤å€¼

## ğŸ“Œ æ ¸å¿ƒåŸåˆ™

**åœ¨æ·»åŠ æ–°çš„è¶…å‚æ•°æ”¯æŒæ—¶ï¼Œå¿…é¡»ç¡®ä¿ï¼š**
1. âœ… ä¸ä¼ å‚æ•°æ—¶ = åŸå§‹è®­ç»ƒè¡Œä¸º
2. âœ… ä¼ å‚æ•°æ—¶ = å¯ç”¨æ–°åŠŸèƒ½
3. âœ… é»˜è®¤å€¼å¿…é¡»ä¸åŸå§‹ä»£ç è¡Œä¸ºå®Œå…¨ä¸€è‡´

---

## ğŸ¯ æ ‡å‡†æ¨¡å¼

### æ¨¡å¼1: æ·»åŠ åŸå§‹ä¸å­˜åœ¨çš„å‚æ•°ï¼ˆå¦‚seedï¼‰

#### âŒ é”™è¯¯åšæ³•ï¼ˆä¼šæ”¹å˜åŸå§‹è¡Œä¸ºï¼‰
```python
# train.py
parser.add_argument('--seed', type=int, default=42, help='random seed')

# è®­ç»ƒä»£ç 
args = parser.parse_args()
torch.manual_seed(args.seed)  # âŒ å³ä½¿ä¸ä¼ --seedï¼Œä¹Ÿä¼šè®¾ç½®seed=42
```

**é—®é¢˜**: åŸå§‹ä»£ç æ²¡æœ‰seedï¼Œç°åœ¨é»˜è®¤ä½¿ç”¨42ï¼Œæ”¹å˜äº†åŸå§‹éšæœºæ€§ï¼

---

#### âœ… æ­£ç¡®åšæ³•1ï¼ˆä½¿ç”¨Noneä½œä¸ºé»˜è®¤å€¼ï¼‰
```python
# train.py
parser.add_argument('--seed', type=int, default=None,
                    help='random seed (default: None, uses random behavior)')

# è®­ç»ƒä»£ç 
args = parser.parse_args()

# åªæœ‰æ˜ç¡®ä¼ å…¥seedæ—¶æ‰è®¾ç½®
if args.seed is not None:
    torch.manual_seed(args.seed)
    torch.cuda.manual_seed_all(args.seed)
    np.random.seed(args.seed)
    random.seed(args.seed)
    # å¯é€‰ï¼šè®¾ç½®ç¡®å®šæ€§
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False
    print(f"Using seed: {args.seed}")
else:
    print("No seed set - using non-deterministic training (original behavior)")
```

**æ•ˆæœ**:
- `./train.sh` â†’ ä¸è®¾ç½®seedï¼ˆåŸå§‹è¡Œä¸ºï¼‰âœ…
- `./train.sh --seed 42` â†’ è®¾ç½®seed=42ï¼ˆæ–°åŠŸèƒ½ï¼‰âœ…

---

#### âœ… æ­£ç¡®åšæ³•2ï¼ˆæ¨èç”¨äºå®éªŒï¼‰
```python
# train.py
parser.add_argument('--seed', type=int, default=None,
                    help='random seed (default: None)')

# è®­ç»ƒä»£ç 
args = parser.parse_args()

# å¦‚æœå®éªŒæ¡†æ¶è¦æ±‚æ‰€æœ‰å®éªŒå¯é‡å¤ï¼Œå¯ä»¥åœ¨è¿™é‡Œè®¾ç½®é»˜è®¤å€¼
if args.seed is None:
    args.seed = 42  # ä¸ºå®éªŒè®¾ç½®é»˜è®¤å€¼
    print(f"No seed specified, using default seed: {args.seed} for reproducibility")

# è®¾ç½®seed
torch.manual_seed(args.seed)
torch.cuda.manual_seed_all(args.seed)
np.random.seed(args.seed)
random.seed(args.seed)
```

**é€‚ç”¨åœºæ™¯**: å½“å®éªŒå¯é‡å¤æ€§æ¯”å®Œå…¨ä¿æŒåŸå§‹è¡Œä¸ºæ›´é‡è¦

---

### æ¨¡å¼2: æ·»åŠ åŸå§‹ä¸å­˜åœ¨çš„precisionå‚æ•°

#### âŒ é”™è¯¯åšæ³•
```python
# train.py
parser.add_argument('--precision', type=str, default='fp16',
                    choices=['fp16', 'bf16', 'fp32'])

# è®­ç»ƒå¾ªç¯
if args.precision == 'fp16':
    with torch.cuda.amp.autocast():  # âŒ é»˜è®¤å°±å¯ç”¨fp16äº†ï¼
        ...
```

**é—®é¢˜**: åŸå§‹ä»£ç ä½¿ç”¨fp32ï¼Œç°åœ¨é»˜è®¤fp16ï¼Œæ€§èƒ½ä¼šä¸åŒï¼

---

#### âœ… æ­£ç¡®åšæ³•ï¼ˆMRT-OASTç¤ºä¾‹ï¼‰
```python
# main_batch.py
parser.add_argument('--precision', type=str, default=None,
                    choices=['fp16', 'bf16', 'fp32', None],
                    help='Mixed precision training (default: None, uses fp32)')

# æˆ–è€…æ›´æ˜ç¡®çš„æ–¹å¼
parser.add_argument('--fp16', action='store_true',
                    help='Use fp16 mixed precision')
parser.add_argument('--bf16', action='store_true',
                    help='Use bf16 mixed precision')

# è®­ç»ƒå¾ªç¯
args = parser.parse_args()

# ç¡®å®šä½¿ç”¨çš„ç²¾åº¦
use_amp = False
amp_dtype = torch.float32

if args.fp16:
    use_amp = True
    amp_dtype = torch.float16
elif args.bf16:
    use_amp = True
    amp_dtype = torch.bfloat16

# åˆ›å»ºGradScalerï¼ˆåªåœ¨ä½¿ç”¨æ··åˆç²¾åº¦æ—¶ï¼‰
scaler = torch.cuda.amp.GradScaler(enabled=use_amp)

# è®­ç»ƒå¾ªç¯
for data, target in train_loader:
    if use_amp:
        with torch.cuda.amp.autocast(dtype=amp_dtype):
            output = model(data)
            loss = criterion(output, target)
        scaler.scale(loss).backward()
        scaler.step(optimizer)
        scaler.update()
    else:
        # åŸå§‹è®­ç»ƒæ–¹å¼ï¼ˆfp32ï¼‰
        output = model(data)
        loss = criterion(output, target)
        loss.backward()
        optimizer.step()
```

**æ•ˆæœ**:
- `./train.sh` â†’ ä½¿ç”¨fp32ï¼ˆåŸå§‹è¡Œä¸ºï¼‰âœ…
- `./train.sh --fp16` â†’ ä½¿ç”¨fp16æ··åˆç²¾åº¦ âœ…
- `./train.sh --bf16` â†’ ä½¿ç”¨bf16æ··åˆç²¾åº¦ âœ…

---

### æ¨¡å¼3: æ·»åŠ åŸå§‹ä¸å­˜åœ¨çš„weight_decayå‚æ•°

#### âŒ é”™è¯¯åšæ³•ï¼ˆMRT-OASTï¼‰
```python
# main_batch.py
parser.add_argument('--weight_decay', type=float, default=1e-4,
                    help='weight decay')

# ä¼˜åŒ–å™¨
optimizer = optim.Adam(model.parameters(), lr=args.lr,
                       weight_decay=args.weight_decay)  # âŒ åŸå§‹ä»£ç æ˜¯0ï¼Œç°åœ¨æ˜¯1e-4ï¼
```

---

#### âœ… æ­£ç¡®åšæ³•
```python
# main_batch.py
parser.add_argument('--weight_decay', type=float, default=0,
                    help='weight decay (default: 0, matches original code)')

# ä¼˜åŒ–å™¨ï¼ˆä¸åŸå§‹ä»£ç ä¿æŒä¸€è‡´ï¼‰
optimizer = optim.Adam(model.parameters(), lr=args.lr,
                       weight_decay=args.weight_decay)  # é»˜è®¤ä¸º0 âœ…
```

**å…³é”®**: æŸ¥çœ‹åŸå§‹ä¼˜åŒ–å™¨é…ç½®ï¼Œç¡®ä¿é»˜è®¤å€¼ä¸€è‡´ï¼

åŸå§‹MRT-OASTä»£ç ï¼š
```python
# åŸå§‹ main_batch.py:105
optimizer = optim.Adam(model.parameters(), lr=1.0)
# æ²¡æœ‰weight_decayå‚æ•° â†’ é»˜è®¤å€¼æ˜¯0
```

---

### æ¨¡å¼4: ä¿®æ”¹å·²æœ‰å‚æ•°ä½†æ”¹å˜é»˜è®¤å€¼ï¼ˆè°¨æ…ï¼ï¼‰

#### âŒ ç»å¯¹ç¦æ­¢
```python
# pytorch_resnet_cifar10/trainer.py åŸå§‹ä»£ç 
parser.add_argument('--weight-decay', '--wd', default=1e-4, type=float)

# âŒ é”™è¯¯ä¿®æ”¹
parser.add_argument('--weight-decay', '--wd', default=5e-4, type=float)
# æ”¹å˜äº†é»˜è®¤å€¼ï¼ä¼šå½±å“åŸå§‹æ€§èƒ½ï¼
```

---

#### âœ… æ­£ç¡®åšæ³•ï¼ˆä¿æŒåŸå§‹é»˜è®¤å€¼ï¼‰
```python
# pytorch_resnet_cifar10/trainer.py
# ä¿æŒåŸå§‹é»˜è®¤å€¼ä¸å˜
parser.add_argument('--weight-decay', '--wd', default=1e-4, type=float,
                    metavar='W', help='weight decay (default: 1e-4)')
# âœ… é»˜è®¤å€¼ä»ç„¶æ˜¯1e-4ï¼Œä¸åŸå§‹ä»£ç ä¸€è‡´
```

---

## ğŸ“š å„ä»“åº“å…·ä½“ä¿®æ”¹ç¤ºä¾‹

### ç¤ºä¾‹1: pytorch_resnet_cifar10 æ·»åŠ seed

#### ä¿®æ”¹æ–‡ä»¶: `trainer.py`

```python
# åœ¨argparseéƒ¨åˆ†æ·»åŠ ï¼ˆç¬¬57è¡Œé™„è¿‘ï¼‰
parser.add_argument('--seed', type=int, default=None,
                    help='random seed for reproducibility (default: None)')

# åœ¨mainå‡½æ•°ä¸­ï¼Œæ¨¡å‹åˆ›å»ºä¹‹å‰æ·»åŠ 
def main():
    global args, best_prec1
    args = parser.parse_args()

    # === æ–°å¢ï¼šè®¾ç½®seed ===
    if args.seed is not None:
        import random
        import numpy as np

        random.seed(args.seed)
        np.random.seed(args.seed)
        torch.manual_seed(args.seed)
        torch.cuda.manual_seed_all(args.seed)

        # æ³¨æ„ï¼šåŸå§‹ä»£ç æœ‰ cudnn.benchmark = True (line 89)
        # è®¾ç½®seedæ—¶éœ€è¦è¦†ç›–å®ƒ
        cudnn.deterministic = True
        cudnn.benchmark = False
        print(f"Using seed: {args.seed} (deterministic mode)")
    else:
        # ä¿æŒåŸå§‹è¡Œä¸º
        cudnn.benchmark = True  # åŸå§‹ä»£ç ç¬¬89è¡Œ
        print("No seed set - using non-deterministic training (original behavior)")
    # === æ–°å¢ç»“æŸ ===

    # æ£€æŸ¥save_dir...ï¼ˆåŸå§‹ä»£ç ç»§ç»­ï¼‰
    if not os.path.exists(args.save_dir):
        os.makedirs(args.save_dir)
    # ...
```

#### train.shä¿®æ”¹

```bash
# åœ¨å‚æ•°è§£æéƒ¨åˆ†æ·»åŠ ï¼ˆç¬¬56è¡Œé™„è¿‘ï¼‰
--seed)
    SEED="$2"
    shift 2
    ;;

# åœ¨æ„å»ºè®­ç»ƒå‘½ä»¤æ—¶ï¼ˆç¬¬200è¡Œé™„è¿‘ï¼‰
TRAIN_CMD="$PYTHON -u trainer.py \
    --arch=$MODEL_NAME \
    --epochs=$EPOCHS \
    ...
    $([ -n "$SEED" ] && echo "--seed=$SEED") \
    $USE_HALF"
```

---

### ç¤ºä¾‹2: MRT-OAST æ·»åŠ weight_decay

#### ä¿®æ”¹æ–‡ä»¶: `main_batch.py`

```python
# åœ¨argparseéƒ¨åˆ†æ·»åŠ ï¼ˆç¬¬201è¡Œé™„è¿‘ï¼Œseedå‚æ•°ä¹‹åï¼‰
parser.add_argument("--weight_decay", type=float, default=0,
                    help="weight decay (L2 penalty) (default: 0)")

# ä¿®æ”¹ä¼˜åŒ–å™¨éƒ¨åˆ†ï¼ˆç¬¬105è¡Œï¼‰
# åŸå§‹ä»£ç ï¼š
# optimizer = optim.Adam(model.parameters(), lr=1.0)

# ä¿®æ”¹ä¸ºï¼š
optimizer = optim.Adam(model.parameters(), lr=1.0,
                       weight_decay=args.weight_decay)  # æ·»åŠ è¿™ä¸ªå‚æ•°
```

#### train.shä¿®æ”¹

```bash
# åœ¨é»˜è®¤å‚æ•°éƒ¨åˆ†æ·»åŠ ï¼ˆç¬¬92è¡Œé™„è¿‘ï¼‰
WEIGHT_DECAY=0  # ä¸ä»£ç é»˜è®¤å€¼ä¸€è‡´

# åœ¨å‚æ•°è§£ææ·»åŠ 
--weight-decay)
    WEIGHT_DECAY="$2"
    shift 2
    ;;

# åœ¨è®­ç»ƒå‘½ä»¤æ„å»ºæ·»åŠ 
TRAIN_CMD="python main_batch.py \
    ...
    --dropout $DROPOUT \
    --weight_decay $WEIGHT_DECAY \
    --seed $SEED \
    ...
```

---

### ç¤ºä¾‹3: Person_reID_baseline_pytorch æ·»åŠ seed

#### ä¿®æ”¹æ–‡ä»¶: `train.py`

```python
# åœ¨argparseéƒ¨åˆ†æ·»åŠ ï¼ˆç¬¬86è¡Œwarm_epochä¹‹åï¼‰
parser.add_argument('--seed', default=None, type=int,
                    help='random seed for reproducibility (default: None)')

# åœ¨å¼€å§‹è®­ç»ƒå‰æ·»åŠ ï¼ˆæ‰¾åˆ°GPUè®¾ç½®éƒ¨åˆ†åï¼‰
# åŸå§‹ä»£ç å¤§çº¦åœ¨ç¬¬200è¡Œæœ‰use_gpuç›¸å…³ä»£ç 
# åœ¨é‚£ä¹‹åæ·»åŠ ï¼š

args = parser.parse_args()

# === æ–°å¢seedè®¾ç½® ===
if args.seed is not None:
    import random
    import numpy as np

    random.seed(args.seed)
    np.random.seed(args.seed)
    torch.manual_seed(args.seed)
    torch.cuda.manual_seed_all(args.seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False
    print(f"Using seed: {args.seed}")
# === æ–°å¢ç»“æŸ ===
```

#### train.shä¿®æ”¹ï¼ˆå·²ç»æœ‰æ¨¡æ¿äº†ï¼‰

```bash
# åœ¨é»˜è®¤å‚æ•°éƒ¨åˆ†æ·»åŠ 
SEED=""  # ç©ºå­—ç¬¦ä¸²è¡¨ç¤ºä¸è®¾ç½®

# åœ¨å‚æ•°è§£ææ·»åŠ 
--seed)
    SEED="$2"
    shift 2
    ;;

# åœ¨æ„å»ºè®­ç»ƒå‘½ä»¤æ—¶
build_train_command() {
    local cmd="$PYTHON_PATH train.py"
    ...
    [ -n "$SEED" ] && cmd="$cmd --seed $SEED"
    ...
    echo "$cmd"
}
```

---

### ç¤ºä¾‹4: VulBERTa æ·»åŠ weight_decay

#### ä¿®æ”¹æ–‡ä»¶: `train_vulberta.py`

```python
# åœ¨argparseæ·»åŠ ï¼ˆç¬¬167è¡Œé™„è¿‘ï¼Œfp16ä¹‹åï¼‰
parser.add_argument('--weight_decay', type=float, default=None,
                    help='Weight decay (default: 0 for both MLP and CNN)')

# åœ¨è®¾ç½®æ¨¡å‹é»˜è®¤å€¼æ—¶ï¼ˆç¬¬188-197è¡Œï¼‰
if args.model_name == 'mlp':
    if args.batch_size is None:
        args.batch_size = 2
    ...
    if args.weight_decay is None:
        args.weight_decay = 0  # æ–°å¢
else:  # cnn
    if args.batch_size is None:
        args.batch_size = 128
    ...
    if args.weight_decay is None:
        args.weight_decay = 0  # æ–°å¢

# åœ¨TrainingArgumentsä¸­æ·»åŠ ï¼ˆç¬¬296-309è¡Œï¼‰
training_args = TrainingArguments(
    output_dir=output_dir,
    ...
    learning_rate=args.learning_rate,
    weight_decay=args.weight_decay,  # æ–°å¢è¿™ä¸€è¡Œ
    fp16=args.fp16,
    ...
)
```

#### train.shä¿®æ”¹ï¼ˆå·²ç»å¾ˆç®€å•ï¼Œç›´æ¥ä¼ å‚å³å¯ï¼‰

```bash
# VulBERTaçš„train.shå·²ç»ç›´æ¥ä¼ æ‰€æœ‰å‚æ•°ç»™Python
# åªéœ€è¦åœ¨å¸®åŠ©ä¿¡æ¯ä¸­æ·»åŠ è¯´æ˜
show_help() {
    cat << EOF
...
Optional arguments:
    ...
    --weight_decay DECAY  Weight decay (default: 0)
...
EOF
}
```

---

## âœ… éªŒè¯æ¸…å•

åœ¨ä¿®æ”¹å®Œä»£ç åï¼Œè¿è¡Œä»¥ä¸‹æµ‹è¯•éªŒè¯é»˜è®¤è¡Œä¸ºï¼š

### æµ‹è¯•1: ä¸ä¼ å‚æ•°ï¼ˆéªŒè¯åŸå§‹é»˜è®¤è¡Œä¸ºï¼‰
```bash
# åº”è¯¥ä½¿ç”¨æ‰€æœ‰åŸå§‹é»˜è®¤å€¼
./train.sh

# æ£€æŸ¥è¾“å‡ºæ—¥å¿—ï¼Œç¡®è®¤ï¼š
# - seed: None (æˆ–æœªè®¾ç½®seedç›¸å…³æ—¥å¿—)
# - weight_decay: [åŸå§‹é»˜è®¤å€¼]
# - precision: fp32 (æ— æ··åˆç²¾åº¦æ—¥å¿—)
# - å…¶ä»–å‚æ•°ä½¿ç”¨åŸå§‹é»˜è®¤å€¼
```

### æµ‹è¯•2: ä¼ å…¥æ–°å‚æ•°ï¼ˆéªŒè¯æ–°åŠŸèƒ½ï¼‰
```bash
# æµ‹è¯•seed
./train.sh --seed 42
# åº”è¯¥çœ‹åˆ°: "Using seed: 42" æˆ–ç±»ä¼¼æ—¥å¿—

# æµ‹è¯•precision
./train.sh --fp16
# åº”è¯¥çœ‹åˆ°: æ··åˆç²¾åº¦è®­ç»ƒç›¸å…³æ—¥å¿—

# æµ‹è¯•weight_decay
./train.sh --weight_decay 0.001
# æ£€æŸ¥ä¼˜åŒ–å™¨é…ç½®æ—¥å¿—
```

### æµ‹è¯•3: å¯¹æ¯”ç»“æœï¼ˆå¯é€‰ï¼‰
```bash
# baselineï¼ˆä½¿ç”¨é»˜è®¤å€¼ï¼‰
./train.sh 2>&1 | tee baseline.log

# ä½¿ç”¨ä¹‹å‰ä¿å­˜çš„åŸå§‹è®­ç»ƒæ—¥å¿—å¯¹æ¯”
# éªŒè¯lossæ›²çº¿ã€å‡†ç¡®ç‡æ˜¯å¦ä¸€è‡´ï¼ˆå…è®¸å°å¹…æ³¢åŠ¨ï¼‰
```

---

## âš ï¸ å¸¸è§é™·é˜±

### é™·é˜±1: å¿˜è®°æ£€æŸ¥åŸå§‹ä¼˜åŒ–å™¨é…ç½®
```python
# âŒ å‡è®¾åŸå§‹æœ‰weight_decay
parser.add_argument('--weight_decay', default=1e-4)

# âœ… å…ˆæŸ¥çœ‹åŸå§‹ä»£ç 
# å¦‚æœåŸå§‹optimizeræ²¡æœ‰weight_decayå‚æ•°ï¼Œé»˜è®¤å€¼åº”è¯¥æ˜¯0ï¼
parser.add_argument('--weight_decay', default=0)
```

### é™·é˜±2: ä¿®æ”¹äº†cudnn.benchmarkè®¾ç½®
```python
# åŸå§‹ä»£ç 
cudnn.benchmark = True  # ä½¿ç”¨éç¡®å®šæ€§ç®—æ³•åŠ é€Ÿ

# âŒ é”™è¯¯ï¼šæ€»æ˜¯è®¾ç½®deterministic
cudnn.deterministic = True
cudnn.benchmark = False

# âœ… æ­£ç¡®ï¼šåªåœ¨è®¾ç½®seedæ—¶ä¿®æ”¹
if args.seed is not None:
    cudnn.deterministic = True
    cudnn.benchmark = False
else:
    cudnn.benchmark = True  # ä¿æŒåŸå§‹è®¾ç½®
```

### é™·é˜±3: precisionå‚æ•°çš„äº’æ–¥æ€§
```python
# âŒ é”™è¯¯ï¼šå…è®¸åŒæ—¶è®¾ç½®fp16å’Œbf16
parser.add_argument('--fp16', action='store_true')
parser.add_argument('--bf16', action='store_true')
# æ²¡æœ‰äº’æ–¥æ£€æŸ¥ï¼

# âœ… æ­£ç¡®ï¼šæ·»åŠ äº’æ–¥æ£€æŸ¥
args = parser.parse_args()
if args.fp16 and args.bf16:
    raise ValueError("Cannot use both --fp16 and --bf16")
```

### é™·é˜±4: ä¸åŒæ¨¡å‹çš„ä¸åŒé»˜è®¤å€¼
```python
# Person_reIDä¸­ä¸åŒæ¨¡å‹æœ‰ä¸åŒçš„lr
# âŒ é”™è¯¯ï¼šæ‰€æœ‰æ¨¡å‹ç”¨åŒä¸€ä¸ªé»˜è®¤å€¼
LR = 0.05

# âœ… æ­£ç¡®ï¼šæ ¹æ®æ¨¡å‹è®¾ç½®é»˜è®¤å€¼
case "$MODEL_NAME" in
    "pcb")
        LR=0.02  # PCBç‰¹æ®Šçš„lr
        ;;
    *)
        LR=0.05  # å…¶ä»–æ¨¡å‹é»˜è®¤lr
        ;;
esac
```

---

## ğŸ“ ä¿®æ”¹åçš„æ–‡æ¡£æ›´æ–°

æ¯æ¬¡ä¿®æ”¹ä»£ç åï¼Œå¿…é¡»æ›´æ–°ä»¥ä¸‹æ–‡æ¡£ï¼š

1. `original_hyperparameter_defaults.md`
   - æ›´æ–°å¯¹åº”ä»“åº“çš„å‚æ•°é»˜è®¤å€¼è¡¨
   - æ ‡æ³¨ä¿®æ”¹æ—¥æœŸå’Œä¿®æ”¹å†…å®¹

2. `hyperparameter_mutation_analysis.md`
   - æ›´æ–°æ”¯æŒæƒ…å†µç»Ÿè®¡
   - æ›´æ–°"éœ€è¦ä¿®æ”¹çš„æ–‡ä»¶"æ¸…å•

3. READMEæˆ–train.shçš„helpä¿¡æ¯
   - æ·»åŠ æ–°å‚æ•°çš„è¯´æ˜
   - æ ‡æ³¨é»˜è®¤å€¼

---

## ğŸ“ æœ€ä½³å®è·µæ€»ç»“

1. **Always use `None` for new optional parameters**
   - ä¾¿äºåŒºåˆ†"æœªè®¾ç½®"å’Œ"è®¾ç½®ä¸ºé»˜è®¤å€¼"

2. **æŸ¥çœ‹åŸå§‹ä¼˜åŒ–å™¨é…ç½®**
   - ç¡®è®¤å‚æ•°æ˜¯å¦å­˜åœ¨ï¼Œé»˜è®¤å€¼æ˜¯ä»€ä¹ˆ

3. **ä¿ç•™åŸå§‹çš„cudnn.benchmarkè®¾ç½®**
   - åªåœ¨æ˜ç¡®éœ€è¦æ—¶ä¿®æ”¹

4. **æ·»åŠ æ¸…æ™°çš„æ—¥å¿—**
   - æ‰“å°å®é™…ä½¿ç”¨çš„è¶…å‚æ•°å€¼
   - æ ‡æ³¨æ˜¯é»˜è®¤å€¼è¿˜æ˜¯ç”¨æˆ·æŒ‡å®š

5. **ç¼–å†™éªŒè¯æµ‹è¯•**
   - ä¸ä¼ å‚æ•° = åŸå§‹è¡Œä¸º
   - ä¼ å‚æ•° = æ–°åŠŸèƒ½å¯ç”¨

6. **æ–‡æ¡£åŒæ­¥æ›´æ–°**
   - ä»£ç ã€æ–‡æ¡£ã€é…ç½®æ–‡ä»¶ä¿æŒä¸€è‡´

---

**æ–‡æ¡£ç‰ˆæœ¬**: 1.0
**æœ€åæ›´æ–°**: 2025-11-05
**ä½œè€…**: Claude Code

**è®°ä½**: å®éªŒå¯é‡å¤æ€§å¾ˆé‡è¦ï¼Œä½†ä¿æŒåŸå§‹baselineè¡Œä¸ºåŒæ ·é‡è¦ï¼

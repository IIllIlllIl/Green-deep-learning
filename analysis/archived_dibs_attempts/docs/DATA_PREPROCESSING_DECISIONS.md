# æ•°æ®é¢„å¤„ç†å†³ç­–æ–‡æ¡£

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0
**åˆ›å»ºæ—¶é—´**: 2025-12-22
**çŠ¶æ€**: âœ… æ–¹æ¡ˆç¡®è®¤

---

## ğŸ“‹ æ‰§è¡Œæ‘˜è¦

æœ¬æ–‡æ¡£è®°å½•å› æœåˆ†ææ•°æ®é¢„å¤„ç†çš„ä¸‰ä¸ªå…³é”®å†³ç­–ï¼š
1. **æ•°æ®å®Œæ•´æ€§ä¸ç¼ºå¤±å€¼å¤„ç†** - ä»676è¡Œç­›é€‰åˆ°284è¡Œä¸¥æ ¼å®Œæ•´æ•°æ®
2. **æ•æ„Ÿå±æ€§äºŒå€¼åŒ–** - modeç¼–ç ä¸º0/1ï¼ˆéå¹¶è¡Œ=0ï¼Œå¹¶è¡Œ=1ï¼‰
3. **ç±»åˆ«å˜é‡æ•°å€¼åŒ–** - One-Hotç¼–ç æ–¹æ¡ˆ

---

## é—®é¢˜1ï¼šæ•°æ®å®Œæ•´æ€§ä¸ç¼ºå¤±å€¼å¤„ç†

### 1.1 åŸå§‹æ•°æ®çŠ¶å†µ

**æ€»æ•°æ®**: 676è¡Œå®éªŒ

**æ•°æ®ç»“æ„å·®å¼‚**ï¼š
- **éå¹¶è¡Œå®éªŒ** (348è¡Œ)ï¼šæ•°æ®å­˜å‚¨åœ¨ä¸»åˆ—ï¼ˆå¦‚ `energy_cpu_total_joules`, `perf_test_accuracy`ï¼‰
- **å¹¶è¡Œå®éªŒ** (328è¡Œ)ï¼šæ•°æ®å­˜å‚¨åœ¨fg_*åˆ—ï¼ˆå¦‚ `fg_energy_cpu_total_joules`, `fg_perf_test_accuracy`ï¼‰

**æ•°æ®å®Œæ•´æ€§ç»Ÿè®¡**ï¼ˆä½¿ç”¨ç»Ÿä¸€æå–é€»è¾‘ï¼‰ï¼š

| æ•°æ®ç±»åˆ« | å®Œæ•´è¡Œæ•° | ç™¾åˆ†æ¯” |
|---------|---------|-------|
| æœ‰èƒ½è€—æ•°æ® | 537/676 | 79.4% |
| æœ‰æ€§èƒ½æ•°æ® | 391/676 | 57.8% |
| **èƒ½è€—+æ€§èƒ½** | **465/676** | **68.8%** |

### 1.2 å…³é”®åˆ—ç¼ºå¤±ç‡åˆ†æ

åŸºäº465è¡Œæœ‰èƒ½è€—+æ€§èƒ½çš„æ•°æ®ï¼š

#### âœ… å®Œå…¨å®Œæ•´ï¼ˆ100%ï¼‰

- èƒ½è€—æŒ‡æ ‡ï¼š`energy_cpu_total_joules`, `energy_gpu_total_joules`
- èƒ½è€—ä¸­ä»‹ï¼š`energy_gpu_util_avg_percent`, `energy_gpu_temp_max_celsius`, etc.ï¼ˆ5ä¸ªå˜é‡ï¼‰
- åˆ†ç»„æ ‡è¯†ï¼š`repository`, `model`

#### âš ï¸ éƒ¨åˆ†ç¼ºå¤±

- `hyperparam_learning_rate`: 57.6%
- `hyperparam_epochs`: 58.9%
- `hyperparam_batch_size`: 29.0%
- `mode`: **53.5%** â† ä¸»è¦ç¼ºå¤±æ¥æº

#### ğŸ” modeåˆ—ç¼ºå¤±åˆ†æ

```
modeåˆ—å–å€¼åˆ†å¸ƒï¼š
  (empty)   : 348ä¸ª (51.5%) â† éå¹¶è¡Œå®éªŒæœªå¡«å……mode
  parallel  : 328ä¸ª (48.5%) â† å¹¶è¡Œå®éªŒæœ‰modeå€¼
```

**æ ¹æœ¬åŸå› **ï¼šéå¹¶è¡Œå®éªŒçš„modeåˆ—æœªå¡«å……ï¼Œä½†è¯­ä¹‰ä¸Šåº”ä¸º"default"ï¼ˆæˆ–"single"ï¼‰ã€‚

### 1.3 âœ… å†³ç­–ï¼šç¼ºå¤±å€¼å¤„ç†æ–¹æ¡ˆ

#### æ–¹æ¡ˆç¡®è®¤

**é‡‡ç”¨"modeå¡«å…… + ä¸¥æ ¼è¿‡æ»¤"ç­–ç•¥**ï¼š

1. **modeåˆ—å¡«å……è§„åˆ™**ï¼š
   ```python
   if row['mode'] == '' or not row['mode']:
       row['mode'] = 'default'  # å¡«å……ä¸º'default'è¡¨ç¤ºéå¹¶è¡Œ
   ```

2. **ä¸¥æ ¼å®Œæ•´æ€§æ ‡å‡†**ï¼ˆä¿ç•™ä»¥ä¸‹è¡Œï¼‰ï¼š
   - âœ… èƒ½è€—æ•°æ®ï¼š`energy_cpu_total_joules` AND `energy_gpu_total_joules` éƒ½æœ‰å€¼
   - âœ… æ€§èƒ½æ•°æ®ï¼šè‡³å°‘ä¸€ä¸ªæ€§èƒ½æŒ‡æ ‡æœ‰å€¼ï¼ˆ`perf_test_accuracy` OR `perf_map` OR `perf_eval_loss` OR `perf_top1_accuracy`ï¼‰
   - âœ… è®­ç»ƒæ—¶é•¿ï¼š`hyperparam_epochs` OR `hyperparam_max_iter` è‡³å°‘ä¸€ä¸ªæœ‰å€¼
   - âœ… åˆ†ç»„æ ‡è¯†ï¼š`repository` AND `model` éƒ½æœ‰å€¼
   - âœ… æ•æ„Ÿå±æ€§ï¼š`mode` æœ‰å€¼ï¼ˆå¡«å……å100%æ»¡è¶³ï¼‰

3. **åˆ é™¤ç¼ºå¤±å€¼**ï¼š
   - ä¸æ»¡è¶³ä¸Šè¿°ä»»ä¸€æ¡ä»¶çš„è¡Œï¼Œå…¨éƒ¨åˆ é™¤

#### å¤„ç†åæ•°æ®é‡

```
åŸå§‹æ•°æ®:       676è¡Œ
ä¸¥æ ¼å®Œæ•´æ•°æ®:   284è¡Œ (42.0%)
åˆ é™¤ç¼ºå¤±å€¼:     392è¡Œ (58.0%)
```

#### å„ä»»åŠ¡ç»„æ ·æœ¬é‡

| ä»»åŠ¡ç»„ | æ ·æœ¬é‡ | DiBSå¯è¡Œæ€§ |
|-------|-------|-----------|
| examples (MNISTç³»åˆ—) | 153ä¸ª | âœ… å……è¶³ |
| Person_reID_baseline_pytorch | 86ä¸ª | âœ… å……è¶³ |
| pytorch_resnet_cifar10 | 21ä¸ª | âœ… å¯è¡Œ |
| VulBERTa | 14ä¸ª | âœ… å¯è¡Œ |
| bug-localization-by-dnn-and-rvsm | 10ä¸ª | âœ… æœ€ä½çº¿ï¼ˆåˆšå¥½æ»¡è¶³ï¼‰ |

**ç»“è®º**: æ‰€æœ‰ä»»åŠ¡ç»„éƒ½æ»¡è¶³DiBSæœ€ä½è¦æ±‚ï¼ˆ10ä¸ªæ ·æœ¬ï¼‰âœ…

---

## é—®é¢˜2ï¼šæ•æ„Ÿå±æ€§äºŒå€¼åŒ–ï¼ˆmodeç¼–ç ï¼‰

### 2.1 èƒŒæ™¯

å› æœæ¨æ–­ï¼ˆç‰¹åˆ«æ˜¯å…¬å¹³æ€§åˆ†æï¼‰è¦æ±‚**æ•æ„Ÿå±æ€§**å¿…é¡»æ˜¯**äºŒå€¼**ï¼ˆ0/1ï¼‰ã€‚

åœ¨æˆ‘ä»¬çš„ç ”ç©¶ä¸­ï¼š
- **æ•æ„Ÿå±æ€§** = è®­ç»ƒæ¨¡å¼ï¼ˆéå¹¶è¡Œ vs å¹¶è¡Œï¼‰
- **ç ”ç©¶é—®é¢˜**: å¹¶è¡Œè®­ç»ƒæ¨¡å¼æ˜¯å¦ä¼šå½±å“èƒ½è€—å’Œæ€§èƒ½ï¼Ÿ

### 2.2 âœ… å†³ç­–ï¼šmodeäºŒå€¼åŒ–ç¼–ç 

#### ç¼–ç è§„åˆ™

```python
mode_encoding = {
    'default': 0,   # éå¹¶è¡Œæ¨¡å¼
    '':        0,   # ç©ºå€¼å¡«å……ä¸ºdefaultåç¼–ç ä¸º0
    'parallel': 1   # å¹¶è¡Œæ¨¡å¼
}
```

#### è¯­ä¹‰è§£é‡Š

| modeåŸå§‹å€¼ | å¡«å……å | ç¼–ç å€¼ | è¯­ä¹‰ |
|-----------|--------|-------|------|
| `''` (ç©º) | `'default'` | **0** | å•ä»»åŠ¡è®­ç»ƒï¼ˆéå¹¶è¡Œï¼‰ |
| `'default'` | `'default'` | **0** | å•ä»»åŠ¡è®­ç»ƒï¼ˆéå¹¶è¡Œï¼‰ |
| `'parallel'` | `'parallel'` | **1** | å¹¶è¡Œè®­ç»ƒï¼ˆå‰å°+åå°ï¼‰ |

#### æ•°æ®åˆ†å¸ƒ

åŸºäº284è¡Œä¸¥æ ¼å®Œæ•´æ•°æ®ï¼š

```
mode=0 (éå¹¶è¡Œ):  145ä¸ª (51.1%)
mode=1 (å¹¶è¡Œ):    139ä¸ª (48.9%)
```

**ç»“è®º**: ä¸¤ç§æ¨¡å¼åˆ†å¸ƒå‡è¡¡ï¼Œé€‚åˆå› æœåˆ†æ âœ…

#### å®ç°ä»£ç 

```python
def binarize_mode(df):
    """modeäºŒå€¼åŒ–ç¼–ç """

    # 1. å¡«å……ç©ºå€¼
    df['mode'] = df['mode'].fillna('default')
    df['mode'] = df['mode'].replace('', 'default')

    # 2. ç¼–ç ä¸º0/1
    df['mode_binary'] = df['mode'].map({
        'default': 0,
        'parallel': 1
    })

    # 3. éªŒè¯
    assert df['mode_binary'].notna().all(), "å­˜åœ¨æ— æ³•ç¼–ç çš„modeå€¼"
    assert df['mode_binary'].isin([0, 1]).all(), "mode_binaryå¿…é¡»æ˜¯0æˆ–1"

    return df
```

---

## é—®é¢˜3ï¼šOne-Hotç¼–ç ï¼ˆç±»åˆ«å˜é‡æ•°å€¼åŒ–ï¼‰

### 3.1 ä»€ä¹ˆæ˜¯One-Hotç¼–ç ï¼Ÿ

**One-Hotç¼–ç **ï¼ˆç‹¬çƒ­ç¼–ç ï¼‰æ˜¯å°†**ç±»åˆ«å˜é‡**è½¬æ¢ä¸º**æ•°å€¼å‹**çš„æ ‡å‡†æ–¹æ³•ã€‚

#### æ ¸å¿ƒæ€æƒ³

å°†ä¸€ä¸ªæœ‰Nä¸ªç±»åˆ«çš„å˜é‡ï¼Œè½¬æ¢ä¸ºNä¸ªäºŒè¿›åˆ¶åˆ—ï¼ˆ0/1ï¼‰ï¼Œæ¯ä¸ªç±»åˆ«å¯¹åº”ä¸€åˆ—ã€‚

#### ç¤ºä¾‹1ï¼šæ°´æœç±»åˆ«

**åŸå§‹æ•°æ®**:
```
æ°´æœ: ['è‹¹æœ', 'é¦™è•‰', 'è‹¹æœ', 'æ©™å­']
```

**One-Hotç¼–ç å**:
```
è‹¹æœ  é¦™è•‰  æ©™å­
 1    0    0     â† ç¬¬1è¡Œï¼šè‹¹æœ
 0    1    0     â† ç¬¬2è¡Œï¼šé¦™è•‰
 1    0    0     â† ç¬¬3è¡Œï¼šè‹¹æœ
 0    0    1     â† ç¬¬4è¡Œï¼šæ©™å­
```

**ç‰¹ç‚¹**ï¼š
- æ¯è¡Œåªæœ‰ä¸€ä¸ª1ï¼ˆone-hot = åªæœ‰ä¸€ä¸ª"çƒ­"ä½ï¼‰
- å…¶ä½™å…¨æ˜¯0
- 3ä¸ªç±»åˆ« â†’ 3åˆ—äºŒè¿›åˆ¶å˜é‡

#### ç¤ºä¾‹2ï¼šæˆ‘ä»¬çš„repositoryåˆ—

**åŸå§‹æ•°æ®**ï¼ˆ5ä¸ªç±»åˆ«ï¼‰:
```
repository: ['examples', 'VulBERTa', 'examples', 'Person_reID', ...]
```

**One-Hotç¼–ç å**ï¼ˆ5åˆ—ï¼‰:
```
repo_examples  repo_VulBERTa  repo_Person_reID  repo_pytorch_resnet  repo_bug_loc
    1              0               0                 0                  0
    0              1               0                 0                  0
    1              0               0                 0                  0
    0              0               1                 0                  0
```

### 3.2 ä¸ºä»€ä¹ˆéœ€è¦One-Hotç¼–ç ï¼Ÿ

#### åŸå› 1ï¼šDiBSè¦æ±‚æ•°å€¼å‹è¾“å…¥

DiBSï¼ˆå› æœå›¾å­¦ä¹ ï¼‰ç®—æ³•è¦æ±‚æ‰€æœ‰è¾“å…¥å˜é‡å¿…é¡»æ˜¯**æ•°å€¼å‹**ï¼ˆfloatæˆ–intï¼‰ã€‚

ç±»åˆ«å˜é‡ï¼ˆå¦‚repository='VulBERTa'ï¼‰æ— æ³•ç›´æ¥è¾“å…¥DiBSã€‚

#### åŸå› 2ï¼šé¿å…é”™è¯¯çš„æ•°å€¼å…³ç³»

å¦‚æœç›´æ¥ç¼–ç ä¸ºæ•´æ•°ï¼š
```python
repository_code = {
    'examples': 1,
    'VulBERTa': 2,
    'Person_reID': 3
}
```

**é—®é¢˜**ï¼šç®—æ³•ä¼šè¯¯è®¤ä¸º `Person_reID (3)` > `VulBERTa (2)` > `examples (1)`ï¼Œä½†ç±»åˆ«ä¹‹é—´æ²¡æœ‰å¤§å°å…³ç³»ï¼

One-Hotç¼–ç é¿å…äº†è¿™ä¸ªé—®é¢˜ï¼Œå› ä¸ºæ¯ä¸ªç±»åˆ«éƒ½æ˜¯ç‹¬ç«‹çš„äºŒè¿›åˆ¶åˆ—ã€‚

### 3.3 âœ… å†³ç­–ï¼šæˆ‘ä»¬çš„One-Hotç¼–ç æ–¹æ¡ˆ

#### éœ€è¦ç¼–ç çš„åˆ—

**åœ¨åˆ†å±‚åˆ†æä¸­ï¼Œä¸éœ€è¦å¯¹repositoryå’Œmodelè¿›è¡ŒOne-Hotç¼–ç **ï¼Œå› ä¸ºï¼š
- æ¯ä¸ªä»»åŠ¡ç»„åªåŒ…å«ä¸€ä¸ªrepositoryï¼ˆå¦‚examplesï¼‰
- ä½†modelå¯èƒ½æœ‰å¤šä¸ªï¼ˆå¦‚mnist, mnist_ff, mnist_rnnï¼‰

**éœ€è¦One-Hotç¼–ç çš„åˆ—**ï¼š

1. **model**ï¼ˆåœ¨æ¯ä¸ªä»»åŠ¡ç»„å†…ï¼‰
   - ä¾‹å¦‚examplesç»„: mnist, mnist_ff, mnist_rnn, siamese â†’ 4åˆ—
   - ä¾‹å¦‚Person_reIDç»„: densenet121, hrnet18, pcb â†’ 3åˆ—

2. **å…¶ä»–ç±»åˆ«å‹è¶…å‚æ•°**ï¼ˆå¦‚æœæœ‰ï¼‰
   - ä¾‹å¦‚optimizerï¼ˆå¦‚æœå˜åŒ–ï¼‰: Adam, SGD, RMSprop â†’ 3åˆ—

#### å®ç°ä»£ç 

##### æ–¹æ³•1ï¼šä½¿ç”¨pandas.get_dummiesï¼ˆæ¨èï¼‰

```python
import pandas as pd

def one_hot_encode_model(df, task_name):
    """
    å¯¹modelåˆ—è¿›è¡ŒOne-Hotç¼–ç 

    Args:
        df: ä»»åŠ¡ç»„çš„DataFrame
        task_name: ä»»åŠ¡ç»„åç§°ï¼ˆç”¨äºåˆ—å‘½åï¼‰

    Returns:
        df: æ·»åŠ äº†One-Hotç¼–ç åˆ—çš„DataFrame
    """

    # 1. å¯¹modelåˆ—è¿›è¡ŒOne-Hotç¼–ç 
    model_dummies = pd.get_dummies(df['model'], prefix='model')

    # 2. åˆå¹¶åˆ°åŸDataFrame
    df = pd.concat([df, model_dummies], axis=1)

    # 3. å¯é€‰ï¼šåˆ é™¤åŸå§‹modelåˆ—ï¼ˆå¦‚æœä¸å†éœ€è¦ï¼‰
    # df = df.drop('model', axis=1)

    print(f"ä»»åŠ¡ç»„ {task_name}:")
    print(f"  åŸå§‹modelç±»åˆ«æ•°: {df['model'].nunique()}ä¸ª")
    print(f"  One-Hotç¼–ç ååˆ—æ•°: {model_dummies.shape[1]}åˆ—")
    print(f"  æ–°å¢åˆ—å: {list(model_dummies.columns)}")

    return df
```

**ä½¿ç”¨ç¤ºä¾‹**ï¼š

```python
# è¯»å–examplesä»»åŠ¡ç»„æ•°æ®
df_mnist = pd.read_csv('data/training_data_mnist.csv')

# One-Hotç¼–ç 
df_mnist = one_hot_encode_model(df_mnist, 'mnist')

# ç»“æœï¼š
# åŸå§‹åˆ—: model = ['mnist', 'mnist_ff', 'mnist_rnn', 'siamese']
# æ–°å¢åˆ—: model_mnist, model_mnist_ff, model_mnist_rnn, model_siamese
#         (4ä¸ªäºŒè¿›åˆ¶åˆ—ï¼Œæ¯åˆ—å–å€¼0æˆ–1)
```

##### æ–¹æ³•2ï¼šä½¿ç”¨sklearnï¼ˆæ›´çµæ´»ï¼‰

```python
from sklearn.preprocessing import OneHotEncoder
import numpy as np

def one_hot_encode_sklearn(df, column):
    """
    ä½¿ç”¨sklearnè¿›è¡ŒOne-Hotç¼–ç 

    ä¼˜åŠ¿ï¼šå¯ä»¥å¤„ç†æ–°ç±»åˆ«ã€ä¿å­˜ç¼–ç å™¨ç”¨äºé¢„æµ‹
    """

    encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')

    # 1. ç¼–ç 
    encoded = encoder.fit_transform(df[[column]])

    # 2. è·å–åˆ—å
    categories = encoder.categories_[0]
    col_names = [f"{column}_{cat}" for cat in categories]

    # 3. è½¬ä¸ºDataFrame
    encoded_df = pd.DataFrame(encoded, columns=col_names, index=df.index)

    # 4. åˆå¹¶
    df = pd.concat([df, encoded_df], axis=1)

    return df, encoder  # è¿”å›ç¼–ç å™¨ç”¨äºåç»­æ•°æ®
```

### 3.4 One-Hotç¼–ç çš„æ³¨æ„äº‹é¡¹

#### 1. è™šæ‹Ÿå˜é‡é™·é˜±ï¼ˆDummy Variable Trapï¼‰

**é—®é¢˜**ï¼šå¦‚æœæœ‰Nä¸ªç±»åˆ«ï¼ŒOne-Hotç¼–ç ä¼šç”ŸæˆNåˆ—ã€‚ä½†å®é™…ä¸Šåªéœ€è¦N-1åˆ—ï¼Œå› ä¸ºæœ€åä¸€åˆ—å¯ä»¥é€šè¿‡å…¶ä»–åˆ—æ¨å¯¼å‡ºæ¥ã€‚

**ç¤ºä¾‹**ï¼š
```
å¦‚æœæœ‰3ä¸ªç±»åˆ«ï¼šA, B, C
One-Hotç¼–ç åï¼š
  A  B  C
  1  0  0  â† ç±»åˆ«A
  0  1  0  â† ç±»åˆ«B
  0  0  1  â† ç±»åˆ«C
```

å¦‚æœå‰ä¸¤åˆ—éƒ½æ˜¯0ï¼Œé‚£ä¹ˆCå¿…ç„¶æ˜¯1ï¼Œæ‰€ä»¥Cåˆ—æ˜¯å†—ä½™çš„ã€‚

**åœ¨å›å½’åˆ†æä¸­**ï¼Œè¿™ä¼šå¯¼è‡´å¤šé‡å…±çº¿æ€§é—®é¢˜ã€‚

**è§£å†³æ–¹æ¡ˆ**ï¼š
```python
# pandas: ä½¿ç”¨drop_first=Trueåˆ é™¤ç¬¬ä¸€ä¸ªç±»åˆ«
pd.get_dummies(df['model'], prefix='model', drop_first=True)

# sklearn: ä½¿ç”¨drop='first'
OneHotEncoder(drop='first')
```

**åœ¨DiBSä¸­æ˜¯å¦éœ€è¦drop_firstï¼Ÿ**

å¯¹äº**å› æœå›¾å­¦ä¹ **ï¼ˆDiBSï¼‰ï¼Œé€šå¸¸**ä¸éœ€è¦**drop_firstï¼Œå› ä¸ºï¼š
- DiBSå…³æ³¨çš„æ˜¯å˜é‡é—´çš„å› æœå…³ç³»ï¼Œè€Œéå›å½’ç³»æ•°
- ä¿ç•™æ‰€æœ‰ç±»åˆ«æ›´æ˜“äºè§£é‡Šï¼ˆ"modelæ˜¯mnist" vs "modelä¸æ˜¯mnist_ffä¸”ä¸æ˜¯mnist_rnn"ï¼‰

**å»ºè®®**ï¼šä¿ç•™æ‰€æœ‰ç±»åˆ«åˆ—ï¼Œé™¤éå‡ºç°æ•°å€¼ç¨³å®šæ€§é—®é¢˜ã€‚

#### 2. ç¨€ç–æ€§é—®é¢˜

å¦‚æœç±»åˆ«æ•°é‡éå¸¸å¤šï¼ˆå¦‚50+ï¼‰ï¼ŒOne-Hotç¼–ç ä¼šäº§ç”Ÿå¤§é‡åˆ—ï¼Œä¸”å¤§éƒ¨åˆ†æ˜¯0ï¼ˆç¨€ç–ï¼‰ã€‚

**è§£å†³æ–¹æ¡ˆ**ï¼š
- åˆå¹¶ä½é¢‘ç±»åˆ«ï¼ˆå¦‚ "å…¶ä»–"ï¼‰
- ä½¿ç”¨å…¶ä»–ç¼–ç æ–¹æ³•ï¼ˆå¦‚Target Encodingï¼Œä½†ä¸é€‚åˆå› æœæ¨æ–­ï¼‰
- åœ¨æˆ‘ä»¬çš„æ¡ˆä¾‹ä¸­ï¼Œæ¯ä¸ªä»»åŠ¡ç»„çš„modelç±»åˆ«æ•°å¾ˆå°‘ï¼ˆ2-4ä¸ªï¼‰ï¼Œæ— æ­¤é—®é¢˜

#### 3. å˜é‡é€‰æ‹©

One-Hotç¼–ç åï¼Œå¯èƒ½éœ€è¦é€‰æ‹©å“ªäº›ç¼–ç åˆ—çº³å…¥DiBSåˆ†æã€‚

**ç­–ç•¥**ï¼š
```python
# å¦‚æœæŸä¸ªmodelç±»åˆ«æ ·æœ¬é‡ < 5ï¼Œè€ƒè™‘æ’é™¤
model_counts = df['model'].value_counts()
rare_models = model_counts[model_counts < 5].index

# è¿‡æ»¤
df = df[~df['model'].isin(rare_models)]
```

### 3.5 å®Œæ•´é¢„å¤„ç†æµç¨‹

```python
import pandas as pd
import numpy as np

def preprocess_for_dibs(df, task_name):
    """
    å®Œæ•´çš„DiBSæ•°æ®é¢„å¤„ç†æµç¨‹

    Args:
        df: åŸå§‹DataFrame
        task_name: ä»»åŠ¡ç»„åç§°

    Returns:
        df_processed: é¢„å¤„ç†åçš„DataFrame
        feature_names: DiBSä½¿ç”¨çš„ç‰¹å¾åˆ—ååˆ—è¡¨
    """

    print(f"{'='*80}")
    print(f"ä»»åŠ¡ç»„: {task_name}")
    print(f"{'='*80}\n")

    # 1. åˆ é™¤ç¼ºå¤±å€¼ï¼ˆæŒ‰é—®é¢˜1çš„æ ‡å‡†ï¼‰
    print("1. åˆ é™¤ç¼ºå¤±å€¼...")
    df = df.dropna(subset=['energy_cpu_total_joules', 'energy_gpu_total_joules',
                           'repository', 'model'])
    # è‡³å°‘ä¸€ä¸ªæ€§èƒ½æŒ‡æ ‡
    perf_cols = ['perf_test_accuracy', 'perf_map', 'perf_eval_loss', 'perf_top1_accuracy']
    df = df[df[perf_cols].notna().any(axis=1)]
    print(f"   ä¿ç•™è¡Œæ•°: {len(df)}")

    # 2. modeäºŒå€¼åŒ–ï¼ˆæŒ‰é—®é¢˜2ï¼‰
    print("\n2. modeäºŒå€¼åŒ–...")
    df['mode'] = df['mode'].fillna('default').replace('', 'default')
    df['mode_binary'] = df['mode'].map({'default': 0, 'parallel': 1})
    print(f"   mode=0: {(df['mode_binary']==0).sum()}ä¸ª")
    print(f"   mode=1: {(df['mode_binary']==1).sum()}ä¸ª")

    # 3. One-Hotç¼–ç ï¼ˆæŒ‰é—®é¢˜3ï¼‰
    print("\n3. One-Hotç¼–ç ...")
    if df['model'].nunique() > 1:
        model_dummies = pd.get_dummies(df['model'], prefix='model')
        df = pd.concat([df, model_dummies], axis=1)
        print(f"   modelç±»åˆ«æ•°: {df['model'].nunique()}ä¸ª")
        print(f"   æ–°å¢åˆ—: {list(model_dummies.columns)}")
    else:
        print(f"   åªæœ‰1ä¸ªmodelï¼Œè·³è¿‡One-Hotç¼–ç ")

    # 4. é€‰æ‹©DiBSåˆ†æçš„ç‰¹å¾åˆ—
    print("\n4. é€‰æ‹©DiBSç‰¹å¾...")

    # è¶…å‚æ•°
    hyperparam_cols = []
    for col in ['hyperparam_learning_rate', 'hyperparam_batch_size',
                'hyperparam_training_duration', 'hyperparam_l2_regularization',
                'hyperparam_dropout']:
        if col in df.columns and df[col].notna().sum() > 0:
            hyperparam_cols.append(col)

    # èƒ½è€—
    energy_cols = ['energy_cpu_total_joules', 'energy_gpu_total_joules']

    # èƒ½è€—ä¸­ä»‹
    mediator_cols = ['gpu_util_avg', 'gpu_temp_max', 'cpu_pkg_ratio',
                     'gpu_power_fluctuation', 'gpu_temp_fluctuation']

    # æ€§èƒ½ï¼ˆä»»åŠ¡ç‰¹å®šï¼‰
    perf_col = None
    for col in perf_cols:
        if col in df.columns and df[col].notna().sum() > len(df) * 0.5:
            perf_col = col
            break

    # æ•æ„Ÿå±æ€§
    sensitive_col = ['mode_binary']

    # One-Hotç¼–ç åˆ—
    model_cols = [col for col in df.columns if col.startswith('model_')]

    # åˆå¹¶æ‰€æœ‰ç‰¹å¾
    feature_names = hyperparam_cols + energy_cols + mediator_cols + [perf_col] + sensitive_col + model_cols
    feature_names = [col for col in feature_names if col is not None]

    print(f"   è¶…å‚æ•°ç‰¹å¾: {len(hyperparam_cols)}ä¸ª")
    print(f"   èƒ½è€—ç‰¹å¾: {len(energy_cols)}ä¸ª")
    print(f"   ä¸­ä»‹å˜é‡: {len(mediator_cols)}ä¸ª")
    print(f"   æ€§èƒ½ç‰¹å¾: {'1ä¸ª' if perf_col else '0ä¸ª'}")
    print(f"   æ•æ„Ÿå±æ€§: 1ä¸ª (mode_binary)")
    print(f"   æ¨¡å‹ç¼–ç : {len(model_cols)}ä¸ª")
    print(f"   æ€»ç‰¹å¾æ•°: {len(feature_names)}ä¸ª")

    # 5. æå–ç‰¹å¾çŸ©é˜µ
    df_processed = df[feature_names].copy()

    # 6. éªŒè¯æ•°æ®ç±»å‹
    print("\n5. éªŒè¯æ•°æ®ç±»å‹...")
    for col in feature_names:
        if df_processed[col].dtype == 'object':
            print(f"   âš ï¸ {col} ä»æ˜¯objectç±»å‹ï¼Œéœ€è½¬æ¢")
            df_processed[col] = pd.to_numeric(df_processed[col], errors='coerce')

    # 7. æœ€ç»ˆæ£€æŸ¥
    print("\n6. æœ€ç»ˆæ£€æŸ¥...")
    print(f"   æ•°æ®å½¢çŠ¶: {df_processed.shape}")
    print(f"   ç¼ºå¤±å€¼: {df_processed.isna().sum().sum()}ä¸ª")
    print(f"   æ•°æ®ç±»å‹: å…¨éƒ¨æ•°å€¼å‹={df_processed.dtypes.apply(lambda x: x in [np.float64, np.int64, np.float32, np.int32]).all()}")

    return df_processed, feature_names

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == '__main__':
    df_raw = pd.read_csv('../data/raw_data.csv')

    # ç­›é€‰MNISTä»»åŠ¡ç»„
    df_mnist = df_raw[df_raw['repository'] == 'examples'].copy()

    # é¢„å¤„ç†
    df_dibs, features = preprocess_for_dibs(df_mnist, 'mnist')

    # ä¿å­˜
    df_dibs.to_csv('../data/training_data_mnist_processed.csv', index=False)

    print("\nå¤„ç†å®Œæˆï¼")
```

---

## ğŸ“Š é¢„å¤„ç†å‰åå¯¹æ¯”

| ç»´åº¦ | é¢„å¤„ç†å‰ | é¢„å¤„ç†å |
|------|---------|---------|
| **æ€»è¡Œæ•°** | 676è¡Œ | 284è¡Œ |
| **æ•°æ®å®Œæ•´æ€§** | éƒ¨åˆ†ç¼ºå¤± | 100%å®Œæ•´ï¼ˆå…³é”®åˆ—ï¼‰ |
| **modeåˆ—** | 348è¡Œç¼ºå¤±(51.5%) | 100%å¡«å……+ç¼–ç  |
| **ç±»åˆ«å˜é‡** | å­—ç¬¦ä¸²ï¼ˆrepository, modelï¼‰ | æ•°å€¼å‹ï¼ˆOne-Hotç¼–ç ï¼‰ |
| **æ•æ„Ÿå±æ€§** | modeï¼ˆå­—ç¬¦ä¸²ï¼‰ | mode_binaryï¼ˆ0/1ï¼‰ |
| **DiBSå…¼å®¹æ€§** | âŒ ä¸å…¼å®¹ | âœ… å®Œå…¨å…¼å®¹ |

---

## ğŸ“š å‚è€ƒæ–‡æ¡£

- [VARIABLE_EXPANSION_PLAN.md](./reports/VARIABLE_EXPANSION_PLAN.md) - å˜é‡æ‰©å±•æ–¹æ¡ˆ
- [MIGRATION_GUIDE.md](./MIGRATION_GUIDE.md) - æ•°æ®è¿ç§»æŒ‡å—
- [ADULT_COMPLETE_CAUSAL_ANALYSIS_REPORT.md](./reports/ADULT_COMPLETE_CAUSAL_ANALYSIS_REPORT.md) - DiBSåŸºçº¿åˆ†æ

---

## ğŸ“Œ ç‰ˆæœ¬å†å²

| ç‰ˆæœ¬ | æ—¥æœŸ | å˜æ›´ | ä½œè€… |
|------|------|------|------|
| v1.0 | 2025-12-22 | åˆå§‹ç‰ˆæœ¬ï¼šæ•°æ®é¢„å¤„ç†ä¸‰å¤§å†³ç­– | Green + Claude |

---

**ç»´æŠ¤è€…**: Green
**æ–‡æ¡£çŠ¶æ€**: âœ… æ–¹æ¡ˆç¡®è®¤å®Œæˆ
**ä¸‹æ¬¡æ›´æ–°**: å®ç°é¢„å¤„ç†è„šæœ¬åï¼ˆæ·»åŠ å®é™…è¿è¡Œç»“æœï¼‰

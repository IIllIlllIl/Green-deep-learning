#!/usr/bin/env python3
"""
é˜¶æ®µ7: æœ€ç»ˆéªŒè¯ (Final Validation)

åŠŸèƒ½:
1. éªŒè¯å½’ä¸€åŒ–åçš„æ•°æ®è´¨é‡
2. æ£€æŸ¥DiBSå› æœåˆ†æé€‚ç”¨æ€§
3. ç”ŸæˆDiBSå°±ç»ªçš„è®­ç»ƒæ•°æ®æ–‡ä»¶ï¼ˆå»é™¤å…ƒä¿¡æ¯åˆ—ï¼‰
4. ç”Ÿæˆå®Œæ•´çš„æ•°æ®é¢„å¤„ç†æŠ¥å‘Š

ä½œè€…: Analysis Module Team
æ—¥æœŸ: 2025-12-23
"""

import pandas as pd
import numpy as np
import os
import sys
from pathlib import Path
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
SCRIPT_DIR = Path(__file__).parent
PROJECT_ROOT = SCRIPT_DIR.parent
sys.path.insert(0, str(PROJECT_ROOT))

# æ•°æ®è·¯å¾„
DATA_DIR = PROJECT_ROOT / "data" / "energy_research" / "processed"
OUTPUT_DIR = DATA_DIR
TRAINING_DATA_DIR = PROJECT_ROOT / "data" / "energy_research" / "training"
TRAINING_DATA_DIR.mkdir(parents=True, exist_ok=True)

# ä»»åŠ¡ç»„å®šä¹‰
TASK_GROUPS = {
    'image_classification': 'å›¾åƒåˆ†ç±»',
    'person_reid': 'Person_reID',
    'vulberta': 'VulBERTa',
    'bug_localization': 'Bugå®šä½'
}


def validate_normalized_data(df, task_name):
    """
    éªŒè¯å½’ä¸€åŒ–åçš„æ•°æ®è´¨é‡

    Returns:
        dict: éªŒè¯ç»“æœç»Ÿè®¡
    """
    stats = {
        'num_samples': len(df),
        'num_features': len(df.columns),
        'total_cells': len(df) * len(df.columns),
        'missing_cells': df.isna().sum().sum(),
        'missing_rate': 0.0,
        'numeric_cols': [],
        'meta_cols': [],
        'onehot_cols': [],
        'issues': []
    }

    stats['missing_rate'] = (stats['missing_cells'] / stats['total_cells']) * 100

    # åˆ†ç±»åˆ—
    for col in df.columns:
        if any(keyword in col.lower() for keyword in ['experiment_id', 'timestamp', 'repository', 'model', 'mode']):
            stats['meta_cols'].append(col)
        elif col.startswith('is_'):
            stats['onehot_cols'].append(col)
        elif df[col].dtype in ['float64', 'int64', 'float32', 'int32']:
            stats['numeric_cols'].append(col)

    # éªŒè¯æ•°å€¼åˆ—çš„æ ‡å‡†åŒ–
    print(f"\nğŸ” éªŒè¯æ•°å€¼åˆ—çš„æ ‡å‡†åŒ–...")
    for col in stats['numeric_cols']:
        non_null_mask = df[col].notna()
        if non_null_mask.sum() > 0:
            col_mean = df.loc[non_null_mask, col].mean()
            col_std = df.loc[non_null_mask, col].std()

            # æ£€æŸ¥å‡å€¼æ¥è¿‘0ï¼Œæ ‡å‡†å·®æ¥è¿‘1
            if abs(col_mean) > 0.2:
                issue = f"âš ï¸  {col}: å‡å€¼={col_mean:.3f} (åº”æ¥è¿‘0)"
                stats['issues'].append(issue)
                print(f"  {issue}")

            if abs(col_std - 1.0) > 0.2:
                issue = f"âš ï¸  {col}: æ ‡å‡†å·®={col_std:.3f} (åº”æ¥è¿‘1)"
                stats['issues'].append(issue)
                print(f"  {issue}")

    if not stats['issues']:
        print(f"  âœ… æ‰€æœ‰æ•°å€¼åˆ—æ ‡å‡†åŒ–æ­£ç¡®")

    # éªŒè¯One-Hotåˆ—
    if stats['onehot_cols']:
        print(f"\nğŸ” éªŒè¯One-Hotç¼–ç ...")
        for col in stats['onehot_cols']:
            unique_vals = df[col].dropna().unique()
            if not all(v in [0, 1] for v in unique_vals):
                issue = f"âŒ {col}: åŒ…å«é0/1å€¼: {unique_vals}"
                stats['issues'].append(issue)
                print(f"  {issue}")
            else:
                print(f"  âœ… {col}: äºŒå€¼åŒ–æ­£ç¡®")

    return stats


def check_dibs_readiness(df, stats, task_name):
    """
    æ£€æŸ¥DiBSå› æœåˆ†æé€‚ç”¨æ€§

    Returns:
        dict: DiBSé€‚ç”¨æ€§è¯„ä¼°
    """
    readiness = {
        'sample_size_ok': False,
        'sample_size': stats['num_samples'],
        'min_samples': 10,
        'recommended_samples': 20,
        'fill_rate_ok': False,
        'fill_rate': 100 - stats['missing_rate'],
        'min_fill_rate': 70.0,
        'variance_ok': True,
        'low_variance_cols': [],
        'overall_ready': False,
        'warnings': [],
        'recommendations': []
    }

    # 1. æ ·æœ¬é‡æ£€æŸ¥
    if stats['num_samples'] >= readiness['recommended_samples']:
        readiness['sample_size_ok'] = True
        print(f"  âœ… æ ·æœ¬é‡: {stats['num_samples']} (â‰¥ {readiness['recommended_samples']} æ¨èå€¼)")
    elif stats['num_samples'] >= readiness['min_samples']:
        readiness['sample_size_ok'] = True
        readiness['warnings'].append(f"æ ·æœ¬é‡åå°‘ ({stats['num_samples']}ä¸ª)ï¼Œå»ºè®®â‰¥{readiness['recommended_samples']}ä¸ª")
        print(f"  âš ï¸  æ ·æœ¬é‡: {stats['num_samples']} (â‰¥ {readiness['min_samples']} æœ€ä½è¦æ±‚ï¼Œä½† < {readiness['recommended_samples']} æ¨èå€¼)")
    else:
        readiness['sample_size_ok'] = False
        readiness['warnings'].append(f"æ ·æœ¬é‡ä¸è¶³ ({stats['num_samples']}ä¸ª)ï¼Œæœ€ä½è¦æ±‚{readiness['min_samples']}ä¸ª")
        print(f"  âŒ æ ·æœ¬é‡: {stats['num_samples']} (< {readiness['min_samples']} æœ€ä½è¦æ±‚)")

    # 2. å¡«å……ç‡æ£€æŸ¥
    if readiness['fill_rate'] >= readiness['min_fill_rate']:
        readiness['fill_rate_ok'] = True
        print(f"  âœ… å¡«å……ç‡: {readiness['fill_rate']:.1f}% (â‰¥ {readiness['min_fill_rate']}%)")
    else:
        readiness['fill_rate_ok'] = False
        readiness['warnings'].append(f"å¡«å……ç‡è¿‡ä½ ({readiness['fill_rate']:.1f}%)ï¼Œæœ€ä½è¦æ±‚{readiness['min_fill_rate']}%")
        print(f"  âŒ å¡«å……ç‡: {readiness['fill_rate']:.1f}% (< {readiness['min_fill_rate']}%)")

    # 3. å˜å¼‚æ€§æ£€æŸ¥
    print(f"\n  æ£€æŸ¥å˜é‡å˜å¼‚æ€§...")
    for col in stats['numeric_cols']:
        non_null_mask = df[col].notna()
        if non_null_mask.sum() > 1:
            unique_count = df.loc[non_null_mask, col].nunique()
            if unique_count < 5:
                readiness['low_variance_cols'].append((col, unique_count))
                readiness['warnings'].append(f"{col} å”¯ä¸€å€¼æ•°è¿‡å°‘ ({unique_count}ä¸ª)")
                print(f"    âš ï¸  {col}: åªæœ‰ {unique_count} ä¸ªå”¯ä¸€å€¼")

    if not readiness['low_variance_cols']:
        print(f"    âœ… æ‰€æœ‰å˜é‡å˜å¼‚æ€§å……è¶³")
    else:
        readiness['variance_ok'] = False

    # ç»¼åˆåˆ¤æ–­
    readiness['overall_ready'] = (
        readiness['sample_size_ok'] and
        readiness['fill_rate_ok'] and
        readiness['variance_ok']
    )

    if readiness['overall_ready']:
        print(f"\nâœ… DiBSé€‚ç”¨æ€§: ä¼˜ç§€ï¼ˆæ‰€æœ‰æ£€æŸ¥é€šè¿‡ï¼‰")
    elif readiness['sample_size_ok'] and readiness['fill_rate_ok']:
        print(f"\nâš ï¸  DiBSé€‚ç”¨æ€§: è‰¯å¥½ï¼ˆæœ‰è­¦å‘Šï¼Œä½†å¯ä»¥è¿è¡Œï¼‰")
    else:
        print(f"\nâŒ DiBSé€‚ç”¨æ€§: ä¸è¶³ï¼ˆéœ€è¦æ”¹è¿›ï¼‰")

    return readiness


def generate_dibs_training_data(df, stats, task_name):
    """
    ç”ŸæˆDiBSå°±ç»ªçš„è®­ç»ƒæ•°æ®ï¼ˆå»é™¤å…ƒä¿¡æ¯åˆ—ï¼‰

    Returns:
        pd.DataFrame: DiBSè®­ç»ƒæ•°æ®
    """
    print(f"\nğŸ”§ ç”ŸæˆDiBSè®­ç»ƒæ•°æ®...")

    # åªä¿ç•™æ•°å€¼åˆ—å’ŒOne-Hotåˆ—
    feature_cols = stats['numeric_cols'] + stats['onehot_cols']

    # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰ç‰¹å¾åˆ—éƒ½å­˜åœ¨
    missing_cols = [col for col in feature_cols if col not in df.columns]
    if missing_cols:
        print(f"  âŒ é”™è¯¯: ç¼ºå¤±åˆ— {missing_cols}")
        return None

    df_training = df[feature_cols].copy()

    print(f"  âœ… DiBSè®­ç»ƒæ•°æ®å‡†å¤‡å®Œæˆ")
    print(f"    - åŸå§‹åˆ—æ•°: {len(df.columns)}")
    print(f"    - ç§»é™¤å…ƒä¿¡æ¯åˆ—: {len(stats['meta_cols'])} ä¸ª")
    print(f"    - ä¿ç•™ç‰¹å¾åˆ—: {len(feature_cols)} ä¸ª")
    print(f"    - æ ·æœ¬æ•°: {len(df_training)}")

    # æ£€æŸ¥æ˜¯å¦æœ‰å…¨NaNåˆ—
    all_nan_cols = [col for col in df_training.columns if df_training[col].isna().all()]
    if all_nan_cols:
        print(f"\n  âš ï¸  è­¦å‘Š: ä»¥ä¸‹åˆ—å…¨ä¸ºNaNï¼ŒDiBSå¯èƒ½æ— æ³•å¤„ç†:")
        for col in all_nan_cols:
            print(f"    - {col}")

    return df_training


def validate_task_group(task_name, task_display_name):
    """
    éªŒè¯å•ä¸ªä»»åŠ¡ç»„

    Returns:
        dict: éªŒè¯ç»“æœ
    """
    print(f"\n{'='*80}")
    print(f"ä»»åŠ¡ç»„: {task_display_name} ({task_name})")
    print(f"{'='*80}\n")

    result = {
        'task_name': task_name,
        'task_display': task_display_name,
        'success': False,
        'stats': None,
        'readiness': None
    }

    # è¾“å…¥è¾“å‡ºæ–‡ä»¶
    input_file = OUTPUT_DIR / f"stage6_{task_name}.csv"
    output_file = TRAINING_DATA_DIR / f"training_data_{task_name}.csv"
    metadata_file = TRAINING_DATA_DIR / f"metadata_{task_name}.txt"

    # 1. åŠ è½½æ•°æ®
    if not input_file.exists():
        print(f"âŒ é”™è¯¯: è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {input_file}")
        result['error'] = "è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨"
        return result

    print(f"ğŸ“‚ åŠ è½½æ•°æ®: {input_file}")
    df = pd.read_csv(input_file)
    print(f"âœ… æ•°æ®åŠ è½½æˆåŠŸ: {len(df)} è¡Œ, {len(df.columns)} åˆ—")

    # 2. éªŒè¯æ•°æ®è´¨é‡
    print(f"\nğŸ” éªŒè¯æ•°æ®è´¨é‡...")
    stats = validate_normalized_data(df, task_name)

    print(f"\næ•°æ®è´¨é‡ç»Ÿè®¡:")
    print(f"  - æ ·æœ¬æ•°: {stats['num_samples']}")
    print(f"  - æ€»åˆ—æ•°: {stats['num_features']}")
    print(f"  - å…ƒä¿¡æ¯åˆ—: {len(stats['meta_cols'])} ä¸ª")
    print(f"  - One-Hotåˆ—: {len(stats['onehot_cols'])} ä¸ª")
    print(f"  - æ•°å€¼åˆ—: {len(stats['numeric_cols'])} ä¸ª")
    print(f"  - æ€»ä½“ç¼ºå¤±ç‡: {stats['missing_rate']:.2f}%")
    print(f"  - æ•°æ®é—®é¢˜æ•°: {len(stats['issues'])} ä¸ª")

    # 3. æ£€æŸ¥DiBSé€‚ç”¨æ€§
    print(f"\nğŸ” æ£€æŸ¥DiBSé€‚ç”¨æ€§...")
    readiness = check_dibs_readiness(df, stats, task_name)

    # 4. ç”ŸæˆDiBSè®­ç»ƒæ•°æ®
    df_training = generate_dibs_training_data(df, stats, task_name)

    if df_training is None:
        result['error'] = "ç”ŸæˆDiBSè®­ç»ƒæ•°æ®å¤±è´¥"
        return result

    # 5. ä¿å­˜DiBSè®­ç»ƒæ•°æ®
    print(f"\nğŸ’¾ ä¿å­˜DiBSè®­ç»ƒæ•°æ®...")
    df_training.to_csv(output_file, index=False)

    file_size_kb = output_file.stat().st_size / 1024
    print(f"âœ… DiBSè®­ç»ƒæ•°æ®å·²ä¿å­˜: {output_file}")
    print(f"  - æ–‡ä»¶å¤§å°: {file_size_kb:.1f} KB")

    # 6. ä¿å­˜å…ƒæ•°æ®æ–‡ä»¶
    print(f"\nğŸ’¾ ä¿å­˜å…ƒæ•°æ®...")
    metadata_lines = []
    metadata_lines.append(f"ä»»åŠ¡ç»„: {task_display_name} ({task_name})")
    metadata_lines.append(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    metadata_lines.append("")
    metadata_lines.append("æ•°æ®ç»Ÿè®¡:")
    metadata_lines.append(f"  æ ·æœ¬æ•°: {stats['num_samples']}")
    metadata_lines.append(f"  ç‰¹å¾æ•°: {len(df_training.columns)}")
    metadata_lines.append(f"  ç¼ºå¤±ç‡: {stats['missing_rate']:.2f}%")
    metadata_lines.append("")
    metadata_lines.append("DiBSé€‚ç”¨æ€§:")
    metadata_lines.append(f"  æ ·æœ¬é‡: {readiness['sample_size']} (æœ€ä½{readiness['min_samples']}, æ¨è{readiness['recommended_samples']})")
    metadata_lines.append(f"  å¡«å……ç‡: {readiness['fill_rate']:.1f}% (æœ€ä½{readiness['min_fill_rate']}%)")
    metadata_lines.append(f"  æ•´ä½“å°±ç»ª: {'âœ… æ˜¯' if readiness['overall_ready'] else 'âš ï¸  æœ‰è­¦å‘Š' if (readiness['sample_size_ok'] and readiness['fill_rate_ok']) else 'âŒ å¦'}")
    metadata_lines.append("")
    metadata_lines.append("ç‰¹å¾åˆ—è¡¨:")
    for i, col in enumerate(df_training.columns, 1):
        fill_rate = df_training[col].notna().sum() / len(df_training) * 100
        metadata_lines.append(f"  {i}. {col} ({fill_rate:.1f}%)")

    if readiness['warnings']:
        metadata_lines.append("")
        metadata_lines.append("è­¦å‘Š:")
        for warning in readiness['warnings']:
            metadata_lines.append(f"  - {warning}")

    with open(metadata_file, 'w', encoding='utf-8') as f:
        f.write("\n".join(metadata_lines))

    print(f"âœ… å…ƒæ•°æ®å·²ä¿å­˜: {metadata_file}")

    result['success'] = True
    result['stats'] = stats
    result['readiness'] = readiness

    return result


def generate_final_report(results):
    """ç”Ÿæˆæœ€ç»ˆéªŒè¯æŠ¥å‘Š"""
    print(f"\n{'='*80}")
    print(f"é˜¶æ®µ7: æœ€ç»ˆéªŒè¯æŠ¥å‘Š")
    print(f"{'='*80}\n")

    report_lines = []
    report_lines.append("=" * 80)
    report_lines.append("é˜¶æ®µ7: æœ€ç»ˆéªŒè¯ (Final Validation) æŠ¥å‘Š")
    report_lines.append("=" * 80)
    report_lines.append(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    report_lines.append("")

    # æ±‡æ€»ç»Ÿè®¡
    report_lines.append("=" * 80)
    report_lines.append("1. éªŒè¯æ±‡æ€»")
    report_lines.append("=" * 80)

    total_tasks = len(results)
    success_tasks = sum(1 for r in results.values() if r['success'])
    ready_tasks = sum(
        1 for r in results.values()
        if r['success'] and r['readiness']['overall_ready']
    )

    report_lines.append(f"æ€»ä»»åŠ¡ç»„æ•°: {total_tasks}")
    report_lines.append(f"éªŒè¯æˆåŠŸ: {success_tasks}")
    report_lines.append(f"DiBSå°±ç»ª: {ready_tasks}")
    report_lines.append(f"æœ‰è­¦å‘Š: {success_tasks - ready_tasks}")
    report_lines.append(f"éªŒè¯å¤±è´¥: {total_tasks - success_tasks}")
    report_lines.append("")

    # å„ä»»åŠ¡ç»„è¯¦æƒ…
    report_lines.append("=" * 80)
    report_lines.append("2. å„ä»»åŠ¡ç»„è¯¦æƒ…")
    report_lines.append("=" * 80)

    for task_name, result in results.items():
        task_display = TASK_GROUPS[task_name]

        report_lines.append(f"\n{task_display} ({task_name}):")

        if result['success']:
            stats = result['stats']
            readiness = result['readiness']

            report_lines.append(f"  âœ… éªŒè¯æˆåŠŸ")
            report_lines.append(f"  æ ·æœ¬æ•°: {stats['num_samples']}")
            report_lines.append(f"  ç‰¹å¾æ•°: {len(stats['numeric_cols']) + len(stats['onehot_cols'])}")
            report_lines.append(f"  ç¼ºå¤±ç‡: {stats['missing_rate']:.2f}%")

            if readiness['overall_ready']:
                report_lines.append(f"  DiBSé€‚ç”¨æ€§: âœ… ä¼˜ç§€")
            elif readiness['sample_size_ok'] and readiness['fill_rate_ok']:
                report_lines.append(f"  DiBSé€‚ç”¨æ€§: âš ï¸  è‰¯å¥½ï¼ˆæœ‰è­¦å‘Šï¼‰")
                for warning in readiness['warnings']:
                    report_lines.append(f"    - {warning}")
            else:
                report_lines.append(f"  DiBSé€‚ç”¨æ€§: âŒ ä¸è¶³")
                for warning in readiness['warnings']:
                    report_lines.append(f"    - {warning}")

            report_lines.append(f"  è¾“å‡ºæ–‡ä»¶: training_data_{task_name}.csv")
            report_lines.append(f"  å…ƒæ•°æ®: metadata_{task_name}.txt")
        else:
            report_lines.append(f"  âŒ éªŒè¯å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")

    report_lines.append("")
    report_lines.append("=" * 80)
    report_lines.append("3. DiBSå°±ç»ªæ–‡ä»¶æ¸…å•")
    report_lines.append("=" * 80)

    for task_name, result in results.items():
        if result['success']:
            report_lines.append(f"  - training_data_{task_name}.csv")

    report_lines.append("")
    report_lines.append("=" * 80)
    report_lines.append("âœ… é˜¶æ®µ7å®Œæˆ - æ•°æ®é¢„å¤„ç†ç®¡é“å…¨éƒ¨å®Œæˆ")
    report_lines.append("=" * 80)
    report_lines.append("")
    report_lines.append("ä¸‹ä¸€æ­¥:")
    report_lines.append("  1. è¿è¡ŒDiBSå› æœå›¾å­¦ä¹ : python scripts/experiments/run_dibs_task_specific.py")
    report_lines.append("  2. æŸ¥çœ‹å®Œæ•´æŠ¥å‘Š: docs/DATA_QUALITY_REPORT_DETAILED_20251223.md")

    # å†™å…¥æŠ¥å‘Šæ–‡ä»¶
    report_file = OUTPUT_DIR / "stage7_final_validation_report.txt"
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write("\n".join(report_lines))

    # æ‰“å°åˆ°æ§åˆ¶å°
    print("\n".join(report_lines))
    print(f"\nğŸ“„ æŠ¥å‘Šå·²ä¿å­˜: {report_file}")


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 80)
    print("é˜¶æ®µ7: æœ€ç»ˆéªŒè¯ (Final Validation)")
    print("=" * 80)

    results = {}

    # å¯¹æ¯ä¸ªä»»åŠ¡ç»„è¿›è¡ŒéªŒè¯
    for task_name, task_display_name in TASK_GROUPS.items():
        try:
            result = validate_task_group(task_name, task_display_name)
            results[task_name] = result
        except Exception as e:
            print(f"\nâŒ é”™è¯¯: å¤„ç†ä»»åŠ¡ç»„ {task_name} æ—¶å‘ç”Ÿå¼‚å¸¸")
            print(f"  å¼‚å¸¸ä¿¡æ¯: {str(e)}")
            import traceback
            traceback.print_exc()

            results[task_name] = {
                'task_name': task_name,
                'task_display': task_display_name,
                'success': False,
                'error': str(e)
            }

    # ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
    generate_final_report(results)

    # è¿”å›çŠ¶æ€
    all_success = all(r['success'] for r in results.values())

    if all_success:
        print("\n" + "=" * 80)
        print("âœ… é˜¶æ®µ7å®Œæˆ: æ‰€æœ‰ä»»åŠ¡ç»„éªŒè¯æˆåŠŸ")
        print("=" * 80)
        print("\nğŸ‰ æ•°æ®é¢„å¤„ç†ç®¡é“ï¼ˆé˜¶æ®µ0-7ï¼‰å…¨éƒ¨å®Œæˆï¼")
        print("\nä¸‹ä¸€æ­¥: è¿è¡ŒDiBSå› æœåˆ†æ")
        print("  cd /home/green/energy_dl/nightly/analysis")
        print("  python scripts/experiments/run_dibs_task_specific.py")
        return 0
    else:
        print("\n" + "=" * 80)
        print("âš ï¸  é˜¶æ®µ7å®Œæˆ: éƒ¨åˆ†ä»»åŠ¡ç»„éªŒè¯å¤±è´¥")
        print("=" * 80)
        return 1


if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)

# 能耗DL项目 - 数据现状完整报告

**报告生成时间**: 2026-01-14
**分析者**: Claude

---

## 📊 数据文件总览

项目目前有 **3个主要数据文件**，分布在不同目录：

### 1. raw_data.csv（原始完整数据）⭐⭐⭐

- **位置**: `data/raw_data.csv`
- **规模**: 1,225 行 × 87 列
- **文件大小**: 537.5 KB
- **最后更新**: 2026-01-13

**特点**:
- ✅ 最完整的原始数据文件
- ✅ 包含所有实验记录（包括并行和非并行）
- ✅ 1,040 个唯一实验ID
- ⚠️  超参数仅记录变异值（完整性 45-47%）

**数据质量**:
- 能耗数据: 1,094/1,225 (89.3%) ✅ 优秀
- 性能数据: 832/1,225 (67.9%) ⚠️  中等
- 完全可用: 812/1,225 (66.3%)

### 2. data.csv（精简统一数据）⭐⭐

- **位置**: `data/data.csv`
- **规模**: 970 行 × 56 列
- **文件大小**: 388.1 KB
- **最后更新**: 2026-01-10

**特点**:
- ✅ 统一了并行/非并行字段
- ✅ 添加了 `is_parallel` 列
- ✅ 列数较少，更易分析
- ⚠️  行数少于 raw_data.csv（少255行）

**数据质量**:
- 能耗数据: 944/970 (97.3%) ✅ 优秀
- 性能数据: 838/970 (86.4%) ✅ 良好
- 完全可用: 818/970 (84.3%) ✅ 优秀

**与 raw_data.csv 的区别**:
- 行数: 970 vs 1,225（少255行，-20.8%）
- 能耗完整性: 97.3% vs 89.3%（更高）
- 性能完整性: 86.4% vs 67.9%（更高）
- 总体可用性: 84.3% vs 66.3%（更高）

**推测**: data.csv 可能是经过筛选的高质量子集，剔除了一些问题数据。

### 3. raw_data_backfilled.csv（回溯超参数后的数据）⭐⭐⭐

- **位置**: `analysis/data/energy_research/backfilled/raw_data_backfilled.csv`
- **规模**: 1,225 行 × 105 列
- **文件大小**: 733.9 KB
- **最后更新**: 2026-01-14（今天创建）

**特点**:
- ✅ 基于 raw_data.csv 回溯超参数默认值
- ✅ 添加了 18 个 `*_source` 列追踪数据来源
- ✅ 超参数完整性大幅提升（45% → 79-91%）
- ✅ 通过独立 Subagent 验证

**数据质量**:
- 能耗数据: 1,094/1,225 (89.3%)（与 raw_data.csv 相同）
- 性能数据: 832/1,225 (67.9%)（与 raw_data.csv 相同）
- 完全可用: 812/1,225 (66.3%)（与 raw_data.csv 相同）

**超参数完整性提升**:

| 超参数 | raw_data.csv | backfilled.csv | 提升 |
|-------|-------------|---------------|-----|
| epochs | 45.5% | **79.3%** | +33.8% ✅ |
| learning_rate | 44.7% | **79.3%** | +34.6% ✅ |
| seed | 46.9% | **91.4%** | +44.5% ✅ |
| batch_size | 15.8% | **28.9%** | +13.1% ✅ |
| dropout | 18.0% | **29.9%** | +11.9% ✅ |

**数据来源追踪**:
- recorded: 3,341 个单元格（原始记录值）
- backfilled: 2,955 个单元格（回溯的默认值）
- not_applicable: 7,546 个单元格（不支持的参数）

---

## 🎯 关键问题回答

### 问题1: 970条数据是哪个文件？

**答案**: `data/data.csv` 文件有 **970 行数据**。

### 问题2: 970条数据可用的有哪些？

**完全可用的数据**（训练成功 + 有能耗 + 有性能）:
- **总计**: 818/970 (84.3%) ✅

**按仓库分类**:

| 仓库 | 可用/总数 | 可用率 | 评级 |
|-----|---------|-------|-----|
| **examples** | 304/304 | **100.0%** | ⭐⭐⭐ 完美 |
| **Person_reID_baseline_pytorch** | 206/206 | **100.0%** | ⭐⭐⭐ 完美 |
| **pytorch_resnet_cifar10** | 74/74 | **100.0%** | ⭐⭐⭐ 完美 |
| **MRT-OAST** | 72/92 | **78.3%** | ⭐⭐ 良好 |
| **bug-localization** | 90/142 | **63.4%** | ⭐ 中等 |
| **VulBERTa** | 72/152 | **47.4%** | ⚠️ 较差 |

**推荐使用的高质量数据**（100%可用的3个仓库）:
- examples: 304 条
- Person_reID_baseline_pytorch: 206 条
- pytorch_resnet_cifar10: 74 条
- **合计**: **584 条** (60.2% 的数据) ⭐⭐⭐

### 问题3: 1,225条数据的情况？

**答案**: `raw_data.csv` 和 `raw_data_backfilled.csv` 都有 **1,225 行数据**。

**完全可用的数据**:
- **总计**: 812/1,225 (66.3%)

**按仓库分类**:

| 仓库 | 可用/总数 | 可用率 | 评级 |
|-----|---------|-------|-----|
| **pytorch_resnet_cifar10** | 87/87 | **100.0%** | ⭐⭐⭐ 完美 |
| **examples** | 305/354 | **86.2%** | ⭐⭐⭐ 优秀 |
| **MRT-OAST** | 75/105 | **71.4%** | ⭐⭐ 良好 |
| **Person_reID_baseline_pytorch** | 183/261 | **70.1%** | ⭐⭐ 良好 |
| **bug-localization** | 90/149 | **60.4%** | ⭐ 中等 |
| **VulBERTa** | 72/164 | **43.9%** | ⚠️ 较差 |

**为什么与970条数据不同？**
- 970条: 可能是筛选后的高质量子集
- 1,225条: 包含所有实验（含部分低质量数据）

---

## 📈 三个数据文件对比

### 文件对比表

| 维度 | raw_data.csv | data.csv | backfilled.csv |
|-----|-------------|----------|----------------|
| **行数** | 1,225 | 970 | 1,225 |
| **列数** | 87 | 56 | 105 |
| **文件大小** | 537.5 KB | 388.1 KB | 733.9 KB |
| **能耗完整性** | 89.3% | **97.3%** ✅ | 89.3% |
| **性能完整性** | 67.9% | **86.4%** ✅ | 67.9% |
| **超参数完整性** | 45-47% | 60% | **79-91%** ✅ |
| **完全可用率** | 66.3% | **84.3%** ✅ | 66.3% |
| **数据来源追踪** | ❌ | ❌ | ✅ 18列 |

### 推荐使用场景

| 文件 | 推荐场景 | 优势 | 劣势 |
|-----|---------|------|------|
| **raw_data.csv** | 完整数据分析、数据探索 | 最全面（1,225行） | 超参数缺失多 |
| **data.csv** | 高质量分析、快速验证 | 数据质量最高（84.3%可用） | 数据量较少（970行） |
| **backfilled.csv** | **回归分析、因果推断** ⭐ | 超参数最完整、有来源追踪 | 文件较大 |

---

## 🔍 数据质量问题总结

### 主要问题

1. **性能数据缺失**（67.9%-86.4%）
   - VulBERTa: 仅 47.4% 可用
   - bug-localization: 仅 63.4% 可用

2. **能耗数据缺失**（89.3%-97.3%）
   - 整体较好，但仍有 10-11% 缺失

3. **超参数缺失**（原始数据 45-47%）
   - 已通过回溯解决（提升至 79-91%）

### 数据差异原因

**为什么 data.csv (970行) 比 raw_data.csv (1,225行) 少 255 行？**

可能原因：
1. **筛选了低质量数据**: 移除了能耗/性能缺失严重的记录
2. **移除了并行实验**: 可能只保留了非并行实验
3. **去重**: 可能移除了重复实验

**建议**: 检查 `tools/data_management/create_unified_data_csv.py` 脚本的筛选逻辑。

---

## 💡 使用建议

### 根据研究目的选择数据

#### 1. 回归分析（问题1）⭐⭐⭐

**推荐**: `raw_data_backfilled.csv`

**理由**:
- ✅ 超参数完整性最高（79-91%）
- ✅ 有数据来源追踪（可区分recorded/backfilled）
- ✅ 数据量最大（1,225行）
- ✅ 通过独立验证

**可用数据**: 812 条完全可用记录

#### 2. 快速原型验证

**推荐**: `data.csv`

**理由**:
- ✅ 数据质量最高（84.3%可用）
- ✅ 文件较小，加载快速
- ✅ 列数较少（56列），易处理

**可用数据**: 818 条完全可用记录

#### 3. 完整数据探索

**推荐**: `raw_data.csv`

**理由**:
- ✅ 包含所有原始记录
- ✅ 未经筛选，数据最全面

**可用数据**: 812 条完全可用记录

### 高质量数据子集（推荐）⭐⭐⭐

如果要确保数据质量，建议使用以下仓库：

**从 data.csv 中筛选**:
```python
high_quality_repos = [
    'examples',
    'Person_reID_baseline_pytorch',
    'pytorch_resnet_cifar10'
]
df = df[df['repository'].isin(high_quality_repos)]
# 得到: 584 条 100%可用的高质量数据
```

**从 backfilled.csv 中筛选**:
```python
# 只使用完全可用的数据
df = df[
    df[[col for col in df.columns if col.startswith('energy_')]].notna().any(axis=1) &
    df[[col for col in df.columns if col.startswith('perf_')]].notna().any(axis=1)
]
# 得到: 812 条可用数据
```

---

## 📝 下一步建议

### 立即行动

1. **✅ 使用 backfilled.csv 开始回归分析**
   - 文件: `analysis/data/energy_research/backfilled/raw_data_backfilled.csv`
   - 可用数据: 812 条
   - 超参数完整性: 79-91%

2. **调查 data.csv 的筛选逻辑**
   - 了解为什么只有 970 行（vs 1,225 行）
   - 确认筛选标准是否合理

3. **改善 VulBERTa 和 bug-localization 的数据质量**
   - 这两个仓库的可用率较低（47.4% 和 63.4%）
   - 检查性能指标提取是否有问题

### 文档更新

建议更新以下文档：
- `docs/DATA_USABILITY_SUMMARY_20260113.md` - 添加 backfilled.csv 的分析
- `CLAUDE.md` § 数据文件说明 - 更新数据现状

---

## 📂 文件清单

### 主要数据文件

1. **data/raw_data.csv** (1,225行 × 87列)
   - 原始完整数据
   - 能耗: 89.3%, 性能: 67.9%, 可用: 66.3%

2. **data/data.csv** (970行 × 56列)
   - 精简统一数据
   - 能耗: 97.3%, 性能: 86.4%, 可用: 84.3% ⭐

3. **analysis/data/energy_research/backfilled/raw_data_backfilled.csv** (1,225行 × 105列)
   - 回溯超参数后的数据
   - 能耗: 89.3%, 性能: 67.9%, 可用: 66.3%
   - 超参数: 79-91% ⭐⭐⭐

### 配套文件

4. **analysis/data/energy_research/backfilled/backfill_report.txt**
   - 回溯操作详细报告

5. **analysis/data/energy_research/backfilled/backfill_stats.json**
   - 回溯统计数据（JSON格式）

6. **analysis/data/energy_research/backfilled/independent_verification_report.md**
   - Subagent 独立验证报告

7. **analysis/data/energy_research/backfilled/BACKFILL_COMPLETION_SUMMARY.md**
   - 回溯工作总结

---

**报告生成**: 2026-01-14
**分析工具**: `analysis/scripts/analyze_current_data_status.py`
**状态**: ✅ 完成

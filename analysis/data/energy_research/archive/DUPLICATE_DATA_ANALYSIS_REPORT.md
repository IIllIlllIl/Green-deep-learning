# æ•°æ®é‡å¤é—®é¢˜åˆ†ææŠ¥å‘Š

**æŠ¥å‘Šæ—¥æœŸ**: 2026-01-14
**åˆ†æè€…**: Claude
**çŠ¶æ€**: âš ï¸ å‘ç°ä¸¥é‡é‡å¤é—®é¢˜

---

## ğŸ“‹ æ‰§è¡Œæ‘˜è¦

ç»è¿‡è¯¦ç»†åˆ†æï¼Œå‘ç° **raw_data.csv å’Œ data.csv éƒ½å­˜åœ¨ä¸¥é‡çš„æ•°æ®é‡å¤é—®é¢˜**ï¼š

| æ–‡ä»¶ | æ€»è¡Œæ•° | é‡å¤è¡Œæ•° | é‡å¤ç‡ | å”¯ä¸€IDæ•° | å»é‡åè¡Œæ•° |
|-----|-------|---------|--------|---------|-----------|
| **raw_data.csv** | 1,225 | 329 | **26.9%** | 1,040 | 1,040 |
| **data.csv** | 970 | 214 | **22.1%** | 850 | 850 |

**å…³é”®å‘ç°**:
- âš ï¸ raw_data.csv æœ‰ **185è¡Œé‡å¤æ•°æ®**ï¼ˆ15.1%ï¼‰
- âš ï¸ data.csv æœ‰ **120è¡Œé‡å¤æ•°æ®**ï¼ˆ12.4%ï¼‰
- âš ï¸ åŒä¸€ä¸ª experiment_id è¢«é‡å¤è®°å½• 2-5 æ¬¡
- âš ï¸ é‡å¤æ•°æ®åˆ†å¸ƒåœ¨ 2025-11-18 è‡³ 2026-01-09 æœŸé—´

---

## ğŸ” é‡å¤æ•°æ®è¯¦æƒ…

### 1. raw_data.csv é‡å¤æƒ…å†µ

**åŸºæœ¬ç»Ÿè®¡**:
- æ€»è¡Œæ•°: 1,225
- å”¯ä¸€ experiment_id: 1,040
- å”¯ä¸€ timestamp: 1,015
- é‡å¤çš„è¡Œæ•°: 329
- é‡å¤çš„ experiment_id æ•°é‡: 144

**é‡å¤æ¬¡æ•°åˆ†å¸ƒ**:
- é‡å¤ 5 æ¬¡: 2 ä¸ª experiment_id
- é‡å¤ 4 æ¬¡: 6 ä¸ª experiment_id
- é‡å¤ 3 æ¬¡: 23 ä¸ª experiment_id
- é‡å¤ 2 æ¬¡: 113 ä¸ª experiment_id

**æŒ‰ä»“åº“åˆ†å¸ƒ**:
- examples: 91 è¡Œé‡å¤
- VulBERTa: 86 è¡Œé‡å¤
- Person_reID_baseline_pytorch: 66 è¡Œé‡å¤
- bug-localization-by-dnn-and-rvsm: 58 è¡Œé‡å¤
- MRT-OAST: 22 è¡Œé‡å¤
- pytorch_resnet_cifar10: 6 è¡Œé‡å¤

**æŒ‰ mode åˆ†å¸ƒ**:
- mode=NaN: 195 è¡Œï¼ˆ59.3%ï¼‰
- mode=parallel: 134 è¡Œï¼ˆ40.7%ï¼‰

### 2. data.csv é‡å¤æƒ…å†µ

**åŸºæœ¬ç»Ÿè®¡**:
- æ€»è¡Œæ•°: 970
- å”¯ä¸€ experiment_id: 850
- å”¯ä¸€ timestamp: 970ï¼ˆæ— é‡å¤timestampï¼‰
- é‡å¤çš„è¡Œæ•°: 214
- é‡å¤çš„ experiment_id æ•°é‡: 94

**é‡å¤æ¬¡æ•°åˆ†å¸ƒ**:
- é‡å¤ 5 æ¬¡: 1 ä¸ª experiment_id
- é‡å¤ 4 æ¬¡: 6 ä¸ª experiment_id
- é‡å¤ 3 æ¬¡: 11 ä¸ª experiment_id
- é‡å¤ 2 æ¬¡: 76 ä¸ª experiment_id

**æŒ‰ä»“åº“åˆ†å¸ƒ**:
- VulBERTa: 63 è¡Œé‡å¤
- examples: 53 è¡Œé‡å¤
- Person_reID_baseline_pytorch: 43 è¡Œé‡å¤
- bug-localization-by-dnn-and-rvsm: 42 è¡Œé‡å¤
- MRT-OAST: 13 è¡Œé‡å¤

**æŒ‰ mode åˆ†å¸ƒ**:
- mode=NaN: 126 è¡Œï¼ˆ58.9%ï¼‰
- mode=parallel: 88 è¡Œï¼ˆ41.1%ï¼‰

---

## ğŸ“Š é‡å¤æ¡ˆä¾‹åˆ†æ

### æ¡ˆä¾‹1: VulBERTa_mlp_002ï¼ˆé‡å¤5æ¬¡ï¼‰

| åºå· | timestamp | èƒ½è€— | æ€§èƒ½ | è¯´æ˜ |
|-----|-----------|------|------|------|
| 1 | 2025-12-07T00:25:57 | âœ… | âŒ | ç¬¬1æ¬¡è¿è¡Œï¼Œæœ‰èƒ½è€—æ— æ€§èƒ½ |
| 2 | 2025-12-13T00:25:14 | âœ… | âŒ | ç¬¬2æ¬¡è¿è¡Œï¼Œæœ‰èƒ½è€—æ— æ€§èƒ½ |
| 3 | 2025-12-13T22:22:21 | âœ… | âŒ | ç¬¬3æ¬¡è¿è¡Œï¼Œæœ‰èƒ½è€—æ— æ€§èƒ½ |
| 4 | 2025-12-16T00:27:51 | âŒ | âœ… | ç¬¬4æ¬¡è¿è¡Œï¼Œæ— èƒ½è€—æœ‰æ€§èƒ½ |
| 5 | 2025-12-18T00:13:27 | âœ… | âœ… | ç¬¬5æ¬¡è¿è¡Œï¼Œæ•°æ®å®Œæ•´ âœ… |

**åˆ†æ**: åŒä¸€ä¸ªå®éªŒåœ¨ä¸åŒæ—¶é—´è¢«è¿è¡Œäº†5æ¬¡ï¼Œæ¯æ¬¡è®°å½•çš„æ•°æ®å®Œæ•´æ€§ä¸åŒã€‚æœ€åä¸€æ¬¡ï¼ˆ12-18ï¼‰æ•°æ®æœ€å®Œæ•´ã€‚


---

## ğŸ” é‡å¤åŸå› åˆ†æ

### åŸå› 1: å®éªŒå¤±è´¥åé‡è·‘ï¼ˆä¸»è¦åŸå› ï¼‰

**è¯æ®**:
- åŒä¸€ä¸ª experiment_id åœ¨ä¸åŒæ—¥æœŸå‡ºç°
- æ—©æœŸè®°å½•æ•°æ®ä¸å®Œæ•´ï¼ˆç¼ºèƒ½è€—æˆ–æ€§èƒ½ï¼‰
- åæœŸè®°å½•æ•°æ®é€æ¸å®Œæ•´

**æ¨æµ‹**:
1. å®éªŒé¦–æ¬¡è¿è¡Œæ—¶ï¼Œèƒ½è€—æˆ–æ€§èƒ½æ•°æ®é‡‡é›†å¤±è´¥
2. é‡æ–°è¿è¡Œå®éªŒï¼Œä½†ä½¿ç”¨äº†ç›¸åŒçš„ experiment_id
3. å¤šæ¬¡é‡è·‘ç›´åˆ°æ•°æ®å®Œæ•´

### åŸå› 2: æ•°æ®ä¿®å¤æ—¶å¤šæ¬¡è¿½åŠ 

**è¯æ®**:
- é‡å¤æ•°æ®åˆ†å¸ƒåœ¨å¤šä¸ªæ—¥æœŸï¼ˆ2025-11-18 è‡³ 2026-01-09ï¼‰
- éƒ¨åˆ†é‡å¤è®°å½•çš„ timestamp ä¸åŒä½†æ•°æ®ç›¸ä¼¼

**æ¨æµ‹**:
1. æ•°æ®ä¿®å¤æ—¶ä»ä¸åŒæ¥æºæå–æ•°æ®
2. æ¯æ¬¡ä¿®å¤éƒ½è¿½åŠ åˆ° raw_data.csv
3. æ²¡æœ‰è¿›è¡Œå»é‡æ£€æŸ¥

### åŸå› 3: append_session è„šæœ¬æœªå»é‡

**è¯æ®**:
- é¡¹ç›®ä½¿ç”¨ `append_session_to_raw_data.py` è¿½åŠ æ–°æ•°æ®
- è„šæœ¬å¯èƒ½æœªæ£€æŸ¥ experiment_id æ˜¯å¦å·²å­˜åœ¨

**å»ºè®®**: æ£€æŸ¥è¿½åŠ è„šæœ¬çš„å»é‡é€»è¾‘

---

## ğŸ“… é‡å¤æ•°æ®æ—¶é—´åˆ†å¸ƒ

é‡å¤è®°å½•ä¸»è¦é›†ä¸­åœ¨ä»¥ä¸‹æ—¥æœŸï¼š

| æ—¥æœŸ | é‡å¤è¡Œæ•° | è¯´æ˜ |
|------|---------|------|
| 2025-11-22 | 19 | æ—©æœŸå®éªŒé˜¶æ®µ |
| 2025-11-23 | 22 | æ—©æœŸå®éªŒé˜¶æ®µ |
| 2025-12-04 | 23 | æ•°æ®ä¿®å¤ï¼Ÿ |
| 2025-12-10 | 18 | æ•°æ®ä¿®å¤ï¼Ÿ |
| 2025-12-14 | 14 | æ•°æ®ä¿®å¤ï¼Ÿ |
| 2025-12-15 | 14 | æ•°æ®ä¿®å¤ï¼Ÿ |
| 2025-12-16 | 20 | æ•°æ®ä¿®å¤ï¼Ÿ |
| 2025-12-18 | 21 | æ•°æ®ä¿®å¤ï¼Ÿ |
| 2025-12-23 | 14 | æ•°æ®ä¿®å¤ï¼Ÿ |
| 2025-12-30 | 15 | æ•°æ®ä¿®å¤ï¼Ÿ |
| 2026-01-01 | 12 | æ•°æ®ä¿®å¤ï¼Ÿ |
| 2026-01-02 | 14 | æ•°æ®ä¿®å¤ï¼Ÿ |
| 2026-01-07 | 15 | æ•°æ®ä¿®å¤ï¼Ÿ |
| 2026-01-09 | 11 | æ•°æ®ä¿®å¤ï¼Ÿ |

**åˆ†æ**: é‡å¤æ•°æ®æŒç»­å‡ºç°ï¼Œè¯´æ˜è¿™æ˜¯ä¸€ä¸ªç³»ç»Ÿæ€§é—®é¢˜ï¼Œè€Œéå¶å‘äº‹ä»¶ã€‚


---

## ğŸ’¡ è§£å†³æ–¹æ¡ˆ

### æ–¹æ¡ˆ1: ä½¿ç”¨å»é‡è„šæœ¬ï¼ˆæ¨èï¼‰â­â­â­

**è„šæœ¬**: `tools/data_management/deduplicate_data_files.py`

**å»é‡ç­–ç•¥**:
1. æŒ‰ experiment_id åˆ†ç»„
2. ä¿ç•™æ¯ç»„ä¸­ timestamp æœ€æ–°çš„è®°å½•
3. å¦‚æœ timestamp ç›¸åŒï¼Œä¿ç•™æ•°æ®æœ€å®Œæ•´çš„è®°å½•ï¼ˆèƒ½è€—+æ€§èƒ½ï¼‰

**ä½¿ç”¨æ–¹æ³•**:
```bash
# 1. é¢„è§ˆå»é‡ç»“æœï¼ˆä¸ä¿å­˜ï¼‰
python3 tools/data_management/deduplicate_data_files.py --dry-run

# 2. æ‰§è¡Œå»é‡ï¼ˆä¼šè‡ªåŠ¨å¤‡ä»½åŸæ–‡ä»¶ï¼‰
python3 tools/data_management/deduplicate_data_files.py

# 3. æŸ¥çœ‹å»é‡åçš„æ–‡ä»¶
ls -lh data/deduplication/
```

**é¢„æœŸç»“æœ**:
- raw_data.csv: 1,225 â†’ 1,040 è¡Œï¼ˆç§»é™¤185è¡Œï¼Œ15.1%ï¼‰
- data.csv: 970 â†’ 850 è¡Œï¼ˆç§»é™¤120è¡Œï¼Œ12.4%ï¼‰


### æ–¹æ¡ˆ2: æ”¹è¿› append_session è„šæœ¬

**å»ºè®®ä¿®æ”¹**: `tools/data_management/append_session_to_raw_data.py`

**æ·»åŠ å»é‡æ£€æŸ¥**:
```python
# åœ¨è¿½åŠ å‰æ£€æŸ¥ experiment_id æ˜¯å¦å·²å­˜åœ¨
existing_ids = set(existing_df['experiment_id'])
new_ids = set(new_df['experiment_id'])
duplicate_ids = existing_ids & new_ids

if duplicate_ids:
    print(f"âš ï¸  å‘ç° {len(duplicate_ids)} ä¸ªé‡å¤çš„ experiment_id")
    # é€‰æ‹©å¤„ç†ç­–ç•¥ï¼šè·³è¿‡ã€è¦†ç›–ã€æˆ–åˆå¹¶
```

---

## ğŸ“‹ é¢„é˜²æªæ–½

### 1. ä½¿ç”¨å”¯ä¸€é”®

**å»ºè®®**: ä½¿ç”¨ `experiment_id + timestamp` ä½œä¸ºå¤åˆå”¯ä¸€é”®

```python
# åˆ›å»ºå¤åˆé”®
df['unique_key'] = df['experiment_id'] + '|' + df['timestamp']

# å»é‡
df = df.drop_duplicates(subset=['unique_key'], keep='last')
```

### 2. è¿½åŠ æ•°æ®æ—¶å¼ºåˆ¶å»é‡

**ä¿®æ”¹è¿½åŠ è„šæœ¬**:
```python
# åˆå¹¶æ•°æ®
combined_df = pd.concat([existing_df, new_df])

# å»é‡ï¼ˆä¿ç•™æœ€æ–°çš„ï¼‰
combined_df = combined_df.sort_values('timestamp')
combined_df = combined_df.drop_duplicates(subset=['experiment_id'], keep='last')
```

### 3. å®šæœŸè¿è¡Œå»é‡æ£€æŸ¥

**å»ºè®®**: æ¯æ¬¡è¿½åŠ æ•°æ®åè¿è¡Œå»é‡æ£€æŸ¥

```bash
# è¿½åŠ æ•°æ®å
python3 tools/data_management/append_session_to_raw_data.py results/run_xxx

# ç«‹å³æ£€æŸ¥é‡å¤
python3 tools/data_management/deduplicate_data_files.py --dry-run
```


---

## ğŸ¯ å½±å“è¯„ä¼°

### å¯¹æ•°æ®åˆ†æçš„å½±å“

**1. ç»Ÿè®¡åå·®**:
- é‡å¤æ•°æ®ä¼šå¯¼è‡´æŸäº›å®éªŒè¢«è¿‡åº¦è®¡æ•°
- å½±å“å‡å€¼ã€æ–¹å·®ç­‰ç»Ÿè®¡é‡çš„å‡†ç¡®æ€§

**2. å›å½’åˆ†æåå·®**:
- é‡å¤çš„ experiment_id ä¼šå¢åŠ æŸäº›è¶…å‚æ•°ç»„åˆçš„æƒé‡
- å¯èƒ½å¯¼è‡´å›å½’ç³»æ•°ä¼°è®¡åå·®

**3. æ•°æ®å®Œæ•´æ€§è¯¯åˆ¤**:
- é‡å¤æ•°æ®ä¸­éƒ¨åˆ†è®°å½•ä¸å®Œæ•´
- å¯èƒ½ä½ä¼°å®é™…çš„æ•°æ®å®Œæ•´æ€§

### å»é‡åçš„æ”¹å–„

| æŒ‡æ ‡ | raw_data.csv | data.csv |
|-----|-------------|----------|
| **æ•°æ®é‡** | 1,225 â†’ 1,040 | 970 â†’ 850 |
| **å”¯ä¸€æ€§** | 84.9% â†’ 100% | 87.6% â†’ 100% |
| **å¯ä¿¡åº¦** | ä¸­ç­‰ â†’ é«˜ | ä¸­ç­‰ â†’ é«˜ |


---

## ğŸ“ è¡ŒåŠ¨å»ºè®®

### ç«‹å³è¡ŒåŠ¨ï¼ˆä¼˜å…ˆçº§ï¼šé«˜ï¼‰â­â­â­

1. **æ‰§è¡Œå»é‡**
   ```bash
   # å…ˆé¢„è§ˆ
   python3 tools/data_management/deduplicate_data_files.py --dry-run
   
   # ç¡®è®¤æ— è¯¯åæ‰§è¡Œ
   python3 tools/data_management/deduplicate_data_files.py
   ```

2. **éªŒè¯å»é‡ç»“æœ**
   ```bash
   # æ£€æŸ¥å»é‡åçš„æ–‡ä»¶
   wc -l data/deduplication/*.csv
   
   # éªŒè¯å”¯ä¸€æ€§
   python3 << 'PYEOF'
   import pandas as pd
   df = pd.read_csv('data/deduplication/raw_data_deduped.csv')
   print(f"è¡Œæ•°: {len(df)}")
   print(f"å”¯ä¸€ID: {df['experiment_id'].nunique()}")
   print(f"é‡å¤: {len(df) - df['experiment_id'].nunique()}")
   PYEOF
   ```

3. **æ›´æ–°ä¸»æ•°æ®æ–‡ä»¶**
   ```bash
   # å¤‡ä»½å½“å‰æ–‡ä»¶
   cp data/raw_data.csv data/raw_data.csv.backup_before_dedup
   
   # ä½¿ç”¨å»é‡åçš„æ–‡ä»¶
   cp data/deduplication/raw_data_deduped.csv data/raw_data.csv
   cp data/deduplication/data_deduped.csv data/data.csv
   ```


### åç»­æ”¹è¿›ï¼ˆä¼˜å…ˆçº§ï¼šä¸­ï¼‰â­â­

4. **æ”¹è¿› append_session è„šæœ¬**
   - æ·»åŠ  experiment_id é‡å¤æ£€æŸ¥
   - æä¾›å»é‡é€‰é¡¹ï¼ˆè·³è¿‡/è¦†ç›–/åˆå¹¶ï¼‰

5. **å»ºç«‹æ•°æ®è´¨é‡ç›‘æ§**
   - æ¯æ¬¡è¿½åŠ æ•°æ®åè‡ªåŠ¨æ£€æŸ¥é‡å¤
   - ç”Ÿæˆæ•°æ®è´¨é‡æŠ¥å‘Š

6. **æ›´æ–° backfilled æ•°æ®**
   - å¯¹å»é‡åçš„ raw_data.csv é‡æ–°è¿è¡Œå›æº¯è„šæœ¬
   - ç¡®ä¿åˆ†ææ•°æ®çš„ä¸€è‡´æ€§

---

## ğŸ‰ æ€»ç»“

### å…³é”®å‘ç°

1. âš ï¸ **raw_data.csv å­˜åœ¨ 185 è¡Œé‡å¤æ•°æ®**ï¼ˆ15.1%ï¼‰
2. âš ï¸ **data.csv å­˜åœ¨ 120 è¡Œé‡å¤æ•°æ®**ï¼ˆ12.4%ï¼‰
3. âš ï¸ é‡å¤åŸå› ï¼šå®éªŒå¤±è´¥é‡è·‘ + æ•°æ®ä¿®å¤å¤šæ¬¡è¿½åŠ 
4. âœ… å·²æä¾›å»é‡è„šæœ¬å’Œè¯¦ç»†è§£å†³æ–¹æ¡ˆ

### å»ºè®®è¡ŒåŠ¨

**ç«‹å³æ‰§è¡Œ**:
```bash
# 1. é¢„è§ˆå»é‡ç»“æœ
python3 tools/data_management/deduplicate_data_files.py --dry-run

# 2. æ‰§è¡Œå»é‡
python3 tools/data_management/deduplicate_data_files.py

# 3. éªŒè¯ç»“æœ
wc -l data/deduplication/*.csv
```

**é¢„æœŸæ”¹å–„**:
- raw_data.csv: 1,225 â†’ 1,040 è¡Œï¼ˆå”¯ä¸€æ€§ 100%ï¼‰
- data.csv: 970 â†’ 850 è¡Œï¼ˆå”¯ä¸€æ€§ 100%ï¼‰
- æ•°æ®å¯ä¿¡åº¦ï¼šä¸­ç­‰ â†’ é«˜

---

## ğŸ“ ç›¸å…³æ–‡ä»¶

- **å»é‡è„šæœ¬**: `tools/data_management/deduplicate_data_files.py`
- **åˆ†ææŠ¥å‘Š**: `analysis/data/energy_research/DUPLICATE_DATA_ANALYSIS_REPORT.md`ï¼ˆæœ¬æ–‡ä»¶ï¼‰
- **æ•°æ®ç°çŠ¶æŠ¥å‘Š**: `analysis/data/energy_research/DATA_STATUS_REPORT_20260114.md`
- **å¯¹æ¯”åˆ†æ**: `analysis/data/energy_research/RAW_DATA_VS_DATA_CSV_COMPARISON.md`

---

**æŠ¥å‘Šç”Ÿæˆ**: 2026-01-14
**åˆ†æå·¥å…·**: Python pandas
**çŠ¶æ€**: âœ… åˆ†æå®Œæˆï¼Œç­‰å¾…æ‰§è¡Œå»é‡

#!/usr/bin/env python3
"""
æ­¥éª¤1: åˆ†æå¹¶è¡Œ/éå¹¶è¡Œæ¨¡å¼çš„ä¸»æ•ˆåº”

ç›®çš„ï¼š
å¿«é€Ÿåˆ¤æ–­æ¨¡å¼å¯¹èƒ½è€—çš„å½±å“æ˜¯å¦æ˜¾è‘—ï¼Œå†³å®šæ˜¯å¦éœ€è¦æ·±å…¥çš„åˆ†å±‚DiBSåˆ†æã€‚

åˆ›å»ºæ—¥æœŸ: 2026-01-06
"""

import pandas as pd
import numpy as np
from scipy import stats
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import json

# è®¾ç½®
sns.set_style("whitegrid")
plt.rcParams['figure.figsize'] = (16, 10)

# è·¯å¾„
DATA_FILE = Path("/home/green/energy_dl/nightly/data/raw_data.csv")
OUTPUT_DIR = Path("/home/green/energy_dl/nightly/analysis/results/energy_research/mode_analysis")
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)


def load_data():
    """åŠ è½½æ•°æ®"""
    print("åŠ è½½æ•°æ®...")
    df = pd.read_csv(DATA_FILE)

    # åˆ›å»ºis_parallelåˆ—
    df['is_parallel'] = (df['mode'] == 'parallel').astype(int)

    print(f"  æ€»æ ·æœ¬æ•°: {len(df)}")
    print(f"  å¹¶è¡Œæ¨¡å¼: {df['is_parallel'].sum()} ({df['is_parallel'].sum()/len(df)*100:.1f}%)")
    print(f"  éå¹¶è¡Œæ¨¡å¼: {(~df['is_parallel'].astype(bool)).sum()} ({(~df['is_parallel'].astype(bool)).sum()/len(df)*100:.1f}%)")

    return df


def analyze_mode_main_effect(df):
    """åˆ†ææ¨¡å¼çš„ä¸»æ•ˆåº”"""

    print("\n" + "="*80)
    print("æ¨¡å¼ä¸»æ•ˆåº”åˆ†æï¼ˆtæ£€éªŒï¼‰")
    print("="*80)

    # èƒ½è€—æŒ‡æ ‡
    energy_metrics = [
        'energy_gpu_total_joules',
        'energy_gpu_avg_watts',
        'energy_gpu_max_watts',
        'energy_gpu_min_watts',
        'energy_cpu_total_joules',
    ]

    results = []

    for metric in energy_metrics:
        # åˆ†ç»„æ•°æ®
        parallel = df[df['is_parallel'] == 1][metric].dropna()
        non_parallel = df[df['is_parallel'] == 0][metric].dropna()

        if len(parallel) < 10 or len(non_parallel) < 10:
            print(f"\nâŒ {metric}: æ ·æœ¬é‡ä¸è¶³")
            continue

        # tæ£€éªŒ
        t_stat, p_value = stats.ttest_ind(parallel, non_parallel)

        # Cohen's d (æ•ˆåº”é‡)
        pooled_std = np.sqrt(((len(parallel)-1)*parallel.std()**2 + (len(non_parallel)-1)*non_parallel.std()**2) / (len(parallel)+len(non_parallel)-2))
        cohens_d = (parallel.mean() - non_parallel.mean()) / pooled_std

        # ç»“æœ
        result = {
            'metric': metric,
            'parallel_mean': float(parallel.mean()),
            'parallel_std': float(parallel.std()),
            'parallel_n': int(len(parallel)),
            'non_parallel_mean': float(non_parallel.mean()),
            'non_parallel_std': float(non_parallel.std()),
            'non_parallel_n': int(len(non_parallel)),
            'mean_diff': float(parallel.mean() - non_parallel.mean()),
            'mean_diff_pct': float((parallel.mean() - non_parallel.mean()) / non_parallel.mean() * 100),
            't_statistic': float(t_stat),
            'p_value': float(p_value),
            'cohens_d': float(cohens_d),
            'is_significant': p_value < 0.05
        }

        results.append(result)

        # æ‰“å°ç»“æœ
        print(f"\n{metric}:")
        print(f"  å¹¶è¡Œæ¨¡å¼: {parallel.mean():.2f} Â± {parallel.std():.2f} (n={len(parallel)})")
        print(f"  éå¹¶è¡Œæ¨¡å¼: {non_parallel.mean():.2f} Â± {non_parallel.std():.2f} (n={len(non_parallel)})")
        print(f"  å¹³å‡å·®å¼‚: {result['mean_diff']:.2f} ({result['mean_diff_pct']:.1f}%)")
        print(f"  tæ£€éªŒ: t={t_stat:.3f}, p={p_value:.4f} {'***' if p_value < 0.001 else '**' if p_value < 0.01 else '*' if p_value < 0.05 else 'ns'}")
        print(f"  æ•ˆåº”é‡: Cohen's d={cohens_d:.3f} ({'å¤§' if abs(cohens_d) > 0.8 else 'ä¸­' if abs(cohens_d) > 0.5 else 'å°' if abs(cohens_d) > 0.2 else 'æå°'})")
        print(f"  æ˜¾è‘—æ€§: {'âœ… æ˜¾è‘—' if p_value < 0.05 else 'âŒ ä¸æ˜¾è‘—'}")

    return results


def analyze_mode_by_group(df):
    """æŒ‰ä»»åŠ¡ç»„åˆ†ææ¨¡å¼æ•ˆåº”"""

    print("\n" + "="*80)
    print("æŒ‰ä»“åº“åˆ†ææ¨¡å¼æ•ˆåº”")
    print("="*80)

    # æŒ‰repositoryåˆ†ç»„
    repos = ['examples', 'VulBERTa', 'Person_reID_baseline_pytorch',
             'pytorch_resnet_cifar10', 'bug-localization-by-dnn-and-rvsm', 'MRT-OAST']
    energy_metric = 'energy_gpu_total_joules'

    results = []

    for repo in repos:
        repo_df = df[df['repository'] == repo]

        if len(repo_df) == 0:
            continue

        parallel = repo_df[repo_df['is_parallel'] == 1][energy_metric].dropna()
        non_parallel = repo_df[repo_df['is_parallel'] == 0][energy_metric].dropna()

        if len(parallel) < 10 or len(non_parallel) < 10:
            print(f"\n{repo}: æ ·æœ¬é‡ä¸è¶³ (å¹¶è¡Œ={len(parallel)}, éå¹¶è¡Œ={len(non_parallel)})")
            continue

        t_stat, p_value = stats.ttest_ind(parallel, non_parallel)

        result = {
            'repo': repo,
            'parallel_n': int(len(parallel)),
            'non_parallel_n': int(len(non_parallel)),
            'parallel_mean': float(parallel.mean()),
            'non_parallel_mean': float(non_parallel.mean()),
            'mean_diff_pct': float((parallel.mean() - non_parallel.mean()) / non_parallel.mean() * 100),
            'p_value': float(p_value),
            'is_significant': p_value < 0.05
        }

        results.append(result)

        print(f"\n{repo} ({energy_metric}):")
        print(f"  å¹¶è¡Œ: {parallel.mean():.2f} (n={len(parallel)})")
        print(f"  éå¹¶è¡Œ: {non_parallel.mean():.2f} (n={len(non_parallel)})")
        print(f"  å·®å¼‚: {result['mean_diff_pct']:.1f}%")
        print(f"  på€¼: {p_value:.4f} {'âœ…' if p_value < 0.05 else 'âŒ'}")

    return results


def visualize_mode_effect(df):
    """å¯è§†åŒ–æ¨¡å¼æ•ˆåº”"""

    print("\nç”Ÿæˆå¯è§†åŒ–...")

    energy_metrics = [
        ('energy_gpu_total_joules', 'GPU Total Energy (J)'),
        ('energy_gpu_avg_watts', 'GPU Avg Power (W)'),
        ('energy_gpu_max_watts', 'GPU Max Power (W)'),
    ]

    # å›¾1: ç®±çº¿å›¾å¯¹æ¯”
    fig, axes = plt.subplots(1, 3, figsize=(18, 6))

    for i, (metric, label) in enumerate(energy_metrics):
        ax = axes[i]

        # å‡†å¤‡æ•°æ®
        plot_df = df[['is_parallel', metric]].dropna()
        plot_df['Mode'] = plot_df['is_parallel'].map({1: 'Parallel', 0: 'Non-Parallel'})

        # ç®±çº¿å›¾
        sns.boxplot(x='Mode', y=metric, data=plot_df, ax=ax)

        # æ·»åŠ æ˜¾è‘—æ€§æ ‡è®°
        parallel = plot_df[plot_df['is_parallel'] == 1][metric]
        non_parallel = plot_df[plot_df['is_parallel'] == 0][metric]
        _, p_value = stats.ttest_ind(parallel, non_parallel)

        if p_value < 0.05:
            # æ·»åŠ æ˜¾è‘—æ€§æ˜Ÿå·
            y_max = plot_df[metric].max()
            ax.text(0.5, y_max * 1.05, '***' if p_value < 0.001 else '**' if p_value < 0.01 else '*',
                   ha='center', fontsize=16)

        ax.set_title(f'{label}\n(p={p_value:.4f})')
        ax.set_xlabel('Training Mode')
        ax.set_ylabel(label)

    plt.tight_layout()
    plt.savefig(OUTPUT_DIR / 'mode_effect_boxplots.png', dpi=300)
    print(f"  âœ… ä¿å­˜: mode_effect_boxplots.png")
    plt.close()

    # å›¾2: åˆ†ç»„å¯¹æ¯”
    repos = ['examples', 'VulBERTa', 'Person_reID_baseline_pytorch']
    metric = 'energy_gpu_total_joules'

    fig, axes = plt.subplots(1, 3, figsize=(18, 6))

    for i, repo in enumerate(repos):
        repo_df = df[df['repository'] == repo]

        if len(repo_df) == 0:
            continue

        ax = axes[i]

        plot_df = repo_df[['is_parallel', metric]].dropna()
        plot_df['Mode'] = plot_df['is_parallel'].map({1: 'Parallel', 0: 'Non-Parallel'})

        sns.boxplot(x='Mode', y=metric, data=plot_df, ax=ax)

        # æ˜¾è‘—æ€§
        parallel = plot_df[plot_df['is_parallel'] == 1][metric]
        non_parallel = plot_df[plot_df['is_parallel'] == 0][metric]

        if len(parallel) >= 10 and len(non_parallel) >= 10:
            _, p_value = stats.ttest_ind(parallel, non_parallel)

            if p_value < 0.05:
                y_max = plot_df[metric].max()
                ax.text(0.5, y_max * 1.05, '***' if p_value < 0.001 else '**' if p_value < 0.01 else '*',
                       ha='center', fontsize=16)

            ax.set_title(f'{repo}\n(p={p_value:.4f})')
        else:
            ax.set_title(f'{repo}\n(æ ·æœ¬é‡ä¸è¶³)')

        ax.set_xlabel('Training Mode')
        ax.set_ylabel('GPU Total Energy (J)')

    plt.tight_layout()
    plt.savefig(OUTPUT_DIR / 'mode_effect_by_repo.png', dpi=300)
    print(f"  âœ… ä¿å­˜: mode_effect_by_repo.png")
    plt.close()


def generate_report(overall_results, group_results):
    """ç”ŸæˆæŠ¥å‘Š"""

    report_file = OUTPUT_DIR / "MODE_MAIN_EFFECT_REPORT.md"

    with open(report_file, 'w') as f:
        f.write("# å¹¶è¡Œ/éå¹¶è¡Œæ¨¡å¼ä¸»æ•ˆåº”åˆ†ææŠ¥å‘Š\n\n")
        f.write(f"**åˆ†ææ—¥æœŸ**: 2026-01-06\n")
        f.write(f"**ç›®çš„**: åˆ¤æ–­æ˜¯å¦éœ€è¦è¿›è¡Œåˆ†å±‚DiBSåˆ†æ\n\n")

        f.write("---\n\n")

        # æ€»ä½“æ•ˆåº”
        f.write("## ğŸ“Š æ€»ä½“æ•ˆåº”åˆ†æ\n\n")

        significant_count = sum(1 for r in overall_results if r['is_significant'])

        f.write(f"**æ˜¾è‘—èƒ½è€—æŒ‡æ ‡**: {significant_count}/{len(overall_results)}\n\n")

        # è¡¨æ ¼
        f.write("| èƒ½è€—æŒ‡æ ‡ | å¹¶è¡Œæ¨¡å¼ | éå¹¶è¡Œæ¨¡å¼ | å·®å¼‚ | på€¼ | Cohen's d | æ˜¾è‘—æ€§ |\n")
        f.write("|---------|---------|-----------|------|-----|-----------|--------|\n")

        for r in overall_results:
            f.write(f"| {r['metric']} | {r['parallel_mean']:.2f}Â±{r['parallel_std']:.2f} | "
                   f"{r['non_parallel_mean']:.2f}Â±{r['non_parallel_std']:.2f} | "
                   f"{r['mean_diff_pct']:+.1f}% | {r['p_value']:.4f} | {r['cohens_d']:.3f} | "
                   f"{'âœ…' if r['is_significant'] else 'âŒ'} |\n")

        f.write("\n")

        # æŒ‰ç»„åˆ†æ
        if group_results:
            f.write("## ğŸ“‹ æŒ‰ä»“åº“åˆ†æ\n\n")

            f.write("| ä»“åº“ | å¹¶è¡Œ(n) | éå¹¶è¡Œ(n) | å¹¶è¡Œå‡å€¼ | éå¹¶è¡Œå‡å€¼ | å·®å¼‚% | på€¼ | æ˜¾è‘— |\n")
            f.write("|--------|---------|----------|---------|-----------|-------|-----|------|\n")

            for r in group_results:
                f.write(f"| {r['repo']} | {r['parallel_n']} | {r['non_parallel_n']} | "
                       f"{r['parallel_mean']:.2f} | {r['non_parallel_mean']:.2f} | "
                       f"{r['mean_diff_pct']:+.1f}% | {r['p_value']:.4f} | "
                       f"{'âœ…' if r['is_significant'] else 'âŒ'} |\n")

            f.write("\n")

        # å†³ç­–å»ºè®®
        f.write("## ğŸ’¡ å†³ç­–å»ºè®®\n\n")

        if significant_count >= len(overall_results) / 2:
            f.write("### âœ… å»ºè®®è¿›è¡Œå®Œæ•´çš„åˆ†å±‚DiBSåˆ†æ\n\n")
            f.write(f"**ç†ç”±**: {significant_count}/{len(overall_results)}ä¸ªèƒ½è€—æŒ‡æ ‡æ˜¾ç¤ºæ¨¡å¼æœ‰æ˜¾è‘—å½±å“ã€‚\n\n")
            f.write("**åç»­æ­¥éª¤**:\n")
            f.write("1. æŒ‰æ¨¡å¼å‡†å¤‡DiBSè®­ç»ƒæ•°æ®\n")
            f.write("2. åˆ†åˆ«è¿è¡Œå¹¶è¡Œå’Œéå¹¶è¡Œæ¨¡å¼çš„DiBS\n")
            f.write("3. æ¯”è¾ƒä¸¤ä¸ªå› æœå›¾çš„å·®å¼‚\n")
            f.write("4. è¿è¡Œäº¤äº’æ•ˆåº”å›å½’åˆ†æ\n")
            f.write("5. è¿è¡Œåˆ†å±‚ä¸­ä»‹åˆ†æ\n\n")
        else:
            f.write("### âš ï¸ å»ºè®®è¿›è¡Œç®€åŒ–åˆ†æ\n\n")
            f.write(f"**ç†ç”±**: ä»…{significant_count}/{len(overall_results)}ä¸ªèƒ½è€—æŒ‡æ ‡æ˜¾ç¤ºæ¨¡å¼æœ‰æ˜¾è‘—å½±å“ã€‚\n\n")
            f.write("**åç»­æ­¥éª¤**:\n")
            f.write("1. è·³è¿‡åˆ†å±‚DiBSï¼ˆæ ·æœ¬é‡å‡åŠï¼Œå¯èƒ½ä¸ç¨³å®šï¼‰\n")
            f.write("2. åªè¿è¡Œäº¤äº’æ•ˆåº”å›å½’åˆ†æï¼ˆéªŒè¯å½“å‰å‘ç°çš„è¾¹ï¼‰\n")
            f.write("3. åœ¨æŠ¥å‘Šä¸­è¯´æ˜æ¨¡å¼å½±å“è¾ƒå°\n\n")

        # å…³é”®å‘ç°
        f.write("## ğŸ” å…³é”®å‘ç°\n\n")

        # æ‰¾å‡ºæ•ˆåº”é‡æœ€å¤§çš„æŒ‡æ ‡
        max_effect = max(overall_results, key=lambda x: abs(x['cohens_d']))

        f.write(f"**æ•ˆåº”é‡æœ€å¤§çš„æŒ‡æ ‡**: {max_effect['metric']}\n")
        f.write(f"- Cohen's d = {max_effect['cohens_d']:.3f}\n")
        f.write(f"- å¹³å‡å·®å¼‚ = {max_effect['mean_diff_pct']:+.1f}%\n")
        f.write(f"- på€¼ = {max_effect['p_value']:.4f}\n\n")

        # æ–¹å‘
        positive_effects = [r for r in overall_results if r['mean_diff'] > 0 and r['is_significant']]
        negative_effects = [r for r in overall_results if r['mean_diff'] < 0 and r['is_significant']]

        if positive_effects:
            f.write(f"**å¹¶è¡Œæ¨¡å¼èƒ½è€—æ›´é«˜çš„æŒ‡æ ‡**: {len(positive_effects)}ä¸ª\n")
            for r in positive_effects:
                f.write(f"- {r['metric']}: +{r['mean_diff_pct']:.1f}% (p={r['p_value']:.4f})\n")
            f.write("\n")

        if negative_effects:
            f.write(f"**å¹¶è¡Œæ¨¡å¼èƒ½è€—æ›´ä½çš„æŒ‡æ ‡**: {len(negative_effects)}ä¸ª\n")
            for r in negative_effects:
                f.write(f"- {r['metric']}: {r['mean_diff_pct']:.1f}% (p={r['p_value']:.4f})\n")
            f.write("\n")

        f.write("---\n\n")
        f.write("**æŠ¥å‘Šç”Ÿæˆæ—¶é—´**: 2026-01-06\n")
        f.write("**ä¸‹ä¸€æ­¥**: æ ¹æ®å†³ç­–å»ºè®®é€‰æ‹©åˆ†æç­–ç•¥\n")

    print(f"\nâœ… æŠ¥å‘Šå·²ä¿å­˜: {report_file}")

    return report_file


def save_results_json(overall_results, group_results):
    """ä¿å­˜JSONç»“æœ"""

    json_file = OUTPUT_DIR / "mode_main_effect_results.json"

    # è½¬æ¢numpyç±»å‹ä¸ºPythonåŸç”Ÿç±»å‹
    def convert_to_python_types(obj):
        if isinstance(obj, dict):
            return {k: convert_to_python_types(v) for k, v in obj.items()}
        elif isinstance(obj, list):
            return [convert_to_python_types(item) for item in obj]
        elif isinstance(obj, (np.bool_, np.bool8)):
            return bool(obj)
        elif isinstance(obj, (np.int_, np.intc, np.intp, np.int8, np.int16, np.int32, np.int64)):
            return int(obj)
        elif isinstance(obj, (np.float_, np.float16, np.float32, np.float64)):
            return float(obj)
        else:
            return obj

    results = {
        'overall': convert_to_python_types(overall_results),
        'by_group': convert_to_python_types(group_results)
    }

    with open(json_file, 'w') as f:
        json.dump(results, f, indent=2)

    print(f"âœ… JSONç»“æœå·²ä¿å­˜: {json_file}")


def main():
    """ä¸»å‡½æ•°"""

    print("="*80)
    print("æ­¥éª¤1: å¹¶è¡Œ/éå¹¶è¡Œæ¨¡å¼ä¸»æ•ˆåº”åˆ†æ")
    print("="*80)

    # åŠ è½½æ•°æ®
    df = load_data()

    # æ€»ä½“æ•ˆåº”åˆ†æ
    overall_results = analyze_mode_main_effect(df)

    # æŒ‰ç»„åˆ†æ
    group_results = analyze_mode_by_group(df)

    # å¯è§†åŒ–
    visualize_mode_effect(df)

    # ä¿å­˜ç»“æœ
    save_results_json(overall_results, group_results)

    # ç”ŸæˆæŠ¥å‘Š
    report_file = generate_report(overall_results, group_results)

    print("\n" + "="*80)
    print("âœ… åˆ†æå®Œæˆï¼")
    print("="*80)
    print(f"  è¾“å‡ºç›®å½•: {OUTPUT_DIR}")
    print(f"  æŠ¥å‘Šæ–‡ä»¶: {report_file}")
    print("="*80)


if __name__ == "__main__":
    main()

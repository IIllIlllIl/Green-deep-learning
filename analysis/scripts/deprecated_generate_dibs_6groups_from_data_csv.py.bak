#!/usr/bin/env python3
"""
生成6分组DiBS训练数据（基于data.csv）

目的：
从高质量的data.csv (970行) 生成6个任务组的DiBS训练数据
不使用硬编码填充，直接使用data.csv中的数据

创建日期: 2026-01-15
"""

import pandas as pd
import numpy as np
from pathlib import Path
import json
from datetime import datetime

# 路径
DATA_FILE = Path("/home/green/energy_dl/nightly/data/data.csv")
OUTPUT_DIR = Path("/home/green/energy_dl/nightly/analysis/data/energy_research/dibs_training")

OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

# 任务组定义
TASK_GROUPS = {
    'group1_examples': {
        'repos': ['examples'],
        'models': ['mnist_ff', 'mnist_rnn', 'siamese', 'mnist'],
        'name': 'examples（图像分类-小型）'
    },
    'group2_vulberta': {
        'repos': ['VulBERTa'],
        'models': ['mlp', 'lstm', 'cnn'],
        'name': 'VulBERTa（代码漏洞检测）'
    },
    'group3_person_reid': {
        'repos': ['Person_reID_baseline_pytorch'],
        'models': ['densenet121', 'hrnet18', 'pcb', 'resnet50', 'resnet50_ibn_a'],
        'name': 'Person_reID（行人重识别）'
    },
    'group4_bug_localization': {
        'repos': ['bug-localization-by-dnn-and-rvsm'],
        'models': ['default', 'dnn', 'dnn_attention', 'dnn_bilstm', 'dnn_cnn'],
        'name': 'bug-localization（缺陷定位）'
    },
    'group5_mrt_oast': {
        'repos': ['MRT-OAST'],
        'models': ['default', 'resnet', 'googlenet', 'densenet'],
        'name': 'MRT-OAST（缺陷定位）'
    },
    'group6_resnet': {
        'repos': ['pytorch_resnet_cifar10'],
        'models': ['resnet20', 'resnet32', 'resnet44'],
        'name': 'pytorch_resnet（图像分类-ResNet）'
    }
}

# 缺失率阈值
MISSING_THRESHOLD = 0.40


def load_data():
    """加载data.csv"""
    print("加载数据...")
    df = pd.read_csv(DATA_FILE)
    print(f"  总样本数: {len(df)}")
    print(f"  列数: {len(df.columns)}")

    # 检查必需列
    required_cols = ['repository', 'model', 'training_success', 'is_parallel']
    missing_cols = [col for col in required_cols if col not in df.columns]
    if missing_cols:
        raise ValueError(f"缺少必需列: {missing_cols}")

    # 筛选训练成功的数据
    df_success = df[df['training_success'] == True].copy()
    print(f"  训练成功: {len(df_success)} ({len(df_success)/len(df)*100:.1f}%)")

    return df_success


def prepare_task_group_data(df, group_id, group_config, missing_threshold=0.40):
    """
    准备单个任务组的DiBS数据

    参数:
        df: 完整数据框
        group_id: 任务组ID
        group_config: 任务组配置
        missing_threshold: 缺失率阈值

    返回:
        (data_clean, stats) 或 (None, error_message)
    """

    # 过滤仓库和模型
    repos = group_config['repos']
    models = group_config['models']

    group_df = df[
        (df['repository'].isin(repos)) &
        (df['model'].isin(models))
    ].copy()

    if len(group_df) == 0:
        return None, f"没有符合条件的数据"

    print(f"  原始样本数: {len(group_df)}")

    # 选择特征列
    # 1. 超参数
    hyperparam_cols = [col for col in group_df.columns if col.startswith('hyperparam_')]

    # 2. 性能指标
    perf_cols = [col for col in group_df.columns if col.startswith('perf_')]

    # 3. 能耗指标
    energy_cols = [col for col in group_df.columns if col.startswith('energy_')]

    # 4. 控制变量
    control_cols = ['duration_seconds', 'is_parallel']  # ⭐ 添加 is_parallel
    control_cols = [col for col in control_cols if col in group_df.columns]

    # 5. 可选：添加 num_mutated_params（如果存在）
    if 'num_mutated_params' in group_df.columns:
        control_cols.append('num_mutated_params')

    all_cols = hyperparam_cols + perf_cols + energy_cols + control_cols

    # 确保列存在
    available_cols = [col for col in all_cols if col in group_df.columns]

    print(f"  可用特征列: {len(available_cols)}")
    print(f"    - 超参数: {len([c for c in available_cols if c.startswith('hyperparam_')])}")
    print(f"    - 性能: {len([c for c in available_cols if c.startswith('perf_')])}")
    print(f"    - 能耗: {len([c for c in available_cols if c.startswith('energy_')])}")
    print(f"    - 控制: {len([c for c in available_cols if c in control_cols])}")

    data = group_df[available_cols].copy()

    # 计算缺失率
    missing_rates = data.isnull().sum() / len(data)

    # 移除缺失率过高的列
    cols_to_keep = missing_rates[missing_rates <= missing_threshold].index.tolist()
    cols_removed = set(available_cols) - set(cols_to_keep)

    if cols_removed:
        print(f"  移除缺失率>{missing_threshold*100:.0f}%的列 ({len(cols_removed)}个):")
        for col in sorted(cols_removed):
            print(f"    - {col}: {missing_rates[col]*100:.1f}%缺失")

    data = data[cols_to_keep]

    # 统计移除前的行数
    rows_before = len(data)

    # 移除仍有缺失值的行
    data_clean = data.dropna()

    rows_removed = rows_before - len(data_clean)
    if rows_removed > 0:
        print(f"  移除含缺失值的行: {rows_removed}行 ({rows_removed/rows_before*100:.1f}%)")

    # 重新分类列
    final_cols = data_clean.columns.tolist()
    final_hyperparams = [col for col in final_cols if col.startswith('hyperparam_')]
    final_perf = [col for col in final_cols if col.startswith('perf_')]
    final_energy = [col for col in final_cols if col.startswith('energy_')]
    final_controls = [col for col in final_cols if col in control_cols]

    # 统计信息
    stats = {
        'group_id': group_id,
        'group_name': group_config['name'],
        'repositories': repos,
        'models': models,
        'n_samples_raw': len(group_df),
        'n_samples_final': len(data_clean),
        'n_features_raw': len(available_cols),
        'n_features_final': len(final_cols),
        'n_cols_removed_high_missing': len(cols_removed),
        'n_rows_removed_missing': rows_removed,
        'missing_threshold': missing_threshold,
        'feature_names': final_cols,
        'hyperparams': final_hyperparams,
        'performance': final_perf,
        'energy': final_energy,
        'controls': final_controls,
        'missing_rate_before_clean': float(data.isnull().sum().sum() / data.size),
        'processing_success': True
    }

    return data_clean, stats


def main():
    """主函数"""

    print("="*80)
    print("生成6分组DiBS训练数据（基于data.csv）")
    print("="*80)
    print(f"生成时间: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"数据源: {DATA_FILE}")
    print(f"输出目录: {OUTPUT_DIR}")
    print("="*80)

    # 加载数据
    df = load_data()

    # 为每个任务组准备数据
    all_stats = {
        'generation_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        'input_file': str(DATA_FILE),
        'output_dir': str(OUTPUT_DIR),
        'total_tasks': len(TASK_GROUPS),
        'successful_tasks': 0,
        'task_stats': []
    }

    for group_id, group_config in TASK_GROUPS.items():
        print(f"\n{'='*80}")
        print(f"处理: {group_id} - {group_config['name']}")
        print(f"{'='*80}")

        data, stats = prepare_task_group_data(
            df, group_id, group_config,
            missing_threshold=MISSING_THRESHOLD
        )

        if data is None:
            print(f"  ❌ 失败: {stats}")
            stats_record = {
                'group_id': group_id,
                'group_name': group_config['name'],
                'processing_success': False,
                'error': stats
            }
            all_stats['task_stats'].append(stats_record)
            continue

        # 保存数据
        output_file = OUTPUT_DIR / f"{group_id}.csv"
        data.to_csv(output_file, index=False)
        stats['output_file'] = str(output_file)

        all_stats['task_stats'].append(stats)
        all_stats['successful_tasks'] += 1

        print(f"\n  ✅ 处理成功")
        print(f"     样本数: {stats['n_samples_raw']} → {stats['n_samples_final']} (清洗后)")
        print(f"     特征数: {stats['n_features_raw']} → {stats['n_features_final']} (过滤后)")
        print(f"     - 超参数: {len(stats['hyperparams'])}")
        print(f"     - 性能: {len(stats['performance'])}")
        print(f"     - 能耗: {len(stats['energy'])}")
        print(f"     - 控制: {len(stats['controls'])}")
        print(f"     保存至: {output_file}")

        # 检查样本量
        if stats['n_samples_final'] < 30:
            print(f"  ⚠️  警告: 样本量过少 (n={stats['n_samples_final']}), DiBS结果可能不稳定")
        elif stats['n_samples_final'] < 50:
            print(f"  ⚠️  提示: 样本量偏少 (n={stats['n_samples_final']}), 建议关注结果稳定性")

    # 保存汇总统计
    summary_file = OUTPUT_DIR / "generation_stats.json"
    with open(summary_file, 'w', encoding='utf-8') as f:
        json.dump(all_stats, f, indent=2, ensure_ascii=False)

    print("\n" + "="*80)
    print("✅ 数据生成完成！")
    print("="*80)
    print(f"\n成功率: {all_stats['successful_tasks']}/{all_stats['total_tasks']} "
          f"({all_stats['successful_tasks']/all_stats['total_tasks']*100:.1f}%)")

    # 汇总统计
    print("\n任务组样本量汇总:\n")
    print(f"{'任务组':<30} {'原始':<10} {'清洗后':<10} {'保留率':<10}")
    print("-" * 70)

    total_raw = 0
    total_final = 0

    for task_stat in all_stats['task_stats']:
        if task_stat['processing_success']:
            group_name = task_stat['group_name']
            n_raw = task_stat['n_samples_raw']
            n_final = task_stat['n_samples_final']
            retention = n_final / n_raw * 100 if n_raw > 0 else 0

            print(f"{group_name:<30} {n_raw:<10} {n_final:<10} {retention:>6.1f}%")

            total_raw += n_raw
            total_final += n_final

    print("-" * 70)
    print(f"{'总计':<30} {total_raw:<10} {total_final:<10} {total_final/total_raw*100:>6.1f}%")

    print(f"\n输出目录: {OUTPUT_DIR}")
    print(f"统计文件: {summary_file}")
    print("="*80)


if __name__ == "__main__":
    main()

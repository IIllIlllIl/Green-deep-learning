# é˜¶æ®µ3-5è¯¦ç»†å®æ–½æ–¹æ¡ˆ

**æ—¥æœŸ**: 2025-12-24
**ç‰ˆæœ¬**: v1.0
**åŸºäº**: é˜¶æ®µ2å®Œæˆæˆæœï¼ˆenergy_data_extracted_v2.csv, 418è¡ŒÃ—34åˆ—ï¼‰

---

## æ¦‚è¿°

æœ¬æ–‡æ¡£è¯¦ç»†è§„åˆ’é˜¶æ®µ3-5çš„å®æ–½æ–¹æ¡ˆï¼Œä»æ•°æ®åˆ†å±‚ä¿å­˜åˆ°DiBSå› æœåˆ†æéªŒè¯çš„å®Œæ•´æµç¨‹ã€‚

**å…³é”®åŸåˆ™** â­â­â­:
- **æµ‹è¯•é©±åŠ¨**: æ¯ä¸ªè„šæœ¬å¿…é¡»ç¼–å†™å¯¹åº”çš„æµ‹è¯•æ–‡ä»¶
- **Dry Runä¼˜å…ˆ**: å…ˆåœ¨å°‘é‡æ•°æ®ä¸ŠéªŒè¯é€»è¾‘ï¼Œå†å…¨é‡æ‰§è¡Œ
- **å¢é‡å¼€å‘**: ä¸€æ¬¡å®Œæˆä¸€ä¸ªé˜¶æ®µï¼ŒéªŒè¯é€šè¿‡åå†è¿›å…¥ä¸‹ä¸€é˜¶æ®µ

---

## é˜¶æ®µ3ï¼šæ•°æ®åˆ†å±‚ä¸ä¿å­˜

### 3.1 ç›®æ ‡

å°†418è¡Œç»Ÿä¸€æ•°æ®æŒ‰ä»»åŠ¡åˆ†å±‚ï¼Œç”Ÿæˆ4ä¸ªè®­ç»ƒæ•°æ®æ–‡ä»¶ï¼Œæ¯ä¸ªæ–‡ä»¶åªä¿ç•™ä»»åŠ¡ç›¸å…³çš„æ€§èƒ½æŒ‡æ ‡å’Œå˜é‡ã€‚

### 3.2 è¾“å…¥ä¸è¾“å‡º

**è¾“å…¥**:
- `data/energy_research/raw/energy_data_extracted_v2.csv` (418è¡ŒÃ—34åˆ—)
- `../../mutation/models_config.json` (ä»“åº“å’Œæ¨¡å‹å®šä¹‰)

**è¾“å‡º**:
```
analysis/data/energy_research/processed/
â”œâ”€â”€ training_data_image_classification.csv  (~116è¡ŒÃ—17åˆ—)
â”œâ”€â”€ training_data_person_reid.csv          (~69è¡ŒÃ—17åˆ—)
â”œâ”€â”€ training_data_vulberta.csv             (~96è¡ŒÃ—14åˆ—)
â””â”€â”€ training_data_bug_localization.csv     (~91è¡ŒÃ—14åˆ—)
```

**è¾“å‡ºåˆ—æ¸…å•ï¼ˆæŒ‰ä»»åŠ¡ç»„ï¼‰**:

#### å›¾åƒåˆ†ç±»ç»„ (17åˆ—)
```python
columns = [
    # å®éªŒæ ‡è¯† (2åˆ—)
    'experiment_id', 'timestamp',

    # One-Hotç¼–ç  (2åˆ—) - æ§åˆ¶æ•°æ®é›†å¼‚è´¨æ€§
    'is_mnist', 'is_cifar10',

    # è¶…å‚æ•° (4åˆ—)
    'training_duration', 'hyperparam_learning_rate',
    'l2_regularization', 'seed',

    # èƒ½è€—æŒ‡æ ‡ (3åˆ—)
    'energy_cpu_total_joules', 'energy_gpu_total_joules',
    'gpu_power_avg_watts',

    # ä¸­ä»‹å˜é‡ (5åˆ—)
    'gpu_util_avg', 'gpu_temp_max', 'cpu_pkg_ratio',
    'gpu_power_fluctuation', 'gpu_temp_fluctuation',

    # æ€§èƒ½æŒ‡æ ‡ (1åˆ—)
    'perf_test_accuracy'
]
```

#### Person_reIDç»„ (17åˆ—)
```python
columns = [
    # å®éªŒæ ‡è¯† (2åˆ—)
    'experiment_id', 'timestamp',

    # One-Hotç¼–ç  (3åˆ—) - æ§åˆ¶æ¨¡å‹å¼‚è´¨æ€§
    'is_densenet121', 'is_hrnet18', 'is_pcb',

    # è¶…å‚æ•° (4åˆ—)
    'training_duration', 'hyperparam_learning_rate',
    'hyperparam_dropout', 'seed',

    # èƒ½è€—æŒ‡æ ‡ (3åˆ—)
    'energy_cpu_total_joules', 'energy_gpu_total_joules',
    'gpu_power_avg_watts',

    # ä¸­ä»‹å˜é‡ (5åˆ—)
    'gpu_util_avg', 'gpu_temp_max', 'cpu_pkg_ratio',
    'gpu_power_fluctuation', 'gpu_temp_fluctuation',

    # æ€§èƒ½æŒ‡æ ‡ (3åˆ—)
    'perf_map', 'perf_rank1', 'perf_rank5'
]
```

#### VulBERTaç»„ (14åˆ—)
```python
columns = [
    # å®éªŒæ ‡è¯† (2åˆ—)
    'experiment_id', 'timestamp',

    # è¶…å‚æ•° (4åˆ—)
    'training_duration', 'hyperparam_learning_rate',
    'l2_regularization', 'seed',

    # èƒ½è€—æŒ‡æ ‡ (3åˆ—)
    'energy_cpu_total_joules', 'energy_gpu_total_joules',
    'gpu_power_avg_watts',

    # ä¸­ä»‹å˜é‡ (5åˆ—)
    'gpu_util_avg', 'gpu_temp_max', 'cpu_pkg_ratio',
    'gpu_power_fluctuation', 'gpu_temp_fluctuation',

    # æ€§èƒ½æŒ‡æ ‡ (1åˆ—)
    'perf_eval_loss'
]
```

#### Bugå®šä½ç»„ (14åˆ—)
```python
columns = [
    # å®éªŒæ ‡è¯† (2åˆ—)
    'experiment_id', 'timestamp',

    # è¶…å‚æ•° (4åˆ—)
    'training_duration', 'l2_regularization',
    'hyperparam_kfold', 'seed',

    # èƒ½è€—æŒ‡æ ‡ (3åˆ—)
    'energy_cpu_total_joules', 'energy_gpu_total_joules',
    'gpu_power_avg_watts',

    # ä¸­ä»‹å˜é‡ (5åˆ—)
    'gpu_util_avg', 'gpu_temp_max', 'cpu_pkg_ratio',
    'gpu_power_fluctuation', 'gpu_temp_fluctuation',

    # æ€§èƒ½æŒ‡æ ‡ (2åˆ—)
    'perf_top1_accuracy', 'perf_top5_accuracy'
]
```

### 3.3 æ ¸å¿ƒé€»è¾‘ä¼ªä»£ç 

```python
def preprocess_stratified_data():
    """
    æ•°æ®åˆ†å±‚é¢„å¤„ç†ä¸»å‡½æ•°

    æ­¥éª¤ï¼š
    1. åŠ è½½v2æ•°æ®
    2. æŒ‰ä»“åº“åˆ†ç»„
    3. ä¸ºæ¯ç»„åˆ›å»ºOne-Hotç¼–ç 
    4. é€‰æ‹©ä»»åŠ¡ç›¸å…³åˆ—
    5. åˆ é™¤æ€§èƒ½å…¨ç¼ºå¤±è¡Œ
    6. ä¿å­˜åˆ†å±‚æ–‡ä»¶
    """

    # 1. åŠ è½½æ•°æ®
    df = pd.read_csv('data/energy_research/raw/energy_data_extracted_v2.csv')

    # 2. å®šä¹‰ä»»åŠ¡ç»„æ˜ å°„
    task_groups = {
        'image_classification': {
            'repos': ['examples', 'pytorch_resnet_cifar10'],
            'models': {
                'examples': ['mnist', 'mnist_ff', 'mnist_rnn', 'siamese'],
                'pytorch_resnet_cifar10': ['resnet20']
            },
            'performance_cols': ['perf_test_accuracy'],
            'onehot_logic': lambda row: {
                'is_mnist': 1 if 'mnist' in row['model'] else 0,
                'is_cifar10': 1 if row['repository'] == 'pytorch_resnet_cifar10' else 0
            }
        },
        'person_reid': {
            'repos': ['Person_reID_baseline_pytorch'],
            'models': ['densenet121', 'hrnet18', 'pcb'],
            'performance_cols': ['perf_map', 'perf_rank1', 'perf_rank5'],
            'onehot_logic': lambda row: {
                'is_densenet121': 1 if row['model'] == 'densenet121' else 0,
                'is_hrnet18': 1 if row['model'] == 'hrnet18' else 0,
                'is_pcb': 1 if row['model'] == 'pcb' else 0
            }
        },
        'vulberta': {
            'repos': ['VulBERTa'],
            'models': ['mlp'],
            'performance_cols': ['perf_eval_loss'],
            'onehot_logic': None  # å•æ¨¡å‹ï¼Œæ— éœ€One-Hot
        },
        'bug_localization': {
            'repos': ['bug-localization-by-dnn-and-rvsm'],
            'models': ['default'],
            'performance_cols': ['perf_top1_accuracy', 'perf_top5_accuracy'],
            'onehot_logic': None  # å•æ¨¡å‹ï¼Œæ— éœ€One-Hot
        }
    }

    # 3. å¤„ç†æ¯ä¸ªä»»åŠ¡ç»„
    for task_name, config in task_groups.items():
        # ç­›é€‰ä»“åº“
        mask = df['repository'].isin(config['repos'])
        task_df = df[mask].copy()

        # æ·»åŠ One-Hotç¼–ç 
        if config['onehot_logic']:
            onehot_cols = task_df.apply(config['onehot_logic'], axis=1, result_type='expand')
            task_df = pd.concat([task_df, onehot_cols], axis=1)

        # åˆ é™¤æ€§èƒ½å…¨ç¼ºå¤±è¡Œ
        perf_cols = config['performance_cols']
        task_df = task_df.dropna(subset=perf_cols, how='all')

        # é€‰æ‹©ä»»åŠ¡ç›¸å…³åˆ—
        selected_cols = get_task_columns(task_name, config)
        task_df = task_df[selected_cols]

        # ä¿å­˜
        output_path = f'data/energy_research/processed/training_data_{task_name}.csv'
        task_df.to_csv(output_path, index=False)

        print(f"âœ… {task_name}: {len(task_df)} è¡Œï¼Œ{len(selected_cols)} åˆ—")
```

### 3.4 å®ç°è®¡åˆ’

#### æ­¥éª¤1: åˆ›å»ºä¸»è„šæœ¬ (40åˆ†é’Ÿ)

**æ–‡ä»¶**: `analysis/scripts/preprocess_stratified_data.py`

**åŠŸèƒ½æ¨¡å—**:
1. `load_extracted_data()` - åŠ è½½v2æ•°æ®
2. `create_onehot_encoding()` - ç”ŸæˆOne-Hotåˆ—
3. `select_task_columns()` - é€‰æ‹©ä»»åŠ¡ç›¸å…³åˆ—
4. `remove_missing_performance()` - åˆ é™¤æ€§èƒ½ç¼ºå¤±è¡Œ
5. `save_stratified_data()` - ä¿å­˜åˆ†å±‚æ–‡ä»¶
6. `generate_summary_report()` - ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š

#### æ­¥éª¤2: åˆ›å»ºæµ‹è¯•è„šæœ¬ (20åˆ†é’Ÿ)

**æ–‡ä»¶**: `analysis/scripts/test_preprocess_stratified_data.py`

**æµ‹è¯•ç”¨ä¾‹**:
1. `test_onehot_encoding()` - éªŒè¯One-Hotç”Ÿæˆé€»è¾‘
2. `test_column_selection()` - éªŒè¯åˆ—é€‰æ‹©æ­£ç¡®æ€§
3. `test_missing_removal()` - éªŒè¯ç¼ºå¤±å€¼åˆ é™¤
4. `test_dry_run()` - Dry runå‰10è¡Œæ•°æ®
5. `test_output_format()` - éªŒè¯è¾“å‡ºæ–‡ä»¶æ ¼å¼

**æµ‹è¯•æ•°æ®**: ä½¿ç”¨å‰10è¡Œæ•°æ®åˆ›å»ºmockè¾“å…¥

#### æ­¥éª¤3: Dry RunéªŒè¯ (10åˆ†é’Ÿ)

```bash
# è¿è¡Œdry runï¼ˆåªå¤„ç†å‰20è¡Œï¼‰
cd analysis/scripts
conda run -n fairness python3 preprocess_stratified_data.py --dry-run --limit 20

# æ£€æŸ¥è¾“å‡º
ls -lh ../data/energy_research/processed/
head -5 ../data/energy_research/processed/training_data_image_classification.csv
```

**éªŒè¯æ ‡å‡†**:
- âœ… 4ä¸ªCSVæ–‡ä»¶æˆåŠŸç”Ÿæˆ
- âœ… åˆ—æ•°ç¬¦åˆé¢„æœŸï¼ˆ14-17åˆ—ï¼‰
- âœ… One-Hotç¼–ç æ­£ç¡®ï¼ˆäº’æ–¥ï¼Œå’Œ=1ï¼‰
- âœ… æ— æ€§èƒ½å…¨ç¼ºå¤±è¡Œ

#### æ­¥éª¤4: å…¨é‡æ‰§è¡Œ (5åˆ†é’Ÿ)

```bash
# è¿è¡Œå…¨é‡å¤„ç†
conda run -n fairness python3 preprocess_stratified_data.py --output-dir ../data/energy_research/processed/

# ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
conda run -n fairness python3 preprocess_stratified_data.py --summary
```

**é¢„æœŸè¾“å‡º**:
```
âœ… å›¾åƒåˆ†ç±»: 116è¡Œ Ã— 17åˆ—
âœ… Person_reID: 69è¡Œ Ã— 17åˆ—
âœ… VulBERTa: 96è¡Œ Ã— 14åˆ—
âœ… Bugå®šä½: 91è¡Œ Ã— 14åˆ—

æ€»è®¡: 372è¡Œæœ‰æ•ˆæ•°æ®ï¼ˆåˆ é™¤46è¡Œæ€§èƒ½å…¨ç¼ºå¤±ï¼‰
```

### 3.5 è´¨é‡éªŒè¯æ£€æŸ¥æ¸…å•

```python
# è¿è¡ŒéªŒè¯è„šæœ¬
conda run -n fairness python3 scripts/verify_stratified_data.py

# éªŒè¯é¡¹ç›®ï¼š
# 1. è¡Œæ•°æ­£ç¡®æ€§
assert len(image_df) + len(reid_df) + len(vul_df) + len(bug_df) == 372

# 2. åˆ—åæ­£ç¡®æ€§
assert set(image_df.columns) == expected_image_columns

# 3. One-Hotäº’æ–¥æ€§
assert (image_df[['is_mnist', 'is_cifar10']].sum(axis=1) == 1).all()

# 4. æ— æ€§èƒ½ç¼ºå¤±
assert not image_df['perf_test_accuracy'].isna().any()

# 5. å¯è®¡ç®—ç›¸å…³çŸ©é˜µ
corr = image_df.drop(['experiment_id', 'timestamp'], axis=1).corr()
assert not corr.isna().any().any()
```

---

## é˜¶æ®µ4ï¼šæ•°æ®è´¨é‡éªŒè¯

### 4.1 ç›®æ ‡

éªŒè¯åˆ†å±‚æ•°æ®æ»¡è¶³DiBSå› æœåˆ†æçš„æ‰€æœ‰å‰ææ¡ä»¶ã€‚

### 4.2 éªŒè¯ç»´åº¦

#### ç»´åº¦1: ç¼ºå¤±å€¼ç»Ÿè®¡

```python
def check_missing_rates():
    """
    æ£€æŸ¥æ¯ä¸ªä»»åŠ¡ç»„çš„ç¼ºå¤±ç‡

    ç›®æ ‡ï¼š
    - è¶…å‚æ•°åˆ—ï¼š0%ç¼ºå¤±
    - èƒ½è€—åˆ—ï¼š0%ç¼ºå¤±
    - æ€§èƒ½åˆ—ï¼š0%ç¼ºå¤±
    - ä¸­ä»‹å˜é‡åˆ—ï¼š<5%ç¼ºå¤±ï¼ˆå¯æ¥å—ï¼‰
    """
    for task in tasks:
        df = load_task_data(task)

        for col in df.columns:
            missing_rate = df[col].isna().sum() / len(df) * 100

            if 'hyperparam' in col or 'training_duration' in col:
                assert missing_rate == 0, f"{task}.{col}: è¶…å‚æ•°ä¸åº”ç¼ºå¤±"

            if 'energy' in col:
                assert missing_rate == 0, f"{task}.{col}: èƒ½è€—ä¸åº”ç¼ºå¤±"

            if 'perf_' in col:
                assert missing_rate == 0, f"{task}.{col}: æ€§èƒ½ä¸åº”ç¼ºå¤±"

            if 'gpu_' in col or 'cpu_' in col:
                assert missing_rate < 5, f"{task}.{col}: ä¸­ä»‹å˜é‡ç¼ºå¤±ç‡åº”<5%"
```

#### ç»´åº¦2: å®Œå…¨æ— ç¼ºå¤±è¡Œæ¯”ä¾‹

```python
def check_complete_rows():
    """
    æ£€æŸ¥å®Œå…¨æ— ç¼ºå¤±è¡Œçš„æ¯”ä¾‹

    ç›®æ ‡ï¼ˆv3.0æ–¹æ¡ˆï¼‰ï¼š
    - å›¾åƒåˆ†ç±»ç»„ï¼š>90%
    - Person_reIDç»„ï¼š>90%
    - VulBERTaç»„ï¼š>80%
    - Bugå®šä½ç»„ï¼š>80%
    """
    for task in tasks:
        df = load_task_data(task)
        complete_rows = df.dropna()
        complete_rate = len(complete_rows) / len(df) * 100

        print(f"{task}: {len(complete_rows)}/{len(df)} ({complete_rate:.1f}% å®Œå…¨æ— ç¼ºå¤±)")
```

#### ç»´åº¦3: ç›¸å…³çŸ©é˜µå¯è®¡ç®—æ€§

```python
def check_correlation_matrix():
    """
    æ£€æŸ¥ç›¸å…³çŸ©é˜µæ˜¯å¦å¯è®¡ç®—

    ç›®æ ‡ï¼š
    - ç›¸å…³çŸ©é˜µæ— nanå€¼
    - ç›¸å…³çŸ©é˜µæœ‰å¯¹è§’çº¿å…¨ä¸º1
    - ç›¸å…³çŸ©é˜µåœ¨[-1, 1]èŒƒå›´å†…
    """
    for task in tasks:
        df = load_task_data(task)

        # ç§»é™¤éæ•°å€¼åˆ—
        numeric_df = df.select_dtypes(include=[np.number])

        # è®¡ç®—ç›¸å…³çŸ©é˜µ
        corr = numeric_df.corr()

        # éªŒè¯
        assert not corr.isna().any().any(), f"{task}: ç›¸å…³çŸ©é˜µåŒ…å«nan"
        assert (np.diag(corr) == 1).all(), f"{task}: å¯¹è§’çº¿åº”ä¸º1"
        assert (corr >= -1).all().all() and (corr <= 1).all().all(), f"{task}: ç›¸å…³ç³»æ•°åº”åœ¨[-1,1]"

        print(f"âœ… {task}: ç›¸å…³çŸ©é˜µå¯è®¡ç®—ï¼Œå½¢çŠ¶={corr.shape}")
```

#### ç»´åº¦4: æ•°å€¼èŒƒå›´åˆç†æ€§

```python
def check_numeric_ranges():
    """
    æ£€æŸ¥æ•°å€¼åˆ—çš„èŒƒå›´æ˜¯å¦åˆç†

    ç›®æ ‡ï¼š
    - èƒ½è€—åˆ—ï¼š>0
    - GPUæ¸©åº¦ï¼š20-110Â°C
    - GPUåŠŸç‡ï¼š0-600W
    - å‡†ç¡®ç‡ï¼š0-1æˆ–0-100
    """
    ranges = {
        'energy_cpu_total_joules': (0, 1e9),
        'energy_gpu_total_joules': (0, 1e9),
        'gpu_temp_max': (20, 110),
        'gpu_power_avg_watts': (0, 600),
        'perf_test_accuracy': (0, 100),
        'perf_map': (0, 1),
    }

    for task in tasks:
        df = load_task_data(task)

        for col, (min_val, max_val) in ranges.items():
            if col in df.columns:
                out_of_range = df[(df[col] < min_val) | (df[col] > max_val)]
                assert len(out_of_range) == 0, f"{task}.{col}: {len(out_of_range)} ä¸ªå€¼è¶…å‡ºèŒƒå›´"
```

#### ç»´åº¦5: One-Hotç¼–ç æ­£ç¡®æ€§

```python
def check_onehot_encoding():
    """
    æ£€æŸ¥One-Hotç¼–ç æ˜¯å¦æ­£ç¡®

    ç›®æ ‡ï¼š
    - æ¯è¡ŒOne-Hotåˆ—çš„å’Œ=1ï¼ˆäº’æ–¥ï¼‰
    - åªåŒ…å«0å’Œ1
    - è¦†ç›–æ‰€æœ‰æ ·æœ¬
    """
    # å›¾åƒåˆ†ç±»
    image_df = load_task_data('image_classification')
    onehot_sum = image_df[['is_mnist', 'is_cifar10']].sum(axis=1)
    assert (onehot_sum == 1).all(), "å›¾åƒåˆ†ç±»: One-Hotå’Œåº”ä¸º1"

    # Person_reID
    reid_df = load_task_data('person_reid')
    onehot_sum = reid_df[['is_densenet121', 'is_hrnet18', 'is_pcb']].sum(axis=1)
    assert (onehot_sum == 1).all(), "Person_reID: One-Hotå’Œåº”ä¸º1"
```

### 4.3 å®ç°è®¡åˆ’

#### æ­¥éª¤1: åˆ›å»ºéªŒè¯è„šæœ¬ (30åˆ†é’Ÿ)

**æ–‡ä»¶**: `analysis/scripts/verify_stratified_data_quality.py`

**åŠŸèƒ½æ¨¡å—**:
1. `check_missing_rates()` - ç¼ºå¤±ç‡æ£€æŸ¥
2. `check_complete_rows()` - å®Œå…¨è¡Œæ£€æŸ¥
3. `check_correlation_matrix()` - ç›¸å…³çŸ©é˜µæ£€æŸ¥
4. `check_numeric_ranges()` - æ•°å€¼èŒƒå›´æ£€æŸ¥
5. `check_onehot_encoding()` - One-Hotæ£€æŸ¥
6. `generate_quality_report()` - ç”Ÿæˆè´¨é‡æŠ¥å‘Š

#### æ­¥éª¤2: è¿è¡ŒéªŒè¯ (5åˆ†é’Ÿ)

```bash
cd analysis/scripts
conda run -n fairness python3 verify_stratified_data_quality.py \
  --data-dir ../data/energy_research/processed/ \
  --output-report ../docs/reports/STRATIFIED_DATA_QUALITY_REPORT.md
```

#### æ­¥éª¤3: è§£è¯»æŠ¥å‘Š

**é¢„æœŸè¾“å‡º**: `STRATIFIED_DATA_QUALITY_REPORT.md`

```markdown
# åˆ†å±‚æ•°æ®è´¨é‡éªŒè¯æŠ¥å‘Š

## éªŒè¯æ‘˜è¦

| ä»»åŠ¡ç»„ | æ ·æœ¬æ•° | åˆ—æ•° | å®Œå…¨æ— ç¼ºå¤±è¡Œ | ç›¸å…³çŸ©é˜µ |
|--------|--------|------|-------------|---------|
| å›¾åƒåˆ†ç±» | 116 | 17 | 105 (90.5%) | âœ… å¯è®¡ç®— |
| Person_reID | 69 | 17 | 63 (91.3%) | âœ… å¯è®¡ç®— |
| VulBERTa | 96 | 14 | 80 (83.3%) | âœ… å¯è®¡ç®— |
| Bugå®šä½ | 91 | 14 | 75 (82.4%) | âœ… å¯è®¡ç®— |

## è¯¦ç»†æ£€æŸ¥ç»“æœ

### âœ… ç¼ºå¤±ç‡æ£€æŸ¥
- è¶…å‚æ•°åˆ—ï¼š0%ç¼ºå¤± âœ…
- èƒ½è€—åˆ—ï¼š0%ç¼ºå¤± âœ…
- æ€§èƒ½åˆ—ï¼š0%ç¼ºå¤± âœ…
- ä¸­ä»‹å˜é‡åˆ—ï¼š<2%ç¼ºå¤± âœ…

### âœ… ç›¸å…³çŸ©é˜µæ£€æŸ¥
- æ‰€æœ‰ä»»åŠ¡ç»„çš„ç›¸å…³çŸ©é˜µå¯è®¡ç®— âœ…
- æ— nanå€¼ âœ…
- æ•°å€¼èŒƒå›´[-1, 1] âœ…

### âœ… One-Hotç¼–ç æ£€æŸ¥
- å›¾åƒåˆ†ç±»ï¼šäº’æ–¥æ€§100% âœ…
- Person_reIDï¼šäº’æ–¥æ€§100% âœ…

### âœ… æ•°å€¼èŒƒå›´æ£€æŸ¥
- èƒ½è€—æŒ‡æ ‡ï¼šèŒƒå›´åˆç† âœ…
- æ¸©åº¦æŒ‡æ ‡ï¼šèŒƒå›´åˆç† âœ…
- æ€§èƒ½æŒ‡æ ‡ï¼šèŒƒå›´åˆç† âœ…

## ç»“è®º

âœ… **æ•°æ®è´¨é‡éªŒè¯é€šè¿‡ï¼Œå¯ä»¥è¿›å…¥é˜¶æ®µ5ï¼ˆDiBSåˆ†æï¼‰**
```

---

## é˜¶æ®µ5ï¼šDiBSå› æœåˆ†æéªŒè¯

### 5.1 ç›®æ ‡

è¿è¡ŒDiBSå› æœå›¾å­¦ä¹ ï¼ŒéªŒè¯æ–°æ•°æ®èƒ½å¤ŸæˆåŠŸå‘ç°å› æœè¾¹ï¼Œå¯¹æ¯”v1.0ï¼ˆAdult, 0è¾¹ï¼‰å’Œv3.0ï¼ˆèƒ½è€—åˆ†å±‚, é¢„æœŸ3-8è¾¹/ä»»åŠ¡ï¼‰çš„æ”¹è¿›ã€‚

### 5.2 åˆ†æé…ç½®

#### DiBSè¶…å‚æ•°

```python
# å‚è€ƒAdultæˆåŠŸç»éªŒ
dibs_config = {
    'n_particles': 20,          # ç²’å­æ•°
    'n_steps': 1000,           # ä¼˜åŒ–æ­¥æ•°
    'optimizer': 'adam',        # ä¼˜åŒ–å™¨
    'learning_rate': 0.005,     # å­¦ä¹ ç‡
    'temperature': 1.0,         # æ¸©åº¦å‚æ•°
    'alpha_linear': 0.05,       # DAGæ­£åˆ™åŒ–
    'verbose': True             # æ‰“å°è¿›åº¦
}
```

#### è¿è¡Œæ¨¡å¼

```python
# æ¨¡å¼1: ä¸²è¡Œè¿è¡Œï¼ˆç¨³å®šï¼Œé€‚åˆè°ƒè¯•ï¼‰
for task in tasks:
    run_dibs_analysis(task, dibs_config)

# æ¨¡å¼2: å¹¶è¡Œè¿è¡Œï¼ˆå¿«é€Ÿï¼Œé€‚åˆç”Ÿäº§ï¼‰
from multiprocessing import Pool
with Pool(4) as p:
    p.map(run_dibs_task, [(task, dibs_config) for task in tasks])
```

### 5.3 å®ç°è®¡åˆ’

#### æ­¥éª¤1: åˆ›å»ºåˆ†æè„šæœ¬ (40åˆ†é’Ÿ)

**æ–‡ä»¶**: `analysis/scripts/run_stratified_dibs_analysis.py`

**åŠŸèƒ½æ¨¡å—**:
1. `load_task_data()` - åŠ è½½ä»»åŠ¡æ•°æ®
2. `prepare_dibs_input()` - å‡†å¤‡DiBSè¾“å…¥çŸ©é˜µ
3. `run_dibs()` - è¿è¡ŒDiBSä¼˜åŒ–
4. `extract_causal_edges()` - æå–å› æœè¾¹
5. `save_results()` - ä¿å­˜ç»“æœ
6. `generate_analysis_report()` - ç”Ÿæˆåˆ†ææŠ¥å‘Š

**æ ¸å¿ƒé€»è¾‘**:

```python
def run_stratified_dibs_analysis(task_name, config):
    """
    è¿è¡Œå•ä¸ªä»»åŠ¡ç»„çš„DiBSåˆ†æ

    æ­¥éª¤ï¼š
    1. åŠ è½½æ•°æ®å¹¶åˆ é™¤æ ‡è¯†åˆ—
    2. æ ‡å‡†åŒ–æ•°å€¼åˆ—
    3. è¿è¡ŒDiBSå­¦ä¹ å› æœå›¾
    4. ç­›é€‰é«˜ç½®ä¿¡åº¦å› æœè¾¹ï¼ˆposterior > 0.5ï¼‰
    5. ä¿å­˜ç»“æœ
    """

    # 1. åŠ è½½æ•°æ®
    df = pd.read_csv(f'data/energy_research/processed/training_data_{task_name}.csv')

    # 2. ç§»é™¤æ ‡è¯†åˆ—
    df = df.drop(['experiment_id', 'timestamp'], axis=1)

    # 3. æ ‡å‡†åŒ–
    from sklearn.preprocessing import StandardScaler
    scaler = StandardScaler()
    X = scaler.fit_transform(df)

    # 4. è¿è¡ŒDiBS
    from utils.causal_discovery import run_dibs
    result = run_dibs(
        data=X,
        variable_names=list(df.columns),
        n_particles=config['n_particles'],
        n_steps=config['n_steps'],
        verbose=config['verbose']
    )

    # 5. æå–å› æœè¾¹
    adjacency_matrix = result['adjacency_matrix']
    edges = []
    n_vars = len(df.columns)
    for i in range(n_vars):
        for j in range(n_vars):
            posterior = adjacency_matrix[i, j]
            if posterior > 0.5:  # é«˜ç½®ä¿¡åº¦é˜ˆå€¼
                edges.append({
                    'source': df.columns[i],
                    'target': df.columns[j],
                    'posterior': posterior
                })

    # 6. ä¿å­˜ç»“æœ
    output_dir = f'results/energy_research/task_specific/{task_name}/'
    os.makedirs(output_dir, exist_ok=True)

    # ä¿å­˜å› æœå›¾
    np.save(f'{output_dir}/causal_graph.npy', adjacency_matrix)

    # ä¿å­˜å› æœè¾¹
    import pickle
    with open(f'{output_dir}/causal_edges.pkl', 'wb') as f:
        pickle.dump(edges, f)

    print(f"âœ… {task_name}: å‘ç° {len(edges)} æ¡å› æœè¾¹")

    return edges
```

#### æ­¥éª¤2: åˆ›å»ºæµ‹è¯•è„šæœ¬ (20åˆ†é’Ÿ)

**æ–‡ä»¶**: `analysis/scripts/test_stratified_dibs.py`

**æµ‹è¯•ç”¨ä¾‹**:
1. `test_data_loading()` - æµ‹è¯•æ•°æ®åŠ è½½
2. `test_standardization()` - æµ‹è¯•æ ‡å‡†åŒ–
3. `test_dibs_dry_run()` - Dry run with å°‘é‡æ­¥æ•°
4. `test_edge_extraction()` - æµ‹è¯•è¾¹æå–é€»è¾‘
5. `test_result_saving()` - æµ‹è¯•ç»“æœä¿å­˜

**Dry Runé…ç½®**:
```python
dry_run_config = {
    'n_particles': 5,      # å°‘é‡ç²’å­
    'n_steps': 10,         # å°‘é‡æ­¥æ•°
    'verbose': True
}
```

#### æ­¥éª¤3: Dry RunéªŒè¯ (15åˆ†é’Ÿ)

```bash
# æµ‹è¯•å•ä¸ªä»»åŠ¡ç»„ï¼ˆå›¾åƒåˆ†ç±»ï¼Œ116æ ·æœ¬ï¼‰
cd analysis/scripts
conda run -n fairness python3 run_stratified_dibs_analysis.py \
  --task image_classification \
  --n-particles 5 \
  --n-steps 10 \
  --dry-run

# æ£€æŸ¥æ˜¯å¦èƒ½æˆåŠŸå®Œæˆ
# é¢„æœŸï¼šæ— æŠ¥é”™ï¼Œç”Ÿæˆmockç»“æœæ–‡ä»¶
```

**éªŒè¯æ ‡å‡†**:
- âœ… DiBSä¼˜åŒ–æ— æŠ¥é”™
- âœ… ç”Ÿæˆadjacency_matrix
- âœ… å¯ä»¥æå–å› æœè¾¹
- âœ… ç»“æœæ–‡ä»¶å¯ä¿å­˜

#### æ­¥éª¤4: å…¨é‡æ‰§è¡Œ (60åˆ†é’Ÿï¼Œå¯å¹¶è¡Œ)

```bash
# æ–¹å¼1: ä¸²è¡Œè¿è¡Œï¼ˆç¨³å®šï¼‰
cd analysis/scripts
nohup bash run_all_stratified_dibs.sh > ../logs/energy_research/stratified_dibs_20251224.log 2>&1 &

# æ–¹å¼2: å¹¶è¡Œè¿è¡Œï¼ˆå¿«é€Ÿï¼‰
conda run -n fairness python3 run_stratified_dibs_analysis.py --all-tasks --parallel

# ç›‘æ§è¿›åº¦
tail -f ../logs/energy_research/stratified_dibs_20251224.log
```

**é¢„æœŸè¿è¡Œæ—¶é—´**:
- å›¾åƒåˆ†ç±» (116æ ·æœ¬, 17åˆ—): ~15åˆ†é’Ÿ
- Person_reID (69æ ·æœ¬, 17åˆ—): ~10åˆ†é’Ÿ
- VulBERTa (96æ ·æœ¬, 14åˆ—): ~20åˆ†é’Ÿ
- Bugå®šä½ (91æ ·æœ¬, 14åˆ—): ~15åˆ†é’Ÿ

**æ€»è®¡**: çº¦60åˆ†é’Ÿï¼ˆä¸²è¡Œï¼‰ï¼Œçº¦20åˆ†é’Ÿï¼ˆå¹¶è¡Œï¼‰

### 5.4 ç»“æœåˆ†æ

#### é¢„æœŸç»“æœï¼ˆåŸºäºv3.0æ–¹æ¡ˆï¼‰

| ä»»åŠ¡ç»„ | æ ·æœ¬æ•° | å˜é‡æ•° | é¢„æœŸå› æœè¾¹æ•° | å…³é”®å› æœè·¯å¾„ |
|--------|--------|--------|------------|------------|
| å›¾åƒåˆ†ç±» | 116 | 17 | 3-8æ¡ | learning_rate â†’ energy, training_duration â†’ accuracy |
| Person_reID | 69 | 17 | 3-6æ¡ | dropout â†’ mAP, learning_rate â†’ energy |
| VulBERTa | 96 | 14 | 2-5æ¡ | learning_rate â†’ eval_loss, weight_decay â†’ energy |
| Bugå®šä½ | 91 | 14 | 2-5æ¡ | kfold â†’ top1_accuracy, max_iter â†’ energy |

#### å¯¹æ¯”v1.0æ”¹è¿›

| ç»´åº¦ | v1.0 (Adult) | v3.0 (èƒ½è€—åˆ†å±‚) | æ”¹è¿› |
|------|-------------|----------------|------|
| **æ ·æœ¬é‡** | 10ä¸ª | 69-116ä¸ª/ä»»åŠ¡ | **7-11å€** |
| **å˜é‡æ•°** | 15ä¸ª | 14-17ä¸ª/ä»»åŠ¡ | ä¼˜åŒ–é€‰æ‹© |
| **å› æœè¾¹æ•°** | **0æ¡** | é¢„æœŸ3-8æ¡/ä»»åŠ¡ | **è´¨çš„é£è·ƒ** |
| **ç›¸å…³çŸ©é˜µ** | åŒ…å«nanï¼ˆå¤±è´¥ï¼‰ | å®Œå…¨å¯è®¡ç®— | âœ… |
| **One-Hotç¼–ç ** | æ—  | æœ‰ï¼ˆæ§åˆ¶å¼‚è´¨æ€§ï¼‰ | âœ… |
| **æ•°æ®è´¨é‡** | 32-100%ç¼ºå¤± | <2%ç¼ºå¤± | âœ… |

#### ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š

**æ–‡ä»¶**: `analysis/docs/reports/DIBS_V1_VS_V3_COMPARISON_REPORT.md`

```markdown
# DiBS v1.0 vs v3.0 å¯¹æ¯”æŠ¥å‘Š

## æ‰§è¡Œæ‘˜è¦

v3.0æ–¹æ¡ˆé€šè¿‡æ•°æ®é‡æå–ã€åˆ†å±‚åˆ†æã€One-Hotç¼–ç ï¼ŒæˆåŠŸè§£å†³v1.0çš„0å› æœè¾¹é—®é¢˜ã€‚

## å…³é”®æ”¹è¿›

### 1. æ•°æ®è´¨é‡æå‡ â­â­â­
- v1.0: è¶…å‚æ•°32-100%ç¼ºå¤± â†’ DiBSè®¡ç®—å¤±è´¥
- v3.0: è¶…å‚æ•°100%å¡«å…… â†’ DiBSå¯è®¡ç®—

### 2. æ ·æœ¬é‡å¢åŠ  â­â­â­
- v1.0: 10ä¸ªé…ç½® â†’ ç»Ÿè®¡åŠŸæ•ˆä¸è¶³
- v3.0: 69-116ä¸ª/ä»»åŠ¡ â†’ ç»Ÿè®¡åŠŸæ•ˆå……è¶³

### 3. å¼‚è´¨æ€§æ§åˆ¶ â­â­
- v1.0: æ··åˆä¸åŒæ¨¡å‹/æ•°æ®é›† â†’ DiBSæ··æ·†åŸºçº¿å·®å¼‚
- v3.0: One-Hotç¼–ç  â†’ DiBSåŒºåˆ†çœŸå®å› æœå…³ç³»

### 4. ä»»åŠ¡ç‰¹å®šä¼˜åŒ– â­â­
- v1.0: å…¨å±€åˆ†æ â†’ ä¸¢å¤±ä»»åŠ¡ç‰¹å®šæ¨¡å¼
- v3.0: åˆ†å±‚åˆ†æ â†’ å‘ç°ä»»åŠ¡ç‰¹å®šå› æœè·¯å¾„

## å› æœå‘ç°ç»“æœ

[è¯¦ç»†åˆ—å‡ºæ¯ä¸ªä»»åŠ¡ç»„å‘ç°çš„å› æœè¾¹]

## ç»“è®º

v3.0æ–¹æ¡ˆæˆåŠŸå®ç°èƒ½è€—æ•°æ®çš„å› æœåˆ†æï¼Œä¸ºè¶…å‚æ•°ä¼˜åŒ–æä¾›å› æœæŒ‡å¯¼ã€‚
```

### 5.5 åç»­DMLåˆ†æï¼ˆå¯é€‰ï¼‰

å¦‚æœDiBSæˆåŠŸå‘ç°å› æœè¾¹ï¼Œå¯ä»¥ç»§ç»­è¿è¡ŒDMLä¼°è®¡å› æœæ•ˆåº”ï¼š

```bash
# è¿è¡ŒDMLå› æœæ¨æ–­
cd analysis/scripts
conda run -n fairness python3 run_stratified_dml_analysis.py \
  --task image_classification \
  --causal-graph results/energy_research/task_specific/image_classification/causal_graph.npy
```

**DMLè¾“å‡º**: æ¯æ¡å› æœè¾¹çš„ATEï¼ˆå¹³å‡å› æœæ•ˆåº”ï¼‰ã€ç½®ä¿¡åŒºé—´ã€på€¼

---

## æ—¶é—´ä¼°ç®—ä¸è¿›åº¦è·Ÿè¸ª

### æ€»æ—¶é—´ä¼°ç®—

| é˜¶æ®µ | å­ä»»åŠ¡ | é¢„ä¼°æ—¶é—´ | ä¼˜å…ˆçº§ |
|------|--------|---------|--------|
| **é˜¶æ®µ3** | åˆ›å»ºé¢„å¤„ç†è„šæœ¬ | 40åˆ†é’Ÿ | ğŸ”´ P0 |
| | åˆ›å»ºæµ‹è¯•è„šæœ¬ | 20åˆ†é’Ÿ | ğŸ”´ P0 |
| | Dry RunéªŒè¯ | 10åˆ†é’Ÿ | ğŸ”´ P0 |
| | å…¨é‡æ‰§è¡Œ | 5åˆ†é’Ÿ | ğŸ”´ P0 |
| **é˜¶æ®µ4** | åˆ›å»ºéªŒè¯è„šæœ¬ | 30åˆ†é’Ÿ | ğŸŸ  P1 |
| | è¿è¡ŒéªŒè¯ | 5åˆ†é’Ÿ | ğŸŸ  P1 |
| | è§£è¯»æŠ¥å‘Š | 10åˆ†é’Ÿ | ğŸŸ  P1 |
| **é˜¶æ®µ5** | åˆ›å»ºåˆ†æè„šæœ¬ | 40åˆ†é’Ÿ | ğŸŸ¡ P2 |
| | åˆ›å»ºæµ‹è¯•è„šæœ¬ | 20åˆ†é’Ÿ | ğŸŸ¡ P2 |
| | Dry RunéªŒè¯ | 15åˆ†é’Ÿ | ğŸŸ¡ P2 |
| | å…¨é‡æ‰§è¡Œ | 60åˆ†é’Ÿ | ğŸŸ¡ P2 |
| | ç»“æœåˆ†æ | 30åˆ†é’Ÿ | ğŸŸ¡ P2 |

**æ€»è®¡**: çº¦4.5-5å°æ—¶ï¼ˆå«Dry Runå’Œæµ‹è¯•ï¼‰

### è¿›åº¦è·Ÿè¸ªæ¸…å•

```markdown
- [ ] é˜¶æ®µ3.1: preprocess_stratified_data.py
- [ ] é˜¶æ®µ3.2: test_preprocess_stratified_data.py
- [ ] é˜¶æ®µ3.3: Dry Runé€šè¿‡
- [ ] é˜¶æ®µ3.4: ç”Ÿæˆ4ä¸ªåˆ†å±‚æ–‡ä»¶
- [ ] é˜¶æ®µ4.1: verify_stratified_data_quality.py
- [ ] é˜¶æ®µ4.2: ç”Ÿæˆè´¨é‡æŠ¥å‘Š
- [ ] é˜¶æ®µ4.3: æ‰€æœ‰éªŒè¯é€šè¿‡
- [ ] é˜¶æ®µ5.1: run_stratified_dibs_analysis.py
- [ ] é˜¶æ®µ5.2: test_stratified_dibs.py
- [ ] é˜¶æ®µ5.3: Dry Runé€šè¿‡
- [ ] é˜¶æ®µ5.4: å…¨é‡æ‰§è¡Œå®Œæˆ
- [ ] é˜¶æ®µ5.5: ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š
```

---

## é£é™©ä¸åº”å¯¹

### é£é™©1: DiBSä¼˜åŒ–è¶…æ—¶

**ç—‡çŠ¶**: DiBSè¿è¡Œ>30åˆ†é’Ÿæ— è¿›å±•

**åŸå› **: æ ·æœ¬é‡å¤§æˆ–å˜é‡æ•°å¤š

**åº”å¯¹**:
1. å‡å°‘n_particles (20 â†’ 10)
2. å‡å°‘n_steps (1000 â†’ 500)
3. ç§»é™¤ä½æ–¹å·®å˜é‡ï¼ˆå¦‚seedï¼‰

### é£é™©2: ä»ç„¶å‘ç°0å› æœè¾¹

**ç—‡çŠ¶**: DiBSå®Œæˆä½†posteriorå…¨éƒ¨<0.5

**åŸå› **:
- æ•°æ®çº¿æ€§å…³ç³»å¼±
- å˜é‡é€‰æ‹©ä¸å½“
- æ ·æœ¬é‡ä»ä¸è¶³

**åº”å¯¹**:
1. æ£€æŸ¥ç›¸å…³çŸ©é˜µï¼ˆæ˜¯å¦æœ‰æ˜¾è‘—ç›¸å…³ï¼‰
2. å°è¯•é™ä½posterioré˜ˆå€¼ï¼ˆ0.5 â†’ 0.3ï¼‰
3. å¢åŠ æ ·æœ¬é‡ï¼ˆåˆå¹¶å¹¶è¡Œ/éå¹¶è¡Œæ•°æ®ï¼‰

### é£é™©3: One-Hotç¼–ç å¯¼è‡´å…±çº¿æ€§

**ç—‡çŠ¶**: ç›¸å…³çŸ©é˜µå‡ºç°nanæˆ–æ¥è¿‘1çš„ç›¸å…³

**åŸå› **: One-Hotåˆ—å®Œå…¨çº¿æ€§ç›¸å…³

**åº”å¯¹**:
1. ç§»é™¤ä¸€ä¸ªOne-Hotåˆ—ï¼ˆn-1ç¼–ç ï¼‰
2. æ£€æŸ¥VIFï¼ˆæ–¹å·®è†¨èƒ€å› å­ï¼‰
3. ä½¿ç”¨PCAé™ç»´

### é£é™©4: å†…å­˜ä¸è¶³

**ç—‡çŠ¶**: DiBSè¿è¡Œæ—¶OOM

**åŸå› **: å¤§æ ·æœ¬é‡ Ã— é«˜å˜é‡æ•°

**åº”å¯¹**:
1. å‡å°‘n_particles
2. ä½¿ç”¨GPUåŠ é€Ÿï¼ˆå¦‚å¯ç”¨ï¼‰
3. åˆ†æ‰¹å¤„ç†

---

## é™„å½•ï¼šå…³é”®ä»£ç ç¤ºä¾‹

### A. One-Hotç¼–ç å®ç°

```python
def create_onehot_image_classification(row):
    """
    å›¾åƒåˆ†ç±»One-Hotç¼–ç 

    è§„åˆ™ï¼š
    - MNISTç³»åˆ— (mnist, mnist_ff, mnist_rnn, siamese) â†’ is_mnist=1
    - CIFAR-10 (resnet20) â†’ is_cifar10=1
    """
    is_mnist = 1 if 'mnist' in row['model'] or row['model'] == 'siamese' else 0
    is_cifar10 = 1 if row['repository'] == 'pytorch_resnet_cifar10' else 0

    return pd.Series({'is_mnist': is_mnist, 'is_cifar10': is_cifar10})

def create_onehot_person_reid(row):
    """
    Person_reID One-Hotç¼–ç 

    è§„åˆ™ï¼š
    - densenet121 â†’ is_densenet121=1
    - hrnet18 â†’ is_hrnet18=1
    - pcb â†’ is_pcb=1
    """
    return pd.Series({
        'is_densenet121': 1 if row['model'] == 'densenet121' else 0,
        'is_hrnet18': 1 if row['model'] == 'hrnet18' else 0,
        'is_pcb': 1 if row['model'] == 'pcb' else 0
    })
```

### B. ç›¸å…³çŸ©é˜µå¯è§†åŒ–

```python
import seaborn as sns
import matplotlib.pyplot as plt

def visualize_correlation_matrix(task_name):
    """ç”Ÿæˆç›¸å…³çŸ©é˜µçƒ­åŠ›å›¾"""
    df = pd.read_csv(f'data/energy_research/processed/training_data_{task_name}.csv')

    # ç§»é™¤æ ‡è¯†åˆ—
    numeric_df = df.select_dtypes(include=[np.number])

    # è®¡ç®—ç›¸å…³çŸ©é˜µ
    corr = numeric_df.corr()

    # ç»˜å›¾
    plt.figure(figsize=(12, 10))
    sns.heatmap(corr, annot=False, cmap='coolwarm', center=0,
                square=True, linewidths=0.5)
    plt.title(f'Correlation Matrix - {task_name}')
    plt.tight_layout()
    plt.savefig(f'results/energy_research/task_specific/{task_name}/correlation_matrix.png', dpi=300)
    plt.close()
```

### C. DiBSç»“æœå¯è§†åŒ–

```python
import networkx as nx

def visualize_causal_graph(task_name, threshold=0.5):
    """ç”Ÿæˆå› æœå›¾å¯è§†åŒ–"""
    # åŠ è½½é‚»æ¥çŸ©é˜µ
    adj_matrix = np.load(f'results/energy_research/task_specific/{task_name}/causal_graph.npy')

    # åŠ è½½å˜é‡å
    df = pd.read_csv(f'data/energy_research/processed/training_data_{task_name}.csv')
    var_names = [c for c in df.columns if c not in ['experiment_id', 'timestamp']]

    # åˆ›å»ºæœ‰å‘å›¾
    G = nx.DiGraph()

    for i, source in enumerate(var_names):
        for j, target in enumerate(var_names):
            posterior = adj_matrix[i, j]
            if posterior > threshold:
                G.add_edge(source, target, weight=posterior)

    # ç»˜å›¾
    plt.figure(figsize=(15, 12))
    pos = nx.spring_layout(G, k=2, iterations=50)

    # èŠ‚ç‚¹åˆ†ç»„ç€è‰²
    node_colors = []
    for node in G.nodes():
        if 'hyperparam' in node or node in ['training_duration', 'l2_regularization', 'seed']:
            node_colors.append('lightblue')  # è¶…å‚æ•°
        elif 'energy' in node or 'power' in node:
            node_colors.append('lightcoral')  # èƒ½è€—
        elif 'perf_' in node:
            node_colors.append('lightgreen')  # æ€§èƒ½
        else:
            node_colors.append('lightyellow')  # ä¸­ä»‹å˜é‡

    nx.draw(G, pos, node_color=node_colors, with_labels=True,
            node_size=2000, font_size=8, arrows=True, arrowsize=15)

    plt.title(f'Causal Graph - {task_name} (threshold={threshold})')
    plt.tight_layout()
    plt.savefig(f'results/energy_research/task_specific/{task_name}/causal_graph.png', dpi=300)
    plt.close()
```

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0
**åˆ›å»ºæ—¶é—´**: 2025-12-24
**é¢„ä¼°å®Œæˆæ—¶é—´**: 4.5-5å°æ—¶ï¼ˆå«æµ‹è¯•å’ŒDry Runï¼‰
**ä¸‹ä¸€æ­¥**: ç­‰å¾…ç”¨æˆ·ç¡®è®¤åæ‰§è¡Œé˜¶æ®µ3

# æ­£ç¡®çš„6åˆ†ç»„æ•°æ®è®¾è®¡æ–¹æ¡ˆ

**æ—¥æœŸ**: 2026-01-15
**æ•°æ®æº**: data.csv (970è¡Œï¼Œ818æ¡å¯ç”¨æ•°æ®)
**è®¾è®¡åŸåˆ™**: å°†å…±ç”¨è¶…å‚æ•°å’Œæ€§èƒ½æŒ‡æ ‡çš„æ¨¡å‹åˆ†ä¸ºä¸€ç»„ï¼Œä¿ç•™æ‰€æœ‰å¯ç”¨æ•°æ®

---

## ğŸ“‹ åˆ†ç»„è®¾è®¡

åŸºäºæ•°æ®åˆ†æï¼ŒæŒ‰ç…§å…±ç”¨ç‰¹å¾å°†æ¨¡å‹åˆ†ä¸ºä»¥ä¸‹6ç»„ï¼š

### Group 1: å›¾åƒåˆ†ç±»-å°å‹æ¨¡å‹ç»„ (examples)
**æ¨¡å‹**: mnist, mnist_ff, mnist_rnn, siamese
**æ ·æœ¬æ•°**: 304è¡Œ
**å…±åŒç‰¹å¾**:
- è¶…å‚æ•°: `hyperparam_batch_size`, `hyperparam_epochs`, `hyperparam_learning_rate`, `hyperparam_seed`
- æ€§èƒ½æŒ‡æ ‡: `perf_test_accuracy`, `perf_test_loss`(éƒ¨åˆ†)
- ç‰¹ç‚¹: å°å‹å›¾åƒåˆ†ç±»æ¨¡å‹ï¼Œå…±äº«batch_sizeå‚æ•°

### Group 2: ä»£ç æ¼æ´æ£€æµ‹ç»„ (VulBERTa)
**æ¨¡å‹**: mlp
**æ ·æœ¬æ•°**: 72è¡Œ
**å…±åŒç‰¹å¾**:
- è¶…å‚æ•°: `hyperparam_epochs`, `hyperparam_learning_rate`, `hyperparam_seed`, `hyperparam_weight_decay`
- æ€§èƒ½æŒ‡æ ‡: `perf_eval_loss`, `perf_final_training_loss`, `perf_eval_samples_per_second`
- ç‰¹ç‚¹: NLPä»»åŠ¡ï¼Œç‹¬ç‰¹çš„æ€§èƒ½è¯„ä¼°æŒ‡æ ‡

### Group 3: è¡Œäººé‡è¯†åˆ«ç»„ (Person_reID)
**æ¨¡å‹**: densenet121, hrnet18, pcb
**æ ·æœ¬æ•°**: 206è¡Œ
**å…±åŒç‰¹å¾**:
- è¶…å‚æ•°: `hyperparam_dropout`, `hyperparam_epochs`, `hyperparam_learning_rate`, `hyperparam_seed`
- æ€§èƒ½æŒ‡æ ‡: `perf_map`, `perf_rank1`, `perf_rank5`
- ç‰¹ç‚¹: æ£€ç´¢ä»»åŠ¡ï¼Œä½¿ç”¨dropoutï¼Œå¤šä¸ªæ’åºæ€§èƒ½æŒ‡æ ‡

### Group 4: ç¼ºé™·å®šä½ç»„ (bug-localization)
**æ¨¡å‹**: default
**æ ·æœ¬æ•°**: 90è¡Œ
**å…±åŒç‰¹å¾**:
- è¶…å‚æ•°: `hyperparam_alpha`, `hyperparam_kfold`, `hyperparam_max_iter`, `hyperparam_seed`
- æ€§èƒ½æŒ‡æ ‡: `perf_top1_accuracy`, `perf_top5_accuracy`, `perf_top10_accuracy`, `perf_top20_accuracy`
- ç‰¹ç‚¹: ä½¿ç”¨scikit-learnï¼Œç‹¬ç‰¹çš„è¶…å‚æ•°é›†(alpha, kfold)

### Group 5: å¤šç›®æ ‡ä¼˜åŒ–ç»„ (MRT-OAST)
**æ¨¡å‹**: default
**æ ·æœ¬æ•°**: 72è¡Œ
**å…±åŒç‰¹å¾**:
- è¶…å‚æ•°: `hyperparam_dropout`, `hyperparam_epochs`, `hyperparam_learning_rate`, `hyperparam_seed`, `hyperparam_weight_decay`
- æ€§èƒ½æŒ‡æ ‡: `perf_accuracy`, `perf_precision`, `perf_recall`
- ç‰¹ç‚¹: å¤šç›®æ ‡æ€§èƒ½æŒ‡æ ‡ï¼ŒåŒæ—¶ä½¿ç”¨dropoutå’Œweight_decay

### Group 6: å›¾åƒåˆ†ç±»-ResNetç»„ (pytorch_resnet_cifar10)
**æ¨¡å‹**: resnet20
**æ ·æœ¬æ•°**: 74è¡Œ
**å…±åŒç‰¹å¾**:
- è¶…å‚æ•°: `hyperparam_epochs`, `hyperparam_learning_rate`, `hyperparam_seed`, `hyperparam_weight_decay`
- æ€§èƒ½æŒ‡æ ‡: `perf_best_val_accuracy`, `perf_test_accuracy`
- ç‰¹ç‚¹: å¤§å‹æ¨¡å‹ï¼Œä½¿ç”¨weight_decayæ­£åˆ™åŒ–

---

## ğŸ“Š æ•°æ®ä¿ç•™é¢„æœŸ

| ç»„åˆ« | æ¨¡å‹æ•° | åŸå§‹å¯ç”¨æ•°æ® | é¢„æœŸä¿ç•™ | ä¿ç•™ç‡ |
|------|--------|-------------|----------|--------|
| Group 1 | 4 | 304 | 304 | 100% |
| Group 2 | 1 | 72 | 72 | 100% |
| Group 3 | 3 | 206 | 206 | 100% |
| Group 4 | 1 | 90 | 90 | 100% |
| Group 5 | 1 | 72 | 72 | 100% |
| Group 6 | 1 | 74 | 74 | 100% |
| **æ€»è®¡** | 11 | 818 | 818 | 100% |

**å…³é”®ä¼˜åŠ¿**: ä¿ç•™æ‰€æœ‰818æ¡å¯ç”¨æ•°æ®ï¼Œæ— æ•°æ®æŸå¤±ï¼

---

## ğŸ› ï¸ å®ç°æ–¹æ¡ˆ

### 1. æ•°æ®ç”Ÿæˆè„šæœ¬ç»“æ„

```python
def generate_6groups_data(input_file='data/data.csv', output_dir='analysis/data/energy_research/dibs_6groups'):
    """
    ç”Ÿæˆ6ç»„DiBSåˆ†ææ•°æ®
    æ ¸å¿ƒåŸåˆ™ï¼šä¿ç•™æ‰€æœ‰å¯ç”¨æ•°æ®ï¼Œåªé€‰æ‹©æ¯ç»„å®é™…ä½¿ç”¨çš„åˆ—
    """

    # å®šä¹‰6ç»„é…ç½®
    GROUP_CONFIGS = {
        'group1_image_classification_small': {
            'name': 'å›¾åƒåˆ†ç±»-å°å‹æ¨¡å‹ç»„',
            'repos': ['examples'],
            'models': ['mnist', 'mnist_ff', 'mnist_rnn', 'siamese'],
            'hyperparams': ['hyperparam_batch_size', 'hyperparam_epochs',
                          'hyperparam_learning_rate', 'hyperparam_seed'],
            'performance': ['perf_test_accuracy', 'perf_test_loss']
        },
        'group2_vulberta': {
            'name': 'ä»£ç æ¼æ´æ£€æµ‹ç»„',
            'repos': ['VulBERTa'],
            'models': ['mlp'],
            'hyperparams': ['hyperparam_epochs', 'hyperparam_learning_rate',
                          'hyperparam_seed', 'hyperparam_weight_decay'],
            'performance': ['perf_eval_loss', 'perf_final_training_loss',
                          'perf_eval_samples_per_second']
        },
        # ... å…¶ä»–4ç»„
    }

    # è¯»å–æ•°æ®
    df = pd.read_csv(input_file)

    # ç­›é€‰å¯ç”¨æ•°æ®
    df_usable = df[
        (df['training_success'] == True) &
        (~df[[col for col in df.columns if col.startswith('energy_')]].isnull().all(axis=1)) &
        (~df[[col for col in df.columns if col.startswith('perf_')]].isnull().all(axis=1))
    ]

    results = {}
    for group_id, config in GROUP_CONFIGS.items():
        # ç­›é€‰è¯¥ç»„çš„æ•°æ®
        group_mask = (
            df_usable['repository'].isin(config['repos']) &
            df_usable['model'].isin(config['models'])
        )
        group_df = df_usable[group_mask].copy()

        # é€‰æ‹©è¯¥ç»„éœ€è¦çš„åˆ—
        meta_cols = ['experiment_id', 'timestamp', 'repository', 'model']
        energy_cols = [col for col in df.columns if col.startswith('energy_')]
        control_cols = ['duration_seconds', 'is_parallel', 'num_mutated_params']

        # åªé€‰æ‹©è¯¥ç»„å®é™…ä½¿ç”¨çš„è¶…å‚æ•°å’Œæ€§èƒ½æŒ‡æ ‡
        selected_cols = (meta_cols + energy_cols + control_cols +
                        config['hyperparams'] + config['performance'])

        # ç¡®ä¿æ‰€æœ‰åˆ—éƒ½å­˜åœ¨
        selected_cols = [col for col in selected_cols if col in group_df.columns]

        # ç”Ÿæˆè¯¥ç»„æ•°æ®
        group_data = group_df[selected_cols]

        # åªåˆ é™¤åœ¨é€‰å®šåˆ—ä¸­å…¨ä¸ºç©ºçš„è¡Œ
        group_data_clean = group_data.dropna(how='all', subset=config['hyperparams'] + config['performance'])

        results[group_id] = group_data_clean

    return results
```

### 2. å…³é”®å®ç°ç‚¹

1. **ä¸è®¾ç½®ç¼ºå¤±ç‡é˜ˆå€¼** - ä¿ç•™æ‰€æœ‰éå…¨ç©ºçš„æ•°æ®
2. **æŒ‰ç»„é€‰æ‹©åˆ—** - æ¯ç»„åªåŒ…å«è¯¥ç»„å®é™…ä½¿ç”¨çš„ç‰¹å¾
3. **ä¿ç•™éƒ¨åˆ†ç¼ºå¤±æ•°æ®** - åªè¦æœ‰éƒ¨åˆ†ç‰¹å¾éç©ºå°±ä¿ç•™
4. **ç»Ÿä¸€å¤„ç†èƒ½è€—å’Œæ§åˆ¶å˜é‡** - æ‰€æœ‰ç»„éƒ½åŒ…å«è¿™äº›é€šç”¨ç‰¹å¾

### 3. æ•°æ®éªŒè¯

```python
def validate_group_data(group_data, group_name):
    """éªŒè¯ç»„æ•°æ®è´¨é‡"""
    print(f"\n{group_name}:")
    print(f"  æ ·æœ¬æ•°: {len(group_data)}")
    print(f"  ç‰¹å¾æ•°: {len(group_data.columns)}")

    # æ£€æŸ¥å…³é”®åˆ—çš„å®Œæ•´æ€§
    for col in group_data.columns:
        if col.startswith('hyperparam_') or col.startswith('perf_'):
            non_null = group_data[col].notna().sum()
            print(f"  {col}: {non_null}/{len(group_data)} ({non_null/len(group_data)*100:.1f}%)")
```

---

## ğŸ“ˆ é¢„æœŸæˆæœ

1. **æ•°æ®ä¿ç•™ç‡**: 100% (818/818æ¡)
2. **æ¯ç»„æ•°æ®è´¨é‡**: ç»„å†…ç‰¹å¾é«˜åº¦ä¸€è‡´ï¼Œé€‚åˆDiBSåˆ†æ
3. **ç‰¹å¾æ¸…æ™°åº¦**: æ¯ç»„åªåŒ…å«ç›¸å…³ç‰¹å¾ï¼Œé¿å…å™ªå£°
4. **å¯è§£é‡Šæ€§**: åˆ†ç»„é€»è¾‘æ¸…æ™°ï¼Œä¾¿äºè§£é‡Šå› æœå…³ç³»

---

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **ä¸è¦ä½¿ç”¨ç¼ºå¤±ç‡é˜ˆå€¼** - è¿™æ˜¯ä¹‹å‰çš„é”™è¯¯ç†è§£
2. **ä¿ç•™æ‰€æœ‰å¯ç”¨æ•°æ®** - å³ä½¿æŸäº›ç‰¹å¾æœ‰ç¼ºå¤±
3. **æŒ‰å®é™…ä½¿ç”¨åˆ†ç»„** - åŸºäºæ¨¡å‹å®é™…ä½¿ç”¨çš„ç‰¹å¾ï¼Œè€Œä¸æ˜¯ç†è®ºè®¾è®¡
4. **éªŒè¯æ•°æ®å®Œæ•´æ€§** - ç¡®ä¿æ²¡æœ‰æ„å¤–ä¸¢å¤±æ•°æ®

---

**è®¾è®¡è€…**: Claude
**åˆ›å»ºæ—¥æœŸ**: 2026-01-15
**çŠ¶æ€**: å¾…è¯„å®¡å’Œå®æ–½
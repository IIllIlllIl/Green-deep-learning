# 6组DiBS训练数据性能指标缺失分析报告

**分析日期**: 2026-01-05
**分析人**: Claude
**数据版本**: 836行完整数据

---

## 📋 执行摘要

### 关键发现

🔴 **严重问题**: 6组数据中有2组（33%）**完全缺失性能指标**

| 任务组 | 样本数 | 性能指标数 | 状态 |
|--------|--------|-----------|------|
| ✅ examples | 259 | 1个 (perf_test_accuracy) | 完整 |
| ❌ VulBERTa | 152 | 0个 | **缺失** |
| ✅ Person_reID | 146 | 3个 (map, rank1, rank5) | 完整 |
| ❌ bug-localization | 142 | 0个 | **缺失** |
| ✅ MRT-OAST | 88 | 2个 (precision, recall) | 完整 |
| ✅ pytorch_resnet | 49 | 2个 (best_val_accuracy, test_accuracy) | 完整 |

**总结**: 4/6组 (67%) 包含性能指标，2/6组 (33%) 完全缺失

---

## 🔍 问题根源分析

### 1. 原始数据中性能指标的缺失情况

**全局视角**（跨所有repository）:

| 性能指标列 | 有效值/总数 | 缺失率 |
|-----------|-----------|--------|
| perf_test_accuracy | 308/836 | 63.2% |
| perf_map | 146/836 | 82.5% |
| perf_rank1 | 146/836 | 82.5% |
| perf_eval_loss | 92/836 | 89.0% |
| perf_precision | 68/836 | 91.9% |
| perf_best_val_accuracy | 49/836 | 94.1% |

**结论**: 跨repository统计，所有性能指标缺失率均>60%，这是因为不同模型使用不同的性能指标。

### 2. 按Repository分组后的真实情况

#### ✅ 有完整性能指标的4组

| Repository | 性能指标 | 缺失率 | 状态 |
|-----------|---------|--------|------|
| examples | perf_test_accuracy | 0.0% | ✓ 完美 |
| Person_reID | perf_map, rank1, rank5 | 0.0% | ✓ 完美 |
| pytorch_resnet | perf_best_val_accuracy, test_accuracy | 0.0% | ✓ 完美 |
| MRT-OAST | perf_precision | 22.7% | ✓ 可用 |
|  | perf_recall | 22.7% | ✓ 可用 |

#### ❌ 性能指标缺失的2组

**VulBERTa组**:
- 唯一可用指标: `perf_eval_loss`, `perf_eval_samples_per_second`, `perf_final_training_loss`
- 缺失率: **39.5%** (> 30%阈值)
- 有效样本: 92/152 (60.5%)
- **处理结果**: 被数据生成脚本过滤（缺失率>30%）

**bug-localization组**:
- 唯一可用指标: `perf_top1_accuracy`, `perf_top5_accuracy`, `perf_top10_accuracy`, `perf_top20_accuracy`
- 缺失率: **36.6%** (> 30%阈值)
- 有效样本: 90/142 (63.4%)
- **处理结果**: 被数据生成脚本过滤（缺失率>30%）

### 3. 数据生成脚本的过滤逻辑

```python
# 步骤4: 移除缺失率>30%的列
missing_rate = df.isna().sum() / len(df)
cols_to_keep = missing_rate[missing_rate <= 0.30].index.tolist()
```

**设计意图**: 确保数据质量，避免过多缺失值影响DiBS分析
**副作用**: VulBERTa和bug-localization的性能指标被完全移除

---

## 💥 对因果分析的影响评估

### 研究问题1: 超参数对能耗的影响

**影响**: ✅ **无影响**

- 分析路径: 超参数 → 能耗指标
- 不需要性能指标
- **可用数据**: 全部6组，836行

### 研究问题2: 能耗和性能之间的权衡关系

**影响**: ⚠️ **中等影响**

- 分析路径: 能耗指标 ↔ 性能指标
- VulBERTa和bug-localization组**无法分析**
- **可用数据**: 4组（examples, Person_reID, MRT-OAST, pytorch_resnet），641行 (76.7%)
- **损失**: 2组（VulBERTa, bug-localization），195行 (23.3%)

### 研究问题3: 中间变量的中介效应

**影响**: 🔴 **严重影响**

- 分析路径: 超参数 → duration_seconds → 能耗/性能
- 需要完整的因果链
- VulBERTa和bug-localization组**缺少关键性能变量**
- **可用数据**: 4组，641行 (76.7%)

---

## 🎯 解决方案建议

### 方案A: 保持当前数据（推荐用于问题1）

**优点**:
- ✅ 数据质量最高（0个NaN值）
- ✅ 符合DiBS所有关键要求
- ✅ 立即可用，无需重新生成

**缺点**:
- ❌ 2/6组无法分析能耗-性能关系
- ❌ 样本量从836减少到641（问题2和3）

**适用场景**:
- **研究问题1**: 超参数→能耗（使用全部6组）
- 快速验证DiBS方法
- 对数据质量要求高

**操作**:
- 无需任何修改
- 直接运行DiBS分析

---

### 方案B: 重新生成数据，调整缺失率阈值为40%（推荐用于问题2和3）

**修改内容**:
```python
# 步骤4: 移除缺失率>40%的列（原30%）
missing_rate = df.isna().sum() / len(df)
cols_to_keep = missing_rate[missing_rate <= 0.40].index.tolist()  # 30% → 40%
```

**影响**:
- ✅ VulBERTa: 保留3个性能指标（缺失率39.5%）
- ✅ bug-localization: 保留4个性能指标（缺失率36.6%）
- ⚠️ 需要填补约37-40%的缺失值（使用均值插补）

**数据质量评估**:

| 指标 | 方案A (30%阈值) | 方案B (40%阈值) |
|------|----------------|----------------|
| 有性能指标的组 | 4/6 (67%) | 6/6 (100%) |
| 平均缺失率 | 0% | ~5-8% (填补后) |
| DiBS适配性 | 完美 | 良好 |
| 样本量（问题2/3） | 641行 (76.7%) | 836行 (100%) |

**优点**:
- ✅ 全部6组均可分析能耗-性能关系
- ✅ 充分利用全部836行数据
- ✅ 研究结论更全面

**缺点**:
- ⚠️ 约40%性能数据由插补生成（VulBERTa和bug-localization）
- ⚠️ 可能引入插补偏差
- ⚠️ 需要在论文中说明数据处理方法

**适用场景**:
- **研究问题2**: 能耗↔性能权衡
- **研究问题3**: 中介效应分析
- 需要全面覆盖所有任务组
- 可接受适度的数据插补

**操作步骤**:
1. 修改 `scripts/generate_6groups_dibs_data.py` 第4步阈值
2. 重新运行数据生成脚本
3. 重新验证数据适配性
4. 文档说明数据处理方法

---

### 方案C: 分层分析策略（推荐综合方案）⭐⭐⭐

**核心思想**: 根据研究问题选择合适的数据集

| 研究问题 | 使用数据集 | 原因 |
|---------|-----------|------|
| 问题1: 超参数→能耗 | 全部6组（836行） | 不需要性能指标 |
| 问题2: 能耗↔性能 | 4组（641行） | 需要完整性能数据 |
| 问题3: 中介效应 | 4组（641行） | 需要完整因果链 |

**优点**:
- ✅ 充分利用数据（问题1用全部836行）
- ✅ 保证结果可靠（问题2/3用高质量数据）
- ✅ 无需重新生成数据
- ✅ 避免插补偏差
- ✅ 科学透明（不同问题用不同数据）

**缺点**:
- ⚠️ 问题2和3的样本量略少（641 vs 836）
- ⚠️ 需要在论文中说明分层策略

**实施细节**:

**阶段1: 问题1分析（超参数→能耗）**
```python
# 使用全部6组数据
groups_to_analyze = [
    'group1_examples',      # 259行
    'group2_vulberta',      # 152行 ✓
    'group3_person_reid',   # 146行
    'group4_bug_localization', # 142行 ✓
    'group5_mrt_oast',      # 88行
    'group6_resnet'         # 49行
]
# 总计: 836行
```

**阶段2: 问题2和3分析（能耗↔性能，中介效应）**
```python
# 仅使用有完整性能指标的4组
groups_to_analyze = [
    'group1_examples',      # 259行
    'group3_person_reid',   # 146行
    'group5_mrt_oast',      # 88行
    'group6_resnet'         # 49行
]
# 总计: 641行（76.7%）
```

**适用场景**:
- 需要平衡数据质量和数据量
- 论文研究需要严谨性
- 希望避免数据插补的潜在问题

**论文表述建议**:
> "由于不同深度学习任务的性能指标差异，我们采用分层分析策略：
> - 研究问题1（超参数对能耗的影响）使用全部6个任务组（n=836）
> - 研究问题2和3（能耗-性能关系和中介效应）使用包含完整性能指标的4个任务组（n=641）
> - 这种策略在保证结果可靠性的同时最大化了数据利用率。"

---

## 📊 三种方案对比

| 维度 | 方案A | 方案B | 方案C ⭐ |
|------|------|------|---------|
| **数据质量** | 最高（0缺失） | 良好（40%插补） | 最高（0缺失） |
| **问题1样本量** | 836行 | 836行 | 836行 |
| **问题2/3样本量** | 641行 | 836行 | 641行 |
| **任务组覆盖** | 4/6 (67%) | 6/6 (100%) | 4/6 (67%) |
| **插补偏差** | 无 | 有 | 无 |
| **实施复杂度** | 最低 | 中等 | 低 |
| **科学严谨性** | 高 | 中等 | 最高 |
| **推荐指数** | ⭐⭐⭐ | ⭐⭐ | ⭐⭐⭐⭐⭐ |

---

## 🎯 最终推荐

### 推荐采用：**方案C（分层分析策略）**

**理由**:

1. **科学严谨**: 避免插补偏差，所有结果基于真实数据
2. **数据利用最大化**: 问题1使用全部836行
3. **结果可靠**: 问题2和3使用高质量数据（641行）
4. **实施简单**: 无需重新生成数据
5. **论文透明**: 清晰说明不同问题的数据策略

### 备选方案

- **如果必须全部6组分析问题2/3**: 选择方案B（40%阈值）
- **如果只关注问题1**: 选择方案A（当前数据）

---

## 📝 后续行动建议

### 立即行动（使用方案C）

1. ✅ 保持当前6组数据不变
2. ✅ 问题1分析：使用全部6组
3. ✅ 问题2和3分析：使用4组（examples, Person_reID, MRT-OAST, pytorch_resnet）
4. 📝 在分析报告中说明分层策略和数据选择理由

### 可选行动（如果采用方案B）

1. 修改数据生成脚本阈值（30% → 40%）
2. 重新生成6组数据
3. 重新验证DiBS适配性
4. 在论文方法部分说明缺失值处理策略

---

## 📚 相关文档

- 数据生成报告: `DATA_GENERATION_REPORT.md`
- 数据适配性验证: `VALIDATION_REPORT.md`
- 数据生成脚本: `scripts/generate_6groups_dibs_data.py`
- 原始数据: `data/energy_research/raw/energy_data_original.csv`

---

**报告生成时间**: 2026-01-05
**报告版本**: 1.0
**下次更新**: 根据方案选择结果更新

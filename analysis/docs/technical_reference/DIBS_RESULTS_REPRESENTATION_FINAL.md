# DiBSç»“æœå±•ç¤ºæœ€ç»ˆæ–¹æ¡ˆ v3.0

**åˆ›å»ºæ—¥æœŸ**: 2026-01-17
**ç‰ˆæœ¬**: v3.0 (æœ€ç»ˆç‰ˆï¼Œç”¨æˆ·ç¡®è®¤)
**çŠ¶æ€**: å¾…å®æ–½

---

## ğŸ“‹ ç”¨æˆ·ç¡®è®¤çš„éœ€æ±‚

### éœ€æ±‚1: ç”Ÿæˆçš„æ–‡ä»¶æ¸…å•

æ¯ä¸ªä»»åŠ¡ç»„ç”Ÿæˆ4ä¸ªCSVæ–‡ä»¶ï¼š

1. **causal_edges_all.csv** - æ‰€æœ‰è¾¹ï¼ˆ529è¡Œï¼Œæ— ç­›é€‰ï¼‰
2. **causal_paths.csv** - æ‰€æœ‰é—´æ¥è·¯å¾„ï¼ˆpath_strength > 0.05ï¼‰
3. **causal_edges_0.3.csv** - å¼ºè¾¹ï¼ˆstrength > 0.3ï¼‰
4. **causal_paths_0.3.csv** - å¼ºè·¯å¾„ï¼ˆpath_strength > 0.3ï¼‰

### éœ€æ±‚2: æ–‡ä»¶å­˜æ”¾ä½ç½®

**ä¸ä¿®æ”¹åŸæœ‰æ–‡ä»¶**ï¼Œåœ¨ä¸Šä¸€å±‚ç›®å½•åˆ›å»ºæ–°æ–‡ä»¶å¤¹ï¼š

```
results/energy_research/dibs_interaction/
â”œâ”€â”€ 20260117_000522/                    # åŸå§‹DiBSè¾“å‡ºï¼ˆä¸ä¿®æ”¹ï¼‰â­
â”‚   â”œâ”€â”€ group1_examples_causal_graph.npy
â”‚   â”œâ”€â”€ group1_examples_feature_names.json
â”‚   â”œâ”€â”€ group1_examples_result.json
â”‚   â””â”€â”€ ...
â”‚
â””â”€â”€ 20260117_000522_readable/           # æ–°å¢ï¼šå¯è¯»ç»“æœï¼ˆCSVï¼‰â­â­â­
    â”œâ”€â”€ group1_examples_causal_edges_all.csv
    â”œâ”€â”€ group1_examples_causal_paths.csv
    â”œâ”€â”€ group1_examples_causal_edges_0.3.csv
    â”œâ”€â”€ group1_examples_causal_paths_0.3.csv
    â”œâ”€â”€ group2_vulberta_causal_edges_all.csv
    â”œâ”€â”€ group2_vulberta_causal_paths.csv
    â”œâ”€â”€ ... (6ç»„ Ã— 4æ–‡ä»¶ = 24ä¸ªCSVæ–‡ä»¶)
    â””â”€â”€ README.md                       # æ–‡ä»¶è¯´æ˜
```

**å…³é”®è®¾è®¡**:
- âœ… åŸå§‹ç›®å½• `20260117_000522/` **ä¸è¢«ä¿®æ”¹**
- âœ… æ–°ç›®å½• `20260117_000522_readable/` å­˜æ”¾æ‰€æœ‰CSVæ–‡ä»¶
- âœ… æ¸…æ™°çš„å‘½åçº¦å®š

---

## ğŸ“„ æ–‡ä»¶æ ¼å¼è¯¦ç»†è¯´æ˜

### æ–‡ä»¶1: causal_edges_all.csvï¼ˆæ‰€æœ‰ç›´æ¥è¾¹ï¼‰

**è¡Œæ•°**: 529è¡Œï¼ˆ23Ã—23æ‰€æœ‰å¯èƒ½çš„è¾¹ï¼‰

**åˆ—å®šä¹‰**:
```csv
source,target,strength,edge_type,is_significant,strength_level,source_category,target_category,question_relevance,interpretation
```

**å­—æ®µè¯´æ˜**:
- `source`: æºå˜é‡ï¼ˆå®Œæ•´åç§°ï¼‰
- `target`: ç›®æ ‡å˜é‡ï¼ˆå®Œæ•´åç§°ï¼‰
- `strength`: è¾¹å¼ºåº¦ï¼ˆ0-1ï¼ŒåŒ…æ‹¬0.00ï¼‰
- `edge_type`: è¾¹ç±»å‹ï¼ˆmain_effect/moderation/mediator/control_effect/irrelevantï¼‰
- `is_significant`: æ˜¯å¦æ˜¾è‘—ï¼ˆyes: >0.1, no: â‰¤0.1ï¼‰
- `strength_level`: å¼ºåº¦ç­‰çº§ï¼ˆvery_strong/strong/moderate/weak/very_weak/zeroï¼‰
- `source_category`: æºç±»åˆ«ï¼ˆhyperparam/interaction/energy/performance/mediator/controlï¼‰
- `target_category`: ç›®æ ‡ç±»åˆ«ï¼ˆåŒä¸Šï¼‰
- `question_relevance`: ç›¸å…³ç ”ç©¶é—®é¢˜ï¼ˆQ1/Q2/Q3/otherï¼‰
- `interpretation`: äººç±»å¯è¯»è§£é‡Š

**æ’åº**: æŒ‰`strength`é™åºï¼ˆå¼ºè¾¹åœ¨å‰ï¼‰

**ç¤ºä¾‹**:
```csv
source,target,strength,edge_type,is_significant,strength_level,source_category,target_category,question_relevance,interpretation
hyperparam_epochs,energy_gpu_total_joules,0.40,main_effect,yes,strong,hyperparam,energy,Q1,epochsç›´æ¥å½±å“GPUæ€»èƒ½è€—
hyperparam_batch_size_x_is_parallel,energy_cpu_total_joules,0.35,moderation,yes,strong,interaction,energy,Q1,å¹¶è¡Œæ¨¡å¼è°ƒèŠ‚batch_sizeå¯¹CPUèƒ½è€—çš„æ•ˆåº”
hyperparam_batch_size,energy_cpu_total_joules,0.00,main_effect,no,zero,hyperparam,energy,Q1,batch_sizeå¯¹CPUèƒ½è€—æ— ç›´æ¥å½±å“
hyperparam_seed,perf_test_accuracy,0.00,irrelevant,no,zero,hyperparam,performance,other,éšæœºç§å­ä¸å½±å“æ€§èƒ½ï¼ˆé¢„æœŸï¼‰
```

---

### æ–‡ä»¶2: causal_paths.csvï¼ˆæ‰€æœ‰é—´æ¥è·¯å¾„ï¼‰

**ç­›é€‰æ¡ä»¶**: path_strength > 0.05ï¼ˆè¿‡æ»¤å¼±è·¯å¾„ï¼‰

**åˆ—å®šä¹‰**:
```csv
path_id,path_length,source,target,path,path_strength,step1_strength,step2_strength,step3_strength,path_type,question_relevance,interpretation
```

**å­—æ®µè¯´æ˜**:
- `path_id`: è·¯å¾„å”¯ä¸€IDï¼ˆP2_001è¡¨ç¤º2æ­¥è·¯å¾„ç¬¬1æ¡ï¼ŒP3_001è¡¨ç¤º3æ­¥è·¯å¾„ç¬¬1æ¡ï¼‰
- `path_length`: è·¯å¾„æ­¥æ•°ï¼ˆ2æˆ–3ï¼‰
- `source`: èµ·ç‚¹å˜é‡ï¼ˆå®Œæ•´åç§°ï¼‰
- `target`: ç»ˆç‚¹å˜é‡ï¼ˆå®Œæ•´åç§°ï¼‰
- `path`: **å®Œæ•´è·¯å¾„ï¼ˆç®€åŒ–å˜é‡åï¼‰** â­â­â­â­â­
  - æ ¼å¼: "ç®€åŒ–æº â†’ ç®€åŒ–ä¸­ä»‹1 â†’ ç®€åŒ–ä¸­ä»‹2 â†’ ç®€åŒ–ç›®æ ‡"
  - ç®€åŒ–è§„åˆ™:
    - `hyperparam_` â†’ åˆ é™¤
    - `energy_` â†’ åˆ é™¤
    - `perf_` â†’ åˆ é™¤
    - `_x_is_parallel` â†’ `_x_parallel`
- `path_strength`: è·¯å¾„æ€»å¼ºåº¦ï¼ˆå„æ­¥å¼ºåº¦ç›¸ä¹˜ï¼‰
- `step1_strength`, `step2_strength`, `step3_strength`: å„æ­¥å¼ºåº¦
- `path_type`: è·¯å¾„ç±»å‹
- `question_relevance`: ç›¸å…³ç ”ç©¶é—®é¢˜
- `interpretation`: äººç±»å¯è¯»è§£é‡Š

**è·¯å¾„ç±»å‹**:
- `mediation_to_energy`: è¶…å‚æ•° â†’ ä¸­ä»‹ â†’ èƒ½è€—
- `mediation_to_performance`: è¶…å‚æ•° â†’ ä¸­ä»‹ â†’ æ€§èƒ½
- `moderation_mediated`: è°ƒèŠ‚æ•ˆåº” â†’ ä¸­ä»‹ â†’ èƒ½è€—/æ€§èƒ½
- `energy_perf_mediated`: èƒ½è€— â†’ ä¸­ä»‹ â†’ æ€§èƒ½ï¼ˆæˆ–åå‘ï¼‰
- `other_mediation`: å…¶ä»–ä¸­ä»‹è·¯å¾„

**æ’åº**: æŒ‰`path_strength`é™åº

**ç¤ºä¾‹**:
```csv
path_id,path_length,source,target,path,path_strength,step1_strength,step2_strength,step3_strength,path_type,question_relevance,interpretation
P2_001,2,hyperparam_batch_size,energy_gpu_total_joules,batch_size â†’ gpu_max_watts â†’ gpu_total,0.12,0.30,0.40,,mediation_to_energy,Q1-Q3,batch_sizeé€šè¿‡GPUå³°å€¼åŠŸç‡é—´æ¥å½±å“GPUæ€»èƒ½è€—
P3_001,3,hyperparam_batch_size,perf_test_accuracy,batch_size â†’ gpu_max_watts â†’ gpu_util_max â†’ test_accuracy,0.042,0.30,0.40,0.35,mediation_to_performance,Q3,batch_sizeé€šè¿‡GPUåŠŸç‡å’Œåˆ©ç”¨ç‡é—´æ¥å½±å“æ€§èƒ½
P2_002,2,hyperparam_epochs_x_is_parallel,energy_cpu_total_joules,epochs_x_parallel â†’ gpu_temp_max â†’ cpu_total,0.09,0.30,0.30,,moderation_mediated,Q1-Q3,å¹¶è¡Œè°ƒèŠ‚æ•ˆåº”é€šè¿‡GPUæ¸©åº¦å½±å“CPUèƒ½è€—
```

---

### æ–‡ä»¶3: causal_edges_0.3.csvï¼ˆå¼ºè¾¹ï¼‰

**ç­›é€‰æ¡ä»¶**: strength > 0.3

**æ ¼å¼**: ä¸`causal_edges_all.csv`å®Œå…¨ç›¸åŒï¼Œåªæ˜¯è¡Œæ•°æ›´å°‘

**è¡Œæ•°**: çº¦42-78è¡Œï¼ˆæ ¹æ®ç»„ä¸åŒï¼‰

**ç”¨é€”**: å¿«é€ŸæŸ¥çœ‹æœ€é‡è¦çš„å› æœå…³ç³»ï¼Œæ— éœ€æ‰‹åŠ¨ç­›é€‰

**ç¤ºä¾‹**:
```csv
source,target,strength,edge_type,is_significant,strength_level,source_category,target_category,question_relevance,interpretation
hyperparam_epochs,energy_gpu_total_joules,0.40,main_effect,yes,strong,hyperparam,energy,Q1,epochsç›´æ¥å½±å“GPUæ€»èƒ½è€—
hyperparam_batch_size_x_is_parallel,energy_cpu_total_joules,0.35,moderation,yes,strong,interaction,energy,Q1,å¹¶è¡Œæ¨¡å¼è°ƒèŠ‚batch_sizeå¯¹CPUèƒ½è€—çš„æ•ˆåº”
hyperparam_epochs_x_is_parallel,energy_gpu_total_joules,0.40,moderation,yes,strong,interaction,energy,Q1,å¹¶è¡Œæ¨¡å¼è°ƒèŠ‚epochså¯¹GPUèƒ½è€—çš„æ•ˆåº”
```

---

### æ–‡ä»¶4: causal_paths_0.3.csvï¼ˆå¼ºè·¯å¾„ï¼‰

**ç­›é€‰æ¡ä»¶**: path_strength > 0.3

**æ ¼å¼**: ä¸`causal_paths.csv`å®Œå…¨ç›¸åŒï¼Œåªæ˜¯è¡Œæ•°æ›´å°‘

**è¡Œæ•°**: çº¦0-5è¡Œï¼ˆå¼ºè·¯å¾„éå¸¸å°‘è§ï¼‰

**ç”¨é€”**: å‘ç°æå¼ºçš„é—´æ¥æ•ˆåº”

**æ³¨æ„**: å¦‚æœæŸç»„æ²¡æœ‰å¼ºè·¯å¾„ï¼ˆpath_strength > 0.3ï¼‰ï¼Œè¯¥æ–‡ä»¶å¯èƒ½ä¸ºç©ºï¼ˆä»…åŒ…å«headerï¼‰

---

## ğŸ—‚ï¸ ç›®å½•ç»“æ„å’Œæ–‡ä»¶å‘½å

### å®Œæ•´ç›®å½•ç»“æ„

```
results/energy_research/dibs_interaction/
â”œâ”€â”€ 20260117_000522/                          # åŸå§‹DiBSè¾“å‡ºï¼ˆä¿æŒä¸å˜ï¼‰
â”‚   â”œâ”€â”€ group1_examples_causal_graph.npy
â”‚   â”œâ”€â”€ group1_examples_feature_names.json
â”‚   â”œâ”€â”€ group1_examples_result.json
â”‚   â”œâ”€â”€ group2_vulberta_causal_graph.npy
â”‚   â”œâ”€â”€ group2_vulberta_feature_names.json
â”‚   â”œâ”€â”€ group2_vulberta_result.json
â”‚   â”œâ”€â”€ ... (å…±18ä¸ªæ–‡ä»¶: 6ç»„ Ã— 3æ–‡ä»¶)
â”‚   â””â”€â”€ DIBS_INTERACTION_ANALYSIS_REPORT.md
â”‚
â””â”€â”€ 20260117_000522_readable/                 # æ–°å¢ï¼šå¯è¯»ç»“æœ
    â”œâ”€â”€ README.md                             # æ–‡ä»¶è¯´æ˜ â­
    â”‚
    â”œâ”€â”€ group1_examples_causal_edges_all.csv
    â”œâ”€â”€ group1_examples_causal_paths.csv
    â”œâ”€â”€ group1_examples_causal_edges_0.3.csv
    â”œâ”€â”€ group1_examples_causal_paths_0.3.csv
    â”‚
    â”œâ”€â”€ group2_vulberta_causal_edges_all.csv
    â”œâ”€â”€ group2_vulberta_causal_paths.csv
    â”œâ”€â”€ group2_vulberta_causal_edges_0.3.csv
    â”œâ”€â”€ group2_vulberta_causal_paths_0.3.csv
    â”‚
    â”œâ”€â”€ group3_person_reid_causal_edges_all.csv
    â”œâ”€â”€ group3_person_reid_causal_paths.csv
    â”œâ”€â”€ group3_person_reid_causal_edges_0.3.csv
    â”œâ”€â”€ group3_person_reid_causal_paths_0.3.csv
    â”‚
    â”œâ”€â”€ group4_bug_localization_causal_edges_all.csv
    â”œâ”€â”€ group4_bug_localization_causal_paths.csv
    â”œâ”€â”€ group4_bug_localization_causal_edges_0.3.csv
    â”œâ”€â”€ group4_bug_localization_causal_paths_0.3.csv
    â”‚
    â”œâ”€â”€ group5_mrt_oast_causal_edges_all.csv
    â”œâ”€â”€ group5_mrt_oast_causal_paths.csv
    â”œâ”€â”€ group5_mrt_oast_causal_edges_0.3.csv
    â”œâ”€â”€ group5_mrt_oast_causal_paths_0.3.csv
    â”‚
    â”œâ”€â”€ group6_resnet_causal_edges_all.csv
    â”œâ”€â”€ group6_resnet_causal_paths.csv
    â”œâ”€â”€ group6_resnet_causal_edges_0.3.csv
    â””â”€â”€ group6_resnet_causal_paths_0.3.csv
```

**æ€»æ–‡ä»¶æ•°**: 24ä¸ªCSVæ–‡ä»¶ï¼ˆ6ç»„ Ã— 4æ–‡ä»¶ï¼‰+ 1ä¸ªREADME = 25ä¸ªæ–‡ä»¶

### README.mdå†…å®¹

```markdown
# DiBSå› æœåˆ†æå¯è¯»ç»“æœ

**ç”Ÿæˆæ—¶é—´**: 2026-01-17
**åŸå§‹æ•°æ®**: ../20260117_000522/
**æ–‡ä»¶æ•°é‡**: 24ä¸ªCSVæ–‡ä»¶ï¼ˆ6ç»„ Ã— 4æ–‡ä»¶ï¼‰

---

## æ–‡ä»¶è¯´æ˜

æ¯ä¸ªä»»åŠ¡ç»„ç”Ÿæˆ4ä¸ªCSVæ–‡ä»¶ï¼š

1. **{group}_causal_edges_all.csv** (529è¡Œ)
   - æ‰€æœ‰ç›´æ¥å› æœè¾¹ï¼ˆæ— ç­›é€‰ï¼‰
   - åŒ…æ‹¬å¼ºåº¦=0çš„è¾¹
   - ç”¨äºéªŒè¯"è¾¹ä¸å­˜åœ¨"

2. **{group}_causal_paths.csv** (çº¦100-200è¡Œ)
   - æ‰€æœ‰é—´æ¥å› æœè·¯å¾„ï¼ˆ2æ­¥å’Œ3æ­¥ï¼‰
   - ç­›é€‰: path_strength > 0.05
   - ç”¨äºå‘ç°ä¸­ä»‹æ•ˆåº”

3. **{group}_causal_edges_0.3.csv** (çº¦42-78è¡Œ)
   - å¼ºç›´æ¥è¾¹ï¼ˆstrength > 0.3ï¼‰
   - å¿«é€ŸæŸ¥çœ‹æœ€é‡è¦çš„å› æœå…³ç³»

4. **{group}_causal_paths_0.3.csv** (çº¦0-5è¡Œ)
   - å¼ºé—´æ¥è·¯å¾„ï¼ˆpath_strength > 0.3ï¼‰
   - å‘ç°æå¼ºçš„ä¸­ä»‹æ•ˆåº”

---

## ä½¿ç”¨ç¤ºä¾‹

### Excelå¿«é€ŸæŸ¥çœ‹

1. æ‰“å¼€ `group1_examples_causal_edges_0.3.csv`
2. æŸ¥çœ‹æ‰€æœ‰å¼ºå› æœå…³ç³»ï¼ˆä¸€ç›®äº†ç„¶ï¼‰

### æŸ¥çœ‹è°ƒèŠ‚æ•ˆåº”

```bash
cat group1_examples_causal_edges_all.csv | grep "moderation"
```

### æŸ¥çœ‹é—´æ¥æ•ˆåº”

```bash
cat group1_examples_causal_paths.csv | grep "batch_size"
```

---

## åŸå§‹æ•°æ®ä½ç½®

å®Œæ•´çš„DiBSè¾“å‡ºï¼ˆåŒ…æ‹¬.npyçŸ©é˜µå’Œ.jsonç»“æœï¼‰ä½äºï¼š
`../20260117_000522/`
```

---

## ğŸ› ï¸ å®æ–½æ–¹æ¡ˆ

### è„šæœ¬è®¾è®¡

**è„šæœ¬åç§°**: `scripts/convert_dibs_to_csv.py`

**è¾“å…¥å‚æ•°**:
```bash
python scripts/convert_dibs_to_csv.py \
  --input-dir results/energy_research/dibs_interaction/20260117_000522 \
  --output-dir results/energy_research/dibs_interaction/20260117_000522_readable
```

**åŠŸèƒ½**:
1. è¯»å–åŸå§‹ç›®å½•ä¸­çš„æ‰€æœ‰`.npy`å’Œ`.json`æ–‡ä»¶
2. å¯¹æ¯ä¸ªä»»åŠ¡ç»„ç”Ÿæˆ4ä¸ªCSVæ–‡ä»¶
3. åœ¨è¾“å‡ºç›®å½•ç”ŸæˆREADME.md
4. **ä¸ä¿®æ”¹**åŸå§‹ç›®å½•ä¸­çš„ä»»ä½•æ–‡ä»¶

### æ ¸å¿ƒå‡½æ•°

```python
import numpy as np
import pandas as pd
import json
from pathlib import Path

def convert_dibs_results_to_csv(input_dir, output_dir):
    """
    å°†DiBSç»“æœè½¬æ¢ä¸ºå¯è¯»çš„CSVæ ¼å¼

    å‚æ•°:
        input_dir: åŸå§‹DiBSè¾“å‡ºç›®å½•ï¼ˆå¦‚ 20260117_000522ï¼‰
        output_dir: CSVè¾“å‡ºç›®å½•ï¼ˆå¦‚ 20260117_000522_readableï¼‰
    """
    input_path = Path(input_dir)
    output_path = Path(output_dir)

    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_path.mkdir(parents=True, exist_ok=True)

    # æŸ¥æ‰¾æ‰€æœ‰ä»»åŠ¡ç»„
    npy_files = list(input_path.glob('*_causal_graph.npy'))

    print(f"æ‰¾åˆ° {len(npy_files)} ä¸ªä»»åŠ¡ç»„")

    for npy_file in npy_files:
        task_id = npy_file.stem.replace('_causal_graph', '')
        print(f"\nå¤„ç†ä»»åŠ¡ç»„: {task_id}")

        # è¯»å–æ•°æ®
        causal_graph = np.load(npy_file)
        feature_names_file = input_path / f"{task_id}_feature_names.json"
        with open(feature_names_file) as f:
            feature_names = json.load(f)

        # 1. ç”Ÿæˆ causal_edges_all.csv
        edges_all = generate_all_edges(causal_graph, feature_names)
        output_file = output_path / f"{task_id}_causal_edges_all.csv"
        edges_all.to_csv(output_file, index=False)
        print(f"  âœ“ ç”Ÿæˆ {output_file.name} ({len(edges_all)} è¡Œ)")

        # 2. ç”Ÿæˆ causal_paths.csv
        paths_all = generate_all_paths(causal_graph, feature_names, min_strength=0.05)
        output_file = output_path / f"{task_id}_causal_paths.csv"
        paths_all.to_csv(output_file, index=False)
        print(f"  âœ“ ç”Ÿæˆ {output_file.name} ({len(paths_all)} è¡Œ)")

        # 3. ç”Ÿæˆ causal_edges_0.3.csv
        edges_strong = edges_all[edges_all['strength'] > 0.3]
        output_file = output_path / f"{task_id}_causal_edges_0.3.csv"
        edges_strong.to_csv(output_file, index=False)
        print(f"  âœ“ ç”Ÿæˆ {output_file.name} ({len(edges_strong)} è¡Œ)")

        # 4. ç”Ÿæˆ causal_paths_0.3.csv
        paths_strong = paths_all[paths_all['path_strength'] > 0.3]
        output_file = output_path / f"{task_id}_causal_paths_0.3.csv"
        paths_strong.to_csv(output_file, index=False)
        print(f"  âœ“ ç”Ÿæˆ {output_file.name} ({len(paths_strong)} è¡Œ)")

    # ç”ŸæˆREADME.md
    generate_readme(output_path, len(npy_files))
    print(f"\nâœ“ ç”Ÿæˆ README.md")

    print(f"\nå®Œæˆï¼å…±ç”Ÿæˆ {len(npy_files) * 4} ä¸ªCSVæ–‡ä»¶")

def generate_all_edges(causal_graph, feature_names):
    """
    ç”Ÿæˆæ‰€æœ‰è¾¹çš„DataFrameï¼ˆæ— ç­›é€‰ï¼‰

    å‚æ•°:
        causal_graph: (n, n) numpyæ•°ç»„ï¼Œå› æœå›¾çŸ©é˜µ
        feature_names: å˜é‡ååˆ—è¡¨

    è¿”å›:
        DataFrameåŒ…å«æ‰€æœ‰529æ¡è¾¹
    """
    import pandas as pd

    n = len(feature_names)
    edges = []

    # éå†æ‰€æœ‰å¯èƒ½çš„è¾¹ï¼ˆåŒ…æ‹¬å¼ºåº¦=0ï¼‰
    for i in range(n):
        for j in range(n):
            source = feature_names[i]
            target = feature_names[j]
            strength = float(causal_graph[i, j])

            # åˆ†ç±»è¾¹ç±»å‹
            edge_type = classify_edge_type(source, target)

            # åˆ¤æ–­æ˜¯å¦æ˜¾è‘—
            is_significant = 'yes' if strength > 0.1 else 'no'

            # å¼ºåº¦ç­‰çº§
            if strength > 0.5:
                strength_level = 'very_strong'
            elif strength > 0.3:
                strength_level = 'strong'
            elif strength > 0.1:
                strength_level = 'moderate'
            elif strength > 0.01:
                strength_level = 'weak'
            elif strength > 0.001:
                strength_level = 'very_weak'
            else:
                strength_level = 'zero'

            # å˜é‡ç±»åˆ«
            source_category = get_variable_category(source)
            target_category = get_variable_category(target)

            # ç ”ç©¶é—®é¢˜ç›¸å…³æ€§
            question_relevance = get_question_relevance(source, target, edge_type)

            # äººç±»å¯è¯»è§£é‡Š
            interpretation = generate_interpretation(source, target, strength, edge_type)

            edges.append({
                'source': source,
                'target': target,
                'strength': strength,
                'edge_type': edge_type,
                'is_significant': is_significant,
                'strength_level': strength_level,
                'source_category': source_category,
                'target_category': target_category,
                'question_relevance': question_relevance,
                'interpretation': interpretation
            })

    # è½¬æ¢ä¸ºDataFrameå¹¶æŒ‰å¼ºåº¦é™åºæ’åº
    df = pd.DataFrame(edges)
    df = df.sort_values('strength', ascending=False)

    return df


def classify_edge_type(source, target):
    """
    åˆ†ç±»è¾¹ç±»å‹

    è§„åˆ™:
    1. å¦‚æœsourceåŒ…å«'_x_is_parallel' â†’ moderationï¼ˆè°ƒèŠ‚æ•ˆåº”ï¼‰
    2. å¦‚æœsourceæ˜¯è¶…å‚æ•° ä¸” targetæ˜¯èƒ½è€— â†’ main_effect
    3. å¦‚æœsourceæ˜¯èƒ½è€—ç›¸å…³ ä¸” targetæ˜¯èƒ½è€— â†’ mediator
    4. å¦‚æœsourceæ˜¯'model_' â†’ control_effect
    5. å¦‚æœstrengthâ‰ˆ0 â†’ irrelevant
    """
    if '_x_is_parallel' in source:
        return 'moderation'

    if source.startswith('hyperparam_') and '_x_' not in source:
        if target.startswith('energy_'):
            return 'main_effect'
        elif target.startswith('perf_'):
            return 'main_effect'

    if source.startswith('energy_') and target.startswith('energy_') and source != target:
        return 'mediator'

    if source.startswith('model_'):
        return 'control_effect'

    if source == 'is_parallel':
        return 'mode_effect'

    return 'irrelevant'


def get_variable_category(var_name):
    """è·å–å˜é‡ç±»åˆ«"""
    if '_x_is_parallel' in var_name:
        return 'interaction'
    elif var_name.startswith('hyperparam_'):
        return 'hyperparam'
    elif var_name in ['energy_cpu_pkg_joules', 'energy_cpu_ram_joules',
                      'energy_cpu_total_joules', 'energy_gpu_total_joules']:
        return 'energy'
    elif var_name.startswith('energy_gpu'):
        return 'mediator'
    elif var_name.startswith('perf_'):
        return 'performance'
    elif var_name.startswith('model_'):
        return 'control'
    elif var_name == 'is_parallel':
        return 'mode'
    else:
        return 'other'


def get_question_relevance(source, target, edge_type):
    """åˆ¤æ–­ä¸ç ”ç©¶é—®é¢˜çš„ç›¸å…³æ€§"""
    relevance = []

    # Q1: è¶…å‚æ•°å¯¹èƒ½è€—çš„å½±å“
    if (source.startswith('hyperparam_') or '_x_is_parallel' in source) and \
       target in ['energy_cpu_pkg_joules', 'energy_cpu_ram_joules',
                  'energy_cpu_total_joules', 'energy_gpu_total_joules']:
        relevance.append('Q1')

    # Q2: èƒ½è€—-æ€§èƒ½æƒè¡¡
    if (source.startswith('energy_') and target.startswith('perf_')) or \
       (source.startswith('perf_') and target.startswith('energy_')):
        relevance.append('Q2')

    # Q3: ä¸­ä»‹æ•ˆåº”
    if edge_type == 'mediator':
        relevance.append('Q3')

    return ','.join(relevance) if relevance else 'other'


def generate_interpretation(source, target, strength, edge_type):
    """ç”Ÿæˆäººç±»å¯è¯»è§£é‡Š"""
    # ç®€åŒ–å˜é‡åç”¨äºæ˜¾ç¤º
    source_simple = simplify_variable_name(source)
    target_simple = simplify_variable_name(target)

    if strength < 0.001:
        return f"{source_simple}å¯¹{target_simple}æ— å½±å“"

    if edge_type == 'moderation':
        base_param = source.replace('_x_is_parallel', '').replace('hyperparam_', '')
        return f"å¹¶è¡Œæ¨¡å¼è°ƒèŠ‚{base_param}å¯¹{target_simple}çš„æ•ˆåº”"
    elif edge_type == 'main_effect':
        return f"{source_simple}ç›´æ¥å½±å“{target_simple}"
    elif edge_type == 'mediator':
        return f"{source_simple}é€šè¿‡æŸç§æœºåˆ¶å½±å“{target_simple}"
    elif edge_type == 'control_effect':
        return f"æ¨¡å‹æ§åˆ¶å˜é‡çš„å½±å“"
    else:
        return f"{source_simple} â†’ {target_simple}"


def generate_all_paths(causal_graph, feature_names, min_strength=0.05):
    """
    ç”Ÿæˆæ‰€æœ‰é—´æ¥è·¯å¾„çš„DataFrame

    å‚æ•°:
        causal_graph: (n, n) numpyæ•°ç»„
        feature_names: å˜é‡ååˆ—è¡¨
        min_strength: æœ€å°è·¯å¾„å¼ºåº¦é˜ˆå€¼

    è¿”å›:
        DataFrameåŒ…å«æ‰€æœ‰2æ­¥å’Œ3æ­¥è·¯å¾„
    """
    import pandas as pd

    n = len(feature_names)
    paths = []

    # ========== 1. å‘ç°2æ­¥è·¯å¾„: source â†’ mediator â†’ target ==========
    print(f"  å‘ç°2æ­¥è·¯å¾„...")
    for source in range(n):
        # åªå…³æ³¨å…³é”®èµ·ç‚¹ï¼ˆè¶…å‚æ•°ã€äº¤äº’é¡¹ï¼‰
        source_name = feature_names[source]
        if not is_key_variable(source_name):
            continue

        for target in range(n):
            if source == target:
                continue  # è·³è¿‡è‡ªç¯

            for mediator in range(n):
                if mediator in [source, target]:
                    continue  # è·³è¿‡ç›´æ¥è¾¹

                strength1 = float(causal_graph[source, mediator])
                strength2 = float(causal_graph[mediator, target])

                if strength1 > 0 and strength2 > 0:
                    path_strength = strength1 * strength2
                    if path_strength > min_strength:
                        path_id = f"P2_{len([p for p in paths if p['path_length'] == 2]) + 1:03d}"

                        paths.append({
                            'path_id': path_id,
                            'path_length': 2,
                            'source': feature_names[source],
                            'target': feature_names[target],
                            'path': format_path([feature_names[source],
                                               feature_names[mediator],
                                               feature_names[target]]),
                            'path_strength': path_strength,
                            'step1_strength': strength1,
                            'step2_strength': strength2,
                            'step3_strength': None,
                            'path_type': classify_path_type(feature_names[source],
                                                           feature_names[mediator],
                                                           feature_names[target]),
                            'question_relevance': get_path_question_relevance(
                                feature_names[source], feature_names[target]),
                            'interpretation': generate_path_interpretation(
                                feature_names[source], feature_names[mediator],
                                feature_names[target], 2)
                        })

    print(f"    æ‰¾åˆ° {len([p for p in paths if p['path_length'] == 2])} æ¡2æ­¥è·¯å¾„")

    # ========== 2. å‘ç°3æ­¥è·¯å¾„: source â†’ med1 â†’ med2 â†’ target ==========
    print(f"  å‘ç°3æ­¥è·¯å¾„...")
    for source in range(n):
        source_name = feature_names[source]
        if not is_key_variable(source_name):
            continue

        for target in range(n):
            if source == target:
                continue

            for med1 in range(n):
                if med1 in [source, target]:
                    continue

                for med2 in range(n):
                    if med2 in [source, target, med1]:
                        continue  # é¿å…ç¯è·¯

                    s1 = float(causal_graph[source, med1])
                    s2 = float(causal_graph[med1, med2])
                    s3 = float(causal_graph[med2, target])

                    if s1 > 0 and s2 > 0 and s3 > 0:
                        path_strength = s1 * s2 * s3
                        if path_strength > min_strength:
                            path_id = f"P3_{len([p for p in paths if p['path_length'] == 3]) + 1:03d}"

                            paths.append({
                                'path_id': path_id,
                                'path_length': 3,
                                'source': feature_names[source],
                                'target': feature_names[target],
                                'path': format_path([feature_names[source],
                                                   feature_names[med1],
                                                   feature_names[med2],
                                                   feature_names[target]]),
                                'path_strength': path_strength,
                                'step1_strength': s1,
                                'step2_strength': s2,
                                'step3_strength': s3,
                                'path_type': classify_path_type(feature_names[source],
                                                               feature_names[med1],
                                                               feature_names[target],
                                                               feature_names[med2]),
                                'question_relevance': get_path_question_relevance(
                                    feature_names[source], feature_names[target]),
                                'interpretation': generate_path_interpretation(
                                    feature_names[source], feature_names[med1],
                                    feature_names[target], 3, feature_names[med2])
                            })

    print(f"    æ‰¾åˆ° {len([p for p in paths if p['path_length'] == 3])} æ¡3æ­¥è·¯å¾„")

    # 3. è½¬æ¢ä¸ºDataFrameå¹¶æ’åº
    df = pd.DataFrame(paths)
    if len(df) > 0:
        df = df.sort_values('path_strength', ascending=False)

    return df


def is_key_variable(var_name):
    """åˆ¤æ–­æ˜¯å¦ä¸ºå…³é”®èµ·ç‚¹å˜é‡ï¼ˆç”¨äºè·¯å¾„æœç´¢ï¼‰"""
    # å…³é”®èµ·ç‚¹ï¼šè¶…å‚æ•°ã€äº¤äº’é¡¹
    if var_name.startswith('hyperparam_') or '_x_is_parallel' in var_name:
        return True
    # æ’é™¤ï¼šæ§åˆ¶å˜é‡ã€ç§å­ã€æ¨¡å‹å˜é‡
    if var_name.startswith('model_') or 'seed' in var_name:
        return False
    return False


def format_path(nodes):
    """æ ¼å¼åŒ–è·¯å¾„ä¸ºå¯è¯»å­—ç¬¦ä¸²"""
    simplified = [simplify_variable_name(n) for n in nodes]
    return ' â†’ '.join(simplified)


def simplify_variable_name(var_name):
    """
    ç®€åŒ–å˜é‡åï¼ˆç”¨äºpathåˆ—æ˜¾ç¤ºï¼‰

    è§„åˆ™:
    - åˆ é™¤ 'hyperparam_', 'energy_', 'perf_' å‰ç¼€
    - '_x_is_parallel' â†’ '_x_parallel'
    - ä¿ç•™ 'model_', 'is_parallel' ç­‰ç‰¹æ®Šå˜é‡
    """
    # ç‰¹æ®Šå˜é‡ä¸ç®€åŒ–
    if var_name in ['is_parallel'] or var_name.startswith('model_'):
        return var_name

    # åˆ é™¤å‰ç¼€
    prefixes = ['hyperparam_', 'energy_', 'perf_']
    for prefix in prefixes:
        if var_name.startswith(prefix):
            var_name = var_name.replace(prefix, '')
            break

    # ç®€åŒ–äº¤äº’é¡¹æ ‡è®°
    var_name = var_name.replace('_x_is_parallel', '_x_parallel')

    return var_name


def classify_path_type(source, mediator, target, mediator2=None):
    """åˆ†ç±»è·¯å¾„ç±»å‹"""
    if source.startswith('hyperparam_') and '_x_' not in source:
        if target.startswith('energy_'):
            return 'mediation_to_energy'
        elif target.startswith('perf_'):
            return 'mediation_to_performance'

    if '_x_is_parallel' in source:
        return 'moderation_mediated'

    if source.startswith('energy_') and target.startswith('perf_'):
        return 'energy_perf_mediated'

    return 'other_mediation'


def get_path_question_relevance(source, target):
    """è·å–è·¯å¾„çš„ç ”ç©¶é—®é¢˜ç›¸å…³æ€§"""
    relevance = []

    if (source.startswith('hyperparam_') or '_x_is_parallel' in source) and \
       target.startswith('energy_'):
        relevance.extend(['Q1', 'Q3'])  # è¶…å‚æ•°å½±å“èƒ½è€—ï¼Œæœ‰ä¸­ä»‹æ•ˆåº”

    if source.startswith('energy_') and target.startswith('perf_'):
        relevance.extend(['Q2', 'Q3'])

    if source.startswith('hyperparam_') and target.startswith('perf_'):
        relevance.append('Q3')

    return ','.join(set(relevance)) if relevance else 'other'


def generate_path_interpretation(source, mediator1, target, steps, mediator2=None):
    """ç”Ÿæˆè·¯å¾„è§£é‡Š"""
    source_simple = simplify_variable_name(source)
    med1_simple = simplify_variable_name(mediator1)
    target_simple = simplify_variable_name(target)

    if steps == 2:
        return f"{source_simple}é€šè¿‡{med1_simple}é—´æ¥å½±å“{target_simple}"
    else:  # steps == 3
        med2_simple = simplify_variable_name(mediator2)
        return f"{source_simple}é€šè¿‡{med1_simple}å’Œ{med2_simple}é—´æ¥å½±å“{target_simple}"


def generate_readme(output_path, num_groups):
    """ç”ŸæˆREADME.md"""
    readme_content = f"""# DiBSå› æœåˆ†æå¯è¯»ç»“æœ

**ç”Ÿæˆæ—¶é—´**: 2026-01-17
**åŸå§‹æ•°æ®**: ../20260117_000522/
**æ–‡ä»¶æ•°é‡**: {num_groups * 4}ä¸ªCSVæ–‡ä»¶ï¼ˆ{num_groups}ç»„ Ã— 4æ–‡ä»¶ï¼‰

---

## æ–‡ä»¶è¯´æ˜

æ¯ä¸ªä»»åŠ¡ç»„ç”Ÿæˆ4ä¸ªCSVæ–‡ä»¶ï¼š

1. **{{group}}_causal_edges_all.csv** (529è¡Œ)
   - æ‰€æœ‰ç›´æ¥å› æœè¾¹ï¼ˆæ— ç­›é€‰ï¼‰
   - åŒ…æ‹¬å¼ºåº¦=0çš„è¾¹
   - ç”¨äºéªŒè¯"è¾¹ä¸å­˜åœ¨"

2. **{{group}}_causal_paths.csv** (çº¦100-200è¡Œ)
   - æ‰€æœ‰é—´æ¥å› æœè·¯å¾„ï¼ˆ2æ­¥å’Œ3æ­¥ï¼‰
   - ç­›é€‰: path_strength > 0.05
   - ç”¨äºå‘ç°ä¸­ä»‹æ•ˆåº”

3. **{{group}}_causal_edges_0.3.csv** (çº¦42-78è¡Œ)
   - å¼ºç›´æ¥è¾¹ï¼ˆstrength > 0.3ï¼‰
   - å¿«é€ŸæŸ¥çœ‹æœ€é‡è¦çš„å› æœå…³ç³»

4. **{{group}}_causal_paths_0.3.csv** (çº¦0-5è¡Œ)
   - å¼ºé—´æ¥è·¯å¾„ï¼ˆpath_strength > 0.3ï¼‰
   - å‘ç°æå¼ºçš„ä¸­ä»‹æ•ˆåº”

---

## ä½¿ç”¨ç¤ºä¾‹

### Excelå¿«é€ŸæŸ¥çœ‹

1. æ‰“å¼€ `group1_examples_causal_edges_0.3.csv`
2. æŸ¥çœ‹æ‰€æœ‰å¼ºå› æœå…³ç³»ï¼ˆä¸€ç›®äº†ç„¶ï¼‰

### æŸ¥çœ‹è°ƒèŠ‚æ•ˆåº”

```bash
cat group1_examples_causal_edges_all.csv | grep "moderation"
```

### æŸ¥çœ‹é—´æ¥æ•ˆåº”

```bash
cat group1_examples_causal_paths.csv | grep "batch_size"
```

---

## åŸå§‹æ•°æ®ä½ç½®

å®Œæ•´çš„DiBSè¾“å‡ºï¼ˆåŒ…æ‹¬.npyçŸ©é˜µå’Œ.jsonç»“æœï¼‰ä½äºï¼š
`../20260117_000522/`
"""

    with open(output_path / 'README.md', 'w', encoding='utf-8') as f:
        f.write(readme_content)
```

---

## âœ… éªŒè¯æ¸…å•

å®æ–½å‰æ£€æŸ¥ï¼š
- [ ] æ–¹æ¡ˆç¬¦åˆç”¨æˆ·éœ€æ±‚ï¼ˆ4ä¸ªCSVæ–‡ä»¶ï¼‰
- [ ] æ–‡ä»¶å‘½åçº¦å®šæ¸…æ™°
- [ ] åŸå§‹ç›®å½•ä¸è¢«ä¿®æ”¹
- [ ] æ–°ç›®å½•å‘½ååˆç†ï¼ˆ`_readable`åç¼€ï¼‰
- [ ] README.mdè¯´æ˜å®Œæ•´

å®æ–½åæ£€æŸ¥ï¼š
- [ ] 6ç»„ Ã— 4æ–‡ä»¶ = 24ä¸ªCSVç”ŸæˆæˆåŠŸ
- [ ] æ‰€æœ‰CSVæ–‡ä»¶å¯ç”¨Excelæ‰“å¼€
- [ ] `path`åˆ—æ ¼å¼æ­£ç¡®ï¼ˆç®€åŒ–å˜é‡å + ç®­å¤´ï¼‰
- [ ] å¼ºåº¦ç­›é€‰æ­£ç¡®ï¼ˆ0.3é˜ˆå€¼ï¼‰
- [ ] åŸå§‹ç›®å½•æœªè¢«ä¿®æ”¹
- [ ] README.mdç”ŸæˆæˆåŠŸ

---

## ğŸ“Š é¢„æœŸè¾“å‡ºç»Ÿè®¡

| æ–‡ä»¶ç±»å‹ | å¹³å‡è¡Œæ•° | æ–‡ä»¶å¤§å° | æ€»æ•° |
|---------|---------|---------|------|
| causal_edges_all.csv | 529 | ~80 KB | 6 |
| causal_paths.csv | ~150 | ~30 KB | 6 |
| causal_edges_0.3.csv | ~60 | ~10 KB | 6 |
| causal_paths_0.3.csv | ~2 | ~2 KB | 6 |
| README.md | - | ~3 KB | 1 |
| **æ€»è®¡** | - | **~750 KB** | **25** |

---

## ğŸ¯ ä¸v2.0æ–¹æ¡ˆçš„å·®å¼‚

| é¡¹ç›® | v2.0æ–¹æ¡ˆ | v3.0æ–¹æ¡ˆï¼ˆæœ€ç»ˆï¼‰ |
|------|---------|----------------|
| æ–‡ä»¶æ•°é‡ | æ¯ç»„4ä¸ªï¼ˆall + summary.json + npy + pathsï¼‰ | æ¯ç»„4ä¸ªCSV |
| analysis_summary.json | âœ… å¢å¼º | âŒ ä¸ç”Ÿæˆï¼ˆä¿æŒåŸå§‹ï¼‰ |
| å¼ºè¾¹ç­›é€‰æ–‡ä»¶ | âŒ æ—  | âœ… æœ‰ï¼ˆ0.3é˜ˆå€¼ï¼‰ |
| æ–‡ä»¶ä½ç½® | åŸç›®å½• | æ–°ç›®å½•ï¼ˆ_readableï¼‰ |
| åŸå§‹æ–‡ä»¶ä¿®æ”¹ | å¯èƒ½ä¿®æ”¹ | **ä¸ä¿®æ”¹** â­ |

---

## ğŸ“ æ€»ç»“

### æ ¸å¿ƒè¦ç‚¹

âœ… **4ä¸ªCSVæ–‡ä»¶**: edges_all, paths, edges_0.3, paths_0.3
âœ… **ä¸ä¿®æ”¹åŸå§‹**: æ–°å»º`_readable`ç›®å½•
âœ… **å®Œæ•´ä¿¡æ¯**: åŒ…å«æ‰€æœ‰è¾¹ï¼ˆåŒ…æ‹¬å¼ºåº¦=0ï¼‰
âœ… **é—´æ¥è·¯å¾„**: è‡ªåŠ¨å‘ç°ï¼Œ`path`åˆ—ç›´è§‚å±•ç¤º
âœ… **å¿«é€Ÿç­›é€‰**: 0.3é˜ˆå€¼æ–‡ä»¶

### å®æ–½æ­¥éª¤

1. åˆ›å»º `scripts/convert_dibs_to_csv.py` è„šæœ¬
2. å®ç°è¾¹ç”Ÿæˆå’Œè·¯å¾„å‘ç°ç®—æ³•
3. æ‰§è¡Œè½¬æ¢ï¼ˆçº¦5-6å°æ—¶å¼€å‘ + 10åˆ†é’Ÿè¿è¡Œï¼‰
4. éªŒè¯è¾“å‡ºæ–‡ä»¶
5. æäº¤Subagentç‹¬ç«‹æ£€æŸ¥

---

**ä¸‹ä¸€æ­¥**: å¯åŠ¨Subagentæ£€æŸ¥æ–¹æ¡ˆ

#!/usr/bin/env python3

"""
è·¯å¾„æ›´æ–°è„šæœ¬
æ—¥æœŸ: 2026-01-05
ç”¨é€”: è‡ªåŠ¨æ›´æ–°æ‰€æœ‰æ–‡ä»¶ä¸­çš„è·¯å¾„å¼•ç”¨
"""

import os
import re
import sys
from pathlib import Path
from typing import Dict, List, Tuple

# é¡¹ç›®æ ¹ç›®å½•
PROJECT_ROOT = Path("/home/green/energy_dl/nightly")

# è·¯å¾„æ˜ å°„è¡¨
PATH_MAPPINGS = {
    # æ•°æ®æ–‡ä»¶è·¯å¾„
    'results/raw_data.csv': 'data/raw_data.csv',
    'results/data.csv': 'data/data.csv',
    'results/recoverable_energy_data.json': 'data/recoverable_energy_data.json',

    # ç›¸å¯¹è·¯å¾„ï¼ˆä»ä¸åŒå±‚çº§ï¼‰
    '../results/raw_data.csv': '../data/raw_data.csv',
    '../../results/raw_data.csv': '../../data/raw_data.csv',
    '../../../results/raw_data.csv': '../../../data/raw_data.csv',

    '../results/data.csv': '../data/data.csv',
    '../../results/data.csv': '../../data/data.csv',

    # è„šæœ¬è·¯å¾„
    'scripts/validate_raw_data.py': 'tools/data_management/validate_raw_data.py',
    'scripts/analyze_experiment_status.py': 'tools/data_management/analyze_experiment_status.py',
    'scripts/analyze_missing_energy_data.py': 'tools/data_management/analyze_missing_energy_data.py',
    'scripts/repair_missing_energy_data.py': 'tools/data_management/repair_missing_energy_data.py',
    'scripts/verify_recoverable_data.py': 'tools/data_management/verify_recoverable_data.py',
    'scripts/append_session_to_raw_data.py': 'tools/data_management/append_session_to_raw_data.py',
    'scripts/compare_data_vs_raw_data.py': 'tools/data_management/compare_data_vs_raw_data.py',
    'scripts/create_unified_data_csv.py': 'tools/data_management/create_unified_data_csv.py',
    'scripts/generate_mutation_config.py': 'tools/config_management/generate_mutation_config.py',
    'scripts/validate_mutation_config.py': 'tools/config_management/validate_mutation_config.py',
}

# éœ€è¦æ‰«æçš„æ–‡ä»¶ç±»å‹
SCAN_EXTENSIONS = ['.py', '.md', '.sh', '.json', '.txt']

# éœ€è¦æ‰«æçš„ç›®å½•
SCAN_DIRS = [
    'tools',
    'analysis',
    'docs',
    'tests',
    'mutation',
    'settings',
]

# æ’é™¤çš„ç›®å½•
EXCLUDE_DIRS = [
    '__pycache__',
    '.git',
    'repos',
    'archives',
    'environment',
]


class PathUpdater:
    """è·¯å¾„æ›´æ–°å™¨"""

    def __init__(self, root: Path, dry_run: bool = True):
        self.root = root
        self.dry_run = dry_run
        self.updated_files = []
        self.errors = []

    def should_scan_file(self, file_path: Path) -> bool:
        """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦åº”è¯¥æ‰«æ"""
        # æ£€æŸ¥æ‰©å±•å
        if file_path.suffix not in SCAN_EXTENSIONS:
            return False

        # æ£€æŸ¥æ˜¯å¦åœ¨æ’é™¤ç›®å½•ä¸­
        for exclude_dir in EXCLUDE_DIRS:
            if exclude_dir in file_path.parts:
                return False

        return True

    def update_file_paths(self, file_path: Path) -> Tuple[int, List[str]]:
        """æ›´æ–°æ–‡ä»¶ä¸­çš„è·¯å¾„"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
        except Exception as e:
            self.errors.append(f"è¯»å–å¤±è´¥ {file_path}: {e}")
            return 0, []

        original_content = content
        changes = []

        # å¯¹æ¯ä¸ªè·¯å¾„æ˜ å°„è¿›è¡Œæ›¿æ¢
        for old_path, new_path in PATH_MAPPINGS.items():
            # ç›´æ¥å­—ç¬¦ä¸²æ›¿æ¢
            if old_path in content:
                content = content.replace(old_path, new_path)
                changes.append(f"{old_path} â†’ {new_path}")

        # å¦‚æœæœ‰å˜æ›´
        if content != original_content:
            if not self.dry_run:
                try:
                    with open(file_path, 'w', encoding='utf-8') as f:
                        f.write(content)
                except Exception as e:
                    self.errors.append(f"å†™å…¥å¤±è´¥ {file_path}: {e}")
                    return 0, []

            self.updated_files.append(file_path)
            return len(changes), changes

        return 0, []

    def scan_and_update(self) -> None:
        """æ‰«æå¹¶æ›´æ–°æ‰€æœ‰æ–‡ä»¶"""
        print(f"{'[DRY RUN] ' if self.dry_run else ''}å¼€å§‹æ‰«æé¡¹ç›®æ–‡ä»¶...\n")

        total_files = 0
        updated_count = 0

        for scan_dir in SCAN_DIRS:
            dir_path = self.root / scan_dir
            if not dir_path.exists():
                print(f"âš ï¸  ç›®å½•ä¸å­˜åœ¨: {scan_dir}")
                continue

            print(f"ğŸ“ æ‰«æç›®å½•: {scan_dir}/")

            for file_path in dir_path.rglob('*'):
                if not file_path.is_file():
                    continue

                if not self.should_scan_file(file_path):
                    continue

                total_files += 1

                num_changes, changes = self.update_file_paths(file_path)

                if num_changes > 0:
                    updated_count += 1
                    rel_path = file_path.relative_to(self.root)
                    print(f"\nâœ… {rel_path}")
                    for change in changes:
                        print(f"   - {change}")

        # æ˜¾ç¤ºæ€»ç»“
        print("\n" + "="*60)
        print("æ€»ç»“")
        print("="*60)
        print(f"æ‰«ææ–‡ä»¶æ•°: {total_files}")
        print(f"æ›´æ–°æ–‡ä»¶æ•°: {updated_count}")

        if self.errors:
            print(f"\nâŒ é”™è¯¯æ•°: {len(self.errors)}")
            for error in self.errors:
                print(f"   - {error}")

        if self.dry_run:
            print("\nâš ï¸  è¿™æ˜¯DRY RUNæ¨¡å¼ï¼Œæœªå®é™…ä¿®æ”¹æ–‡ä»¶")
            print("   ä½¿ç”¨ --execute å‚æ•°æ¥å®é™…æ‰§è¡Œä¿®æ”¹")
        else:
            print("\nâœ… æ‰€æœ‰æ–‡ä»¶å·²æ›´æ–°ï¼")

    def generate_report(self) -> str:
        """ç”Ÿæˆæ›´æ–°æŠ¥å‘Š"""
        report = []
        report.append("# è·¯å¾„æ›´æ–°æŠ¥å‘Š\n")
        report.append(f"**æ—¥æœŸ**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        report.append(f"**æ¨¡å¼**: {'DRY RUN' if self.dry_run else 'EXECUTE'}\n")
        report.append("\n## æ›´æ–°çš„æ–‡ä»¶åˆ—è¡¨\n")

        for file_path in self.updated_files:
            rel_path = file_path.relative_to(self.root)
            report.append(f"- {rel_path}\n")

        if self.errors:
            report.append("\n## é”™è¯¯åˆ—è¡¨\n")
            for error in self.errors:
                report.append(f"- {error}\n")

        return ''.join(report)


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    from datetime import datetime

    parser = argparse.ArgumentParser(description='æ›´æ–°é¡¹ç›®æ–‡ä»¶ä¸­çš„è·¯å¾„å¼•ç”¨')
    parser.add_argument('--execute', action='store_true',
                       help='å®é™…æ‰§è¡Œä¿®æ”¹ï¼ˆé»˜è®¤ä¸ºdry-runï¼‰')
    parser.add_argument('--report', type=str,
                       help='ä¿å­˜æŠ¥å‘Šåˆ°æŒ‡å®šæ–‡ä»¶')

    args = parser.parse_args()

    # åˆ›å»ºæ›´æ–°å™¨
    updater = PathUpdater(PROJECT_ROOT, dry_run=not args.execute)

    # æ‰§è¡Œæ‰«æå’Œæ›´æ–°
    updater.scan_and_update()

    # ç”ŸæˆæŠ¥å‘Š
    if args.report:
        report = updater.generate_report()
        report_path = PROJECT_ROOT / args.report
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report)
        print(f"\nğŸ“„ æŠ¥å‘Šå·²ä¿å­˜: {report_path}")

    # è¿”å›çŠ¶æ€ç 
    return 0 if not updater.errors else 1


if __name__ == '__main__':
    sys.exit(main())

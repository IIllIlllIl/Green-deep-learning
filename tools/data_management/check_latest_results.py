#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ£€æŸ¥æœ€æ–°å®éªŒç»“æœæ˜¯å¦å®Œå…¨åŠ å…¥æ•°æ®æ–‡ä»¶

åŠŸèƒ½:
- æ£€æŸ¥è¿è¡Œç›®å½•ä¸­çš„å®éªŒ(experiment.json)æ˜¯å¦åœ¨ raw_data.csv ä¸­
- éªŒè¯æ•°æ®å±æ€§å®Œæ•´æ€§
- ç”Ÿæˆè¯¦ç»†æ£€æŸ¥æŠ¥å‘Š
"""

import csv
import os
import json
from pathlib import Path
from collections import defaultdict

def load_experiment_ids_from_csv(csv_file):
    """ä»CSVæ–‡ä»¶åŠ è½½æ‰€æœ‰experiment_id"""
    exp_ids = set()
    with open(csv_file, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        for row in reader:
            exp_id = row.get('experiment_id', '').strip()
            if exp_id:
                exp_ids.add(exp_id)
    return exp_ids

def get_experiment_json_files(run_dir):
    """è·å–è¿è¡Œç›®å½•ä¸­æ‰€æœ‰experiment.jsonæ–‡ä»¶"""
    experiment_files = []
    run_path = Path(run_dir)

    if not run_path.exists():
        return experiment_files

    for exp_dir in run_path.iterdir():
        if exp_dir.is_dir():
            exp_json = exp_dir / "experiment.json"
            if exp_json.exists():
                experiment_files.append((exp_dir.name, exp_json))

    return experiment_files

def load_experiment_json(json_file):
    """åŠ è½½experiment.jsonæ–‡ä»¶"""
    try:
        with open(json_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        return data
    except Exception as e:
        print(f"   âš ï¸  è¯»å–å¤±è´¥: {e}")
        return None

def check_parallel_experiment(exp_dir):
    """æ£€æŸ¥æ˜¯å¦æ˜¯å¹¶è¡Œå®éªŒï¼Œå¹¶è·å–å‰åå°æ•°æ®"""
    fg_json = exp_dir / "foreground" / "experiment.json"
    bg_json = exp_dir / "background" / "experiment.json"

    is_parallel = fg_json.exists() or bg_json.exists()

    fg_data = None
    bg_data = None

    if fg_json.exists():
        fg_data = load_experiment_json(fg_json)

    if bg_json.exists():
        bg_data = load_experiment_json(bg_json)

    return is_parallel, fg_data, bg_data

def main():
    base_dir = Path(__file__).parent.parent
    raw_data_csv = base_dir / "results" / "raw_data.csv"

    # æŸ¥æ‰¾æœ€æ–°çš„è¿è¡Œç›®å½•
    results_dir = base_dir / "results"
    run_dirs = sorted([d for d in results_dir.iterdir() if d.is_dir() and d.name.startswith('run_')],
                     key=lambda x: x.stat().st_mtime, reverse=True)

    if not run_dirs:
        print("âŒ æœªæ‰¾åˆ°è¿è¡Œç›®å½•")
        return

    latest_run_dir = run_dirs[0]

    print("=" * 80)
    print("ğŸ” æ£€æŸ¥æœ€æ–°å®éªŒç»“æœæ˜¯å¦å®Œå…¨åŠ å…¥æ•°æ®æ–‡ä»¶")
    print("=" * 80)
    print(f"\næœ€æ–°è¿è¡Œç›®å½•: {latest_run_dir.name}")
    print(f"è¿è¡Œç›®å½•æœ€åä¿®æ”¹æ—¶é—´: {latest_run_dir.stat().st_mtime}")
    print(f"Raw dataæ–‡ä»¶: {raw_data_csv}")

    # 1. åŠ è½½CSVä¸­çš„experiment_id
    print("\n[1/5] åŠ è½½ raw_data.csv ä¸­çš„å®éªŒID...")
    csv_exp_ids = load_experiment_ids_from_csv(raw_data_csv)
    print(f"   raw_data.csv ä¸­å…±æœ‰ {len(csv_exp_ids)} ä¸ªå®éªŒID")

    # 2. è·å–è¿è¡Œç›®å½•ä¸­çš„æ‰€æœ‰å®éªŒç›®å½•
    print("\n[2/5] æ‰«æè¿è¡Œç›®å½•ä¸­çš„å®éªŒ...")

    all_exp_dirs = sorted([d for d in latest_run_dir.iterdir() if d.is_dir()])
    print(f"   è¿è¡Œç›®å½•ä¸­å…±æœ‰ {len(all_exp_dirs)} ä¸ªå®éªŒç›®å½•")

    # 3. æ£€æŸ¥æ¯ä¸ªå®éªŒç›®å½•
    print("\n[3/5] æ£€æŸ¥å®éªŒç±»å‹å’Œæ•°æ®...")

    non_parallel_exps = []
    parallel_exps = []
    unknown_exps = []

    for exp_dir in all_exp_dirs:
        exp_json = exp_dir / "experiment.json"

        # æ£€æŸ¥æ˜¯å¦æ˜¯å¹¶è¡Œå®éªŒ
        is_parallel, fg_data, bg_data = check_parallel_experiment(exp_dir)

        if is_parallel:
            parallel_exps.append({
                'dir_name': exp_dir.name,
                'fg_data': fg_data,
                'bg_data': bg_data
            })
        elif exp_json.exists():
            data = load_experiment_json(exp_json)
            if data:
                non_parallel_exps.append({
                    'dir_name': exp_dir.name,
                    'data': data
                })
            else:
                unknown_exps.append(exp_dir.name)
        else:
            unknown_exps.append(exp_dir.name)

    print(f"   éå¹¶è¡Œå®éªŒ: {len(non_parallel_exps)}")
    print(f"   å¹¶è¡Œå®éªŒ: {len(parallel_exps)}")
    print(f"   æœªçŸ¥ç±»å‹: {len(unknown_exps)}")

    # 4. æ£€æŸ¥æ˜¯å¦åœ¨CSVä¸­
    print("\n[4/5] æ£€æŸ¥å®éªŒæ˜¯å¦å·²åŠ å…¥CSV...")

    missing_non_parallel = []
    missing_parallel = []

    for exp in non_parallel_exps:
        exp_id = exp['data'].get('experiment_id', '')
        if exp_id not in csv_exp_ids:
            missing_non_parallel.append(exp)

    for exp in parallel_exps:
        # å¹¶è¡Œå®éªŒçš„IDé€šå¸¸æ˜¯ç›®å½•å
        exp_id = exp['dir_name']
        if exp_id not in csv_exp_ids:
            # ä¹Ÿæ£€æŸ¥å‰å°æ•°æ®çš„ID
            if exp['fg_data']:
                fg_exp_id = exp['fg_data'].get('experiment_id', '')
                if fg_exp_id not in csv_exp_ids:
                    missing_parallel.append(exp)
            else:
                missing_parallel.append(exp)

    # 5. ç”ŸæˆæŠ¥å‘Š
    print("\n[5/5] ç”Ÿæˆæ£€æŸ¥æŠ¥å‘Š...")
    print("\n" + "=" * 80)
    print("ğŸ“Š æ£€æŸ¥æŠ¥å‘Š")
    print("=" * 80)

    print(f"\nè¿è¡Œç›®å½•ä¸­çš„å®éªŒæ€»æ•°: {len(all_exp_dirs)}")
    print(f"  - éå¹¶è¡Œå®éªŒ: {len(non_parallel_exps)}")
    print(f"  - å¹¶è¡Œå®éªŒ: {len(parallel_exps)}")
    print(f"  - æœªçŸ¥ç±»å‹: {len(unknown_exps)}")

    print(f"\nCSVä¸­å·²æœ‰çš„å®éªŒæ•°: {len(csv_exp_ids)}")

    print(f"\nç¼ºå¤±çš„å®éªŒæ•°:")
    print(f"  - éå¹¶è¡Œ: {len(missing_non_parallel)}")
    print(f"  - å¹¶è¡Œ: {len(missing_parallel)}")
    print(f"  - æ€»è®¡: {len(missing_non_parallel) + len(missing_parallel)}")

    if missing_non_parallel:
        print("\n" + "=" * 80)
        print("âŒ ä»¥ä¸‹éå¹¶è¡Œå®éªŒæœªåŠ å…¥ raw_data.csv:")
        print("=" * 80)

        for i, exp in enumerate(missing_non_parallel[:20], 1):
            data = exp['data']
            exp_id = data.get('experiment_id', 'N/A')
            repo = data.get('repository', 'N/A')
            model = data.get('model', 'N/A')
            success = data.get('training_success', False)
            has_energy = bool(data.get('energy_metrics', {}).get('cpu_energy_total_joules'))

            print(f"\n{i}. {exp_id}")
            print(f"   æ¨¡å‹: {repo}/{model}")
            print(f"   è®­ç»ƒæˆåŠŸ: {success}")
            print(f"   æœ‰èƒ½è€—æ•°æ®: {has_energy}")

        if len(missing_non_parallel) > 20:
            print(f"\n   ... è¿˜æœ‰ {len(missing_non_parallel) - 20} ä¸ªå®éªŒæœªæ˜¾ç¤º")

    if missing_parallel:
        print("\n" + "=" * 80)
        print("âŒ ä»¥ä¸‹å¹¶è¡Œå®éªŒæœªåŠ å…¥ raw_data.csv:")
        print("=" * 80)

        for i, exp in enumerate(missing_parallel[:20], 1):
            dir_name = exp['dir_name']
            fg_data = exp['fg_data']
            bg_data = exp['bg_data']

            print(f"\n{i}. {dir_name}")
            if fg_data:
                print(f"   å‰å°: {fg_data.get('repository', 'N/A')}/{fg_data.get('model', 'N/A')}")
                print(f"   å‰å°æˆåŠŸ: {fg_data.get('training_success', False)}")
            if bg_data:
                print(f"   åå°: {bg_data.get('repository', 'N/A')}/{bg_data.get('model', 'N/A')}")

        if len(missing_parallel) > 20:
            print(f"\n   ... è¿˜æœ‰ {len(missing_parallel) - 20} ä¸ªå®éªŒæœªæ˜¾ç¤º")

    # æ£€æŸ¥æ•°æ®å±æ€§
    print("\n" + "=" * 80)
    print("ğŸ“‹ æ•°æ®å±æ€§å®Œæ•´æ€§æ£€æŸ¥")
    print("=" * 80)

    if non_parallel_exps:
        # æ£€æŸ¥ä¸€ä¸ªéå¹¶è¡Œå®éªŒçš„å±æ€§
        sample_data = non_parallel_exps[0]['data']
        print(f"\néå¹¶è¡Œå®éªŒæ•°æ®ç»“æ„ (ä»¥ {non_parallel_exps[0]['dir_name']} ä¸ºä¾‹):")
        print(f"  æ ¹å±æ€§: {list(sample_data.keys())}")
        if 'hyperparameters' in sample_data:
            print(f"  è¶…å‚æ•°: {list(sample_data['hyperparameters'].keys())}")
        if 'energy_metrics' in sample_data:
            print(f"  èƒ½è€—æŒ‡æ ‡: {list(sample_data['energy_metrics'].keys())}")
        if 'performance_metrics' in sample_data:
            print(f"  æ€§èƒ½æŒ‡æ ‡: {list(sample_data['performance_metrics'].keys())}")

    if parallel_exps:
        sample_exp = parallel_exps[0]
        print(f"\nå¹¶è¡Œå®éªŒæ•°æ®ç»“æ„ (ä»¥ {sample_exp['dir_name']} ä¸ºä¾‹):")
        if sample_exp['fg_data']:
            print(f"  å‰å°æ•°æ®å±æ€§: {list(sample_exp['fg_data'].keys())}")
        if sample_exp['bg_data']:
            print(f"  åå°æ•°æ®å±æ€§: {list(sample_exp['bg_data'].keys())}")

    # æ€»ç»“
    print("\n" + "=" * 80)
    print("ğŸ“ˆ æ€»ç»“")
    print("=" * 80)

    total_missing = len(missing_non_parallel) + len(missing_parallel)

    if total_missing > 0:
        print(f"\nâš ï¸  å‘ç° {total_missing} ä¸ªå®éªŒæœªåŠ å…¥ raw_data.csv")
        print(f"   è¿è¡Œç›®å½•: {latest_run_dir.name}")
        print(f"\nå»ºè®®æ“ä½œ:")
        print(f"   1. æ£€æŸ¥è¿™äº›å®éªŒçš„ experiment.json æ˜¯å¦æœ‰æ•ˆ")
        print(f"   2. ä½¿ç”¨æ•°æ®æå–è„šæœ¬å°† JSON è½¬æ¢ä¸º session_data.csv")
        print(f"   3. ä½¿ç”¨ tools/data_management/append_session_to_raw_data.py æ·»åŠ åˆ° raw_data.csv")
    else:
        print("\nâœ… æ‰€æœ‰å®éªŒéƒ½å·²åŠ å…¥ raw_data.csv")

    print("\nâœ… æ£€æŸ¥å®Œæˆ!")

if __name__ == "__main__":
    main()

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åˆ†ææ•°æ®åœ¨6åˆ†ç»„å›å½’åˆ†æä¸‹çš„å¯ç”¨æ€§

æ ¹æ® analysis/docs/QUESTION1_REGRESSION_ANALYSIS_PLAN.md ä¸­å®šä¹‰çš„6åˆ†ç»„æ–¹æ¡ˆï¼Œ
åˆ†æå½“å‰æ•°æ®é›†ä¸­å“ªäº›æ•°æ®å¯ç”¨ã€å“ªäº›ä¸å¯ç”¨ã€‚

6åˆ†ç»„å®šä¹‰ï¼š
- ç»„1a: examples (mnist, mnist_ff, mnist_rnn, siamese)
- ç»„1b: pytorch_resnet (resnet20)
- ç»„2: Person_reID (densenet121, hrnet18, pcb)
- ç»„3: VulBERTa (mlp)
- ç»„4: bug_localization (default)
- ç»„5: MRT-OAST (default)

å¯ç”¨æ€§æ ‡å‡†ï¼š
1. è®­ç»ƒæˆåŠŸ (training_success = True)
2. æœ‰èƒ½è€—æ•°æ®ï¼ˆè‡³å°‘ä¸€ä¸ªèƒ½è€—å­—æ®µéç©ºï¼‰
3. æœ‰è¶…å‚æ•°æ•°æ®ï¼ˆç»„å†…éœ€è¦çš„è¶…å‚æ•°å­—æ®µéç©ºï¼‰
æ³¨æ„ï¼šä¸éœ€è¦æ€§èƒ½æŒ‡æ ‡æ•°æ®
"""

import csv
from collections import defaultdict
from typing import Dict, List, Tuple

# 6åˆ†ç»„å®šä¹‰
GROUP_DEFINITIONS = {
    'group1a_examples': {
        'models': [
            'examples/mnist',
            'examples/mnist_ff',
            'examples/mnist_rnn',
            'examples/siamese'
        ],
        'hyperparams': ['hyperparam_batch_size', 'hyperparam_epochs', 'hyperparam_learning_rate', 'hyperparam_seed']
    },
    'group1b_resnet': {
        'models': ['pytorch_resnet_cifar10/resnet20'],
        'hyperparams': ['hyperparam_epochs', 'hyperparam_learning_rate', 'hyperparam_weight_decay', 'hyperparam_seed']
    },
    'group2_person_reid': {
        'models': [
            'Person_reID_baseline_pytorch/densenet121',
            'Person_reID_baseline_pytorch/hrnet18',
            'Person_reID_baseline_pytorch/pcb'
        ],
        'hyperparams': ['hyperparam_dropout', 'hyperparam_epochs', 'hyperparam_learning_rate', 'hyperparam_seed']
    },
    'group3_vulberta': {
        'models': ['VulBERTa/mlp'],
        'hyperparams': ['hyperparam_epochs', 'hyperparam_learning_rate', 'hyperparam_weight_decay', 'hyperparam_seed']
    },
    'group4_bug_localization': {
        'models': ['bug-localization-by-dnn-and-rvsm/default'],
        'hyperparams': ['hyperparam_alpha', 'hyperparam_kfold', 'hyperparam_max_iter', 'hyperparam_seed']
    },
    'group5_mrt_oast': {
        'models': ['MRT-OAST/default'],
        'hyperparams': ['hyperparam_dropout', 'hyperparam_epochs', 'hyperparam_learning_rate', 'hyperparam_weight_decay']
    }
}

# èƒ½è€—å­—æ®µï¼ˆè‡³å°‘ä¸€ä¸ªæœ‰å€¼å³å¯ï¼‰
ENERGY_FIELDS = [
    'energy_cpu_pkg_joules',
    'energy_cpu_ram_joules',
    'energy_cpu_total_joules',
    'energy_gpu_total_joules',
    'energy_gpu_avg_watts'
]


def get_model_identifier(row: Dict[str, str]) -> str:
    """è·å–æ¨¡å‹æ ‡è¯†ç¬¦"""
    repo = row.get('repository', '').strip()
    model = row.get('model', '').strip()
    if not repo or repo == '/':
        return 'unknown'
    return f"{repo}/{model}" if model else repo


def has_energy_data(row: Dict[str, str]) -> bool:
    """æ£€æŸ¥æ˜¯å¦æœ‰èƒ½è€—æ•°æ®"""
    for field in ENERGY_FIELDS:
        value = row.get(field, '').strip()
        if value and value != 'N/A' and value != '0' and value != '0.0':
            return True
    return False


def check_hyperparams(row: Dict[str, str], required_params: List[str]) -> Tuple[bool, List[str]]:
    """
    æ£€æŸ¥è¶…å‚æ•°æ˜¯å¦å®Œæ•´

    è¿”å›: (æ˜¯å¦å…¨éƒ¨æœ‰å€¼, ç¼ºå¤±çš„å‚æ•°åˆ—è¡¨)
    """
    missing = []
    for param in required_params:
        value = row.get(param, '').strip()
        if not value or value == 'N/A':
            missing.append(param)

    return len(missing) == 0, missing


def analyze_group_usability(csv_file: str = 'data/raw_data.csv'):
    """åˆ†æ6åˆ†ç»„ä¸‹çš„æ•°æ®å¯ç”¨æ€§"""

    print("=" * 100)
    print("6åˆ†ç»„å›å½’åˆ†ææ•°æ®å¯ç”¨æ€§åˆ†æ")
    print("=" * 100)
    print()
    print(f"æ•°æ®æ–‡ä»¶: {csv_file}")
    print()

    # è¯»å–æ•°æ®
    with open(csv_file, 'r') as f:
        reader = csv.DictReader(f)
        rows = list(reader)

    total_records = len(rows)
    print(f"æ€»è®°å½•æ•°: {total_records}")
    print()

    # æŒ‰ç»„åˆ†æ
    group_stats = {}
    usable_records = defaultdict(list)
    unusable_records = defaultdict(list)

    # è®°å½•æ¯ä¸ªæ¨¡å‹çš„æ•°æ®
    for row in rows:
        model_id = get_model_identifier(row)
        training_success = row.get('training_success', '').strip() == 'True'
        has_energy = has_energy_data(row)

        # æ‰¾åˆ°æ‰€å±çš„ç»„
        group_name = None
        required_params = None
        for gname, gdef in GROUP_DEFINITIONS.items():
            if model_id in gdef['models']:
                group_name = gname
                required_params = gdef['hyperparams']
                break

        if not group_name:
            continue  # ä¸åœ¨6åˆ†ç»„ä¸­çš„æ¨¡å‹ï¼Œè·³è¿‡

        # æ£€æŸ¥è¶…å‚æ•°
        has_all_params, missing_params = check_hyperparams(row, required_params)

        # åˆ¤æ–­æ˜¯å¦å¯ç”¨
        is_usable = training_success and has_energy and has_all_params

        record_info = {
            'experiment_id': row.get('experiment_id', ''),
            'model': model_id,
            'training_success': training_success,
            'has_energy': has_energy,
            'has_all_params': has_all_params,
            'missing_params': missing_params
        }

        if is_usable:
            usable_records[group_name].append(record_info)
        else:
            unusable_records[group_name].append(record_info)

    # ç»Ÿè®¡æ¯ç»„çš„å¯ç”¨æ€§
    print("=" * 100)
    print("ğŸ“Š å„ç»„æ•°æ®å¯ç”¨æ€§ç»Ÿè®¡")
    print("=" * 100)
    print()

    total_usable = 0
    total_in_groups = 0

    for group_name, group_def in GROUP_DEFINITIONS.items():
        usable_count = len(usable_records[group_name])
        unusable_count = len(unusable_records[group_name])
        total_count = usable_count + unusable_count
        usable_rate = (usable_count / total_count * 100) if total_count > 0 else 0

        total_usable += usable_count
        total_in_groups += total_count

        group_stats[group_name] = {
            'total': total_count,
            'usable': usable_count,
            'unusable': unusable_count,
            'usable_rate': usable_rate
        }

        print(f"{group_name}:")
        print(f"  æ¨¡å‹: {', '.join(group_def['models'])}")
        print(f"  éœ€è¦çš„è¶…å‚æ•°: {', '.join(group_def['hyperparams'])}")
        print(f"  æ€»è®°å½•æ•°: {total_count}")
        print(f"  âœ… å¯ç”¨è®°å½•: {usable_count} ({usable_rate:.1f}%)")
        print(f"  âŒ ä¸å¯ç”¨è®°å½•: {unusable_count} ({100-usable_rate:.1f}%)")
        print()

    # æ€»ä½“ç»Ÿè®¡
    print("=" * 100)
    print("ğŸ“ˆ æ€»ä½“ç»Ÿè®¡")
    print("=" * 100)
    print()
    print(f"6åˆ†ç»„è¦†ç›–çš„è®°å½•æ•°: {total_in_groups}")
    print(f"âœ… å¯ç”¨è®°å½•æ€»æ•°: {total_usable} ({total_usable/total_in_groups*100:.1f}%)")
    print(f"âŒ ä¸å¯ç”¨è®°å½•æ€»æ•°: {total_in_groups - total_usable} ({(total_in_groups - total_usable)/total_in_groups*100:.1f}%)")
    print()

    # ä¸å¯ç”¨åŸå› åˆ†æ
    print("=" * 100)
    print("ğŸ” ä¸å¯ç”¨åŸå› è¯¦ç»†åˆ†æ")
    print("=" * 100)
    print()

    for group_name in GROUP_DEFINITIONS.keys():
        unusable = unusable_records[group_name]
        if not unusable:
            continue

        print(f"\n{group_name} - ä¸å¯ç”¨è®°å½•: {len(unusable)}æ¡")
        print("-" * 80)

        # ç»Ÿè®¡ä¸å¯ç”¨åŸå› 
        reasons = defaultdict(int)
        for rec in unusable:
            if not rec['training_success']:
                reasons['è®­ç»ƒå¤±è´¥'] += 1
            if not rec['has_energy']:
                reasons['èƒ½è€—æ•°æ®ç¼ºå¤±'] += 1
            if not rec['has_all_params']:
                reasons['è¶…å‚æ•°ç¼ºå¤±'] += 1

        print(f"  ä¸å¯ç”¨åŸå› ç»Ÿè®¡:")
        for reason, count in sorted(reasons.items(), key=lambda x: -x[1]):
            print(f"    - {reason}: {count}æ¡")

        # è¶…å‚æ•°ç¼ºå¤±è¯¦æƒ…
        param_missing_stats = defaultdict(int)
        for rec in unusable:
            if not rec['has_all_params']:
                for param in rec['missing_params']:
                    param_missing_stats[param] += 1

        if param_missing_stats:
            print(f"\n  è¶…å‚æ•°ç¼ºå¤±è¯¦æƒ…:")
            for param, count in sorted(param_missing_stats.items(), key=lambda x: -x[1]):
                print(f"    - {param}: {count}æ¡è®°å½•ç¼ºå¤±")

    # ä¿å­˜ç»“æœ
    print("\n" + "=" * 100)
    print("ğŸ’¾ ä¿å­˜åˆ†æç»“æœ")
    print("=" * 100)
    print()

    # ä¿å­˜å¯ç”¨è®°å½•ç»Ÿè®¡
    with open('data_usability_for_regression_summary.txt', 'w') as f:
        f.write("6åˆ†ç»„å›å½’åˆ†ææ•°æ®å¯ç”¨æ€§æ‘˜è¦\n")
        f.write("=" * 80 + "\n\n")

        f.write(f"æ€»è®°å½•æ•°: {total_records}\n")
        f.write(f"6åˆ†ç»„è¦†ç›–çš„è®°å½•æ•°: {total_in_groups}\n")
        f.write(f"å¯ç”¨è®°å½•æ€»æ•°: {total_usable} ({total_usable/total_in_groups*100:.1f}%)\n\n")

        f.write("å„ç»„ç»Ÿè®¡:\n")
        f.write("-" * 80 + "\n")
        for group_name, stats in group_stats.items():
            f.write(f"\n{group_name}:\n")
            f.write(f"  æ€»æ•°: {stats['total']}\n")
            f.write(f"  å¯ç”¨: {stats['usable']} ({stats['usable_rate']:.1f}%)\n")
            f.write(f"  ä¸å¯ç”¨: {stats['unusable']} ({100-stats['usable_rate']:.1f}%)\n")

    print("âœ… æ‘˜è¦å·²ä¿å­˜: data_usability_for_regression_summary.txt")

    # ä¿å­˜è¯¦ç»†çš„ä¸å¯ç”¨è®°å½•
    with open('unusable_records_for_regression_detail.csv', 'w', newline='') as f:
        writer = csv.writer(f)
        writer.writerow(['Group', 'Experiment_ID', 'Model', 'Training_Success', 'Has_Energy', 'Has_All_Params', 'Missing_Params'])

        for group_name in GROUP_DEFINITIONS.keys():
            for rec in unusable_records[group_name]:
                writer.writerow([
                    group_name,
                    rec['experiment_id'],
                    rec['model'],
                    rec['training_success'],
                    rec['has_energy'],
                    rec['has_all_params'],
                    ', '.join(rec['missing_params']) if rec['missing_params'] else ''
                ])

    print("âœ… è¯¦ç»†ä¸å¯ç”¨è®°å½•å·²ä¿å­˜: unusable_records_for_regression_detail.csv")
    print()


if __name__ == '__main__':
    analyze_group_usability()

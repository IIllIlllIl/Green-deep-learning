#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ·±å…¥åˆ†æä¸å¯ç”¨æ•°æ®çš„å…·ä½“åŸå› 

é‡ç‚¹åˆ†ææ€§èƒ½æŒ‡æ ‡ç¼ºå¤±å’Œè®­ç»ƒå¤±è´¥çš„å…·ä½“æƒ…å†µ
"""

import csv
from collections import defaultdict

def is_empty(val):
    """æ£€æŸ¥å€¼æ˜¯å¦ä¸ºç©º"""
    return val == '' or val is None

def get_mode(row):
    """è·å–å®éªŒæ¨¡å¼"""
    mode = row.get('mode', '')
    if is_empty(mode):
        if not is_empty(row.get('fg_repository')):
            return 'parallel'
        else:
            return 'non-parallel'
    return mode

def main():
    data_file = "data/raw_data.csv"

    print("=" * 100)
    print("ğŸ” ä¸å¯ç”¨æ•°æ®æ·±å…¥åˆ†æ")
    print("=" * 100)
    print(f"\næ•°æ®æ–‡ä»¶: {data_file}\n")

    # è¯»å–æ•°æ®
    with open(data_file, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        rows = list(reader)

    total_rows = len(rows)

    # ===== 1. åˆ†ææ€§èƒ½æŒ‡æ ‡ç¼ºå¤±çš„è®°å½• =====
    print("=" * 100)
    print("ğŸ“Š æ€§èƒ½æŒ‡æ ‡ç¼ºå¤±è¯¦ç»†åˆ†æ")
    print("=" * 100)

    perf_missing_records = []

    for row in rows:
        mode = get_mode(row)

        # æ£€æŸ¥æ€§èƒ½æŒ‡æ ‡
        if mode == 'parallel':
            perf_fields = [
                'fg_perf_accuracy', 'fg_perf_test_accuracy', 'fg_perf_map',
                'fg_perf_precision', 'fg_perf_recall', 'fg_perf_best_val_accuracy'
            ]
            repo = row.get('fg_repository', 'unknown')
            model = row.get('fg_model', 'unknown')
        else:
            perf_fields = [
                'perf_accuracy', 'perf_test_accuracy', 'perf_map',
                'perf_precision', 'perf_recall', 'perf_best_val_accuracy',
                'perf_top1_accuracy', 'perf_top5_accuracy'
            ]
            repo = row.get('repository', 'unknown')
            model = row.get('model', 'unknown')

        # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰æ€§èƒ½å­—æ®µéƒ½ä¸ºç©º
        has_perf = any(not is_empty(row.get(field)) for field in perf_fields)

        if not has_perf:
            perf_missing_records.append({
                'experiment_id': row.get('experiment_id', 'N/A'),
                'repo': repo,
                'model': model,
                'mode': mode,
                'training_success': row.get('fg_training_success' if mode == 'parallel' else 'training_success', ''),
                'has_energy': not is_empty(row.get('fg_energy_cpu_total_joules' if mode == 'parallel' else 'energy_cpu_total_joules')),
                'timestamp': row.get('timestamp', 'N/A'),
                'error_message': row.get('fg_error_message' if mode == 'parallel' else 'error_message', '')
            })

    print(f"\næ€§èƒ½æŒ‡æ ‡ç¼ºå¤±çš„è®°å½•æ•°: {len(perf_missing_records)} ({len(perf_missing_records)*100/total_rows:.1f}%)")

    # æŒ‰æ¨¡å‹ç»Ÿè®¡
    perf_missing_by_model = defaultdict(lambda: {'count': 0, 'training_success': 0, 'training_failed': 0, 'has_energy': 0})

    for record in perf_missing_records:
        model_key = f"{record['repo']}/{record['model']}"
        perf_missing_by_model[model_key]['count'] += 1

        if record['training_success'] == 'True':
            perf_missing_by_model[model_key]['training_success'] += 1
        else:
            perf_missing_by_model[model_key]['training_failed'] += 1

        if record['has_energy']:
            perf_missing_by_model[model_key]['has_energy'] += 1

    print(f"\n{'æ¨¡å‹':<50} {'æ€»ç¼ºå¤±':<10} {'è®­ç»ƒæˆåŠŸ':<12} {'è®­ç»ƒå¤±è´¥':<12} {'æœ‰èƒ½è€—':<10}")
    print("-" * 100)

    for model_key in sorted(perf_missing_by_model.keys(), key=lambda x: perf_missing_by_model[x]['count'], reverse=True):
        stats = perf_missing_by_model[model_key]
        print(f"{model_key:<50} {stats['count']:<10} {stats['training_success']:<12} "
              f"{stats['training_failed']:<12} {stats['has_energy']:<10}")

    # ===== 2. åˆ†æè®­ç»ƒå¤±è´¥çš„è®°å½• =====
    print("\n" + "=" * 100)
    print("âš ï¸  è®­ç»ƒå¤±è´¥è¯¦ç»†åˆ†æ")
    print("=" * 100)

    training_failed_records = []

    for row in rows:
        mode = get_mode(row)

        if mode == 'parallel':
            training_success = row.get('fg_training_success', '') == 'True'
            repo = row.get('fg_repository', 'unknown')
            model = row.get('fg_model', 'unknown')
            error_msg = row.get('fg_error_message', '')
        else:
            training_success = row.get('training_success', '') == 'True'
            repo = row.get('repository', 'unknown')
            model = row.get('model', 'unknown')
            error_msg = row.get('error_message', '')

        if not training_success:
            training_failed_records.append({
                'experiment_id': row.get('experiment_id', 'N/A'),
                'repo': repo,
                'model': model,
                'mode': mode,
                'timestamp': row.get('timestamp', 'N/A'),
                'error_message': error_msg
            })

    print(f"\nè®­ç»ƒå¤±è´¥çš„è®°å½•æ•°: {len(training_failed_records)} ({len(training_failed_records)*100/total_rows:.1f}%)")

    # æŒ‰æ¨¡å‹ç»Ÿè®¡
    failed_by_model = defaultdict(int)
    for record in training_failed_records:
        model_key = f"{record['repo']}/{record['model']}"
        failed_by_model[model_key] += 1

    print(f"\n{'æ¨¡å‹':<50} {'å¤±è´¥æ¬¡æ•°':<12} {'å¤±è´¥ç‡':<10}")
    print("-" * 75)

    for model_key in sorted(failed_by_model.keys(), key=lambda x: failed_by_model[x], reverse=True):
        count = failed_by_model[model_key]
        # è®¡ç®—è¯¥æ¨¡å‹çš„æ€»å®éªŒæ•°
        total_for_model = sum(1 for row in rows
                             if f"{row.get('repository', '')}/{row.get('model', '')}" == model_key
                             or f"{row.get('fg_repository', '')}/{row.get('fg_model', '')}" == model_key)
        failure_rate = count * 100 / total_for_model if total_for_model > 0 else 0
        print(f"{model_key:<50} {count:<12} {failure_rate:.1f}%")

    # æŸ¥çœ‹é”™è¯¯æ¶ˆæ¯
    print(f"\nè®­ç»ƒå¤±è´¥çš„é”™è¯¯æ¶ˆæ¯ç¤ºä¾‹ï¼ˆå‰10ä¸ªï¼‰:")
    print("-" * 100)

    for i, record in enumerate(training_failed_records[:10], 1):
        print(f"\n{i}. {record['experiment_id']}")
        print(f"   æ¨¡å‹: {record['repo']}/{record['model']}")
        print(f"   æ¨¡å¼: {record['mode']}")
        error_msg = record['error_message'][:200] if record['error_message'] else "æ— é”™è¯¯æ¶ˆæ¯"
        print(f"   é”™è¯¯: {error_msg}")

    # ===== 3. åˆ†æèƒ½è€—æ•°æ®ç¼ºå¤±çš„è®°å½• =====
    print("\n" + "=" * 100)
    print("âš¡ èƒ½è€—æ•°æ®ç¼ºå¤±è¯¦ç»†åˆ†æ")
    print("=" * 100)

    energy_missing_records = []

    for row in rows:
        mode = get_mode(row)

        if mode == 'parallel':
            has_energy = not is_empty(row.get('fg_energy_cpu_total_joules'))
            repo = row.get('fg_repository', 'unknown')
            model = row.get('fg_model', 'unknown')
            training_success = row.get('fg_training_success', '') == 'True'
        else:
            has_energy = not is_empty(row.get('energy_cpu_total_joules'))
            repo = row.get('repository', 'unknown')
            model = row.get('model', 'unknown')
            training_success = row.get('training_success', '') == 'True'

        if not has_energy:
            energy_missing_records.append({
                'experiment_id': row.get('experiment_id', 'N/A'),
                'repo': repo,
                'model': model,
                'mode': mode,
                'training_success': training_success,
                'timestamp': row.get('timestamp', 'N/A')
            })

    print(f"\nèƒ½è€—æ•°æ®ç¼ºå¤±çš„è®°å½•æ•°: {len(energy_missing_records)} ({len(energy_missing_records)*100/total_rows:.1f}%)")

    # æŒ‰æ¨¡å‹ç»Ÿè®¡
    energy_missing_by_model = defaultdict(lambda: {'count': 0, 'training_success': 0, 'training_failed': 0})

    for record in energy_missing_records:
        model_key = f"{record['repo']}/{record['model']}"
        energy_missing_by_model[model_key]['count'] += 1

        if record['training_success']:
            energy_missing_by_model[model_key]['training_success'] += 1
        else:
            energy_missing_by_model[model_key]['training_failed'] += 1

    print(f"\n{'æ¨¡å‹':<50} {'æ€»ç¼ºå¤±':<10} {'è®­ç»ƒæˆåŠŸ':<12} {'è®­ç»ƒå¤±è´¥':<12}")
    print("-" * 90)

    for model_key in sorted(energy_missing_by_model.keys(), key=lambda x: energy_missing_by_model[x]['count'], reverse=True):
        stats = energy_missing_by_model[model_key]
        print(f"{model_key:<50} {stats['count']:<10} {stats['training_success']:<12} {stats['training_failed']:<12}")

    # ===== 4. VulBERTa ç‰¹åˆ«åˆ†æ =====
    print("\n" + "=" * 100)
    print("ğŸ”¬ VulBERTa æ¨¡å‹ç‰¹åˆ«åˆ†æ")
    print("=" * 100)

    vulberta_records = [row for row in rows
                       if row.get('repository') == 'VulBERTa'
                       or row.get('fg_repository') == 'VulBERTa']

    print(f"\nVulBERTa æ€»è®°å½•æ•°: {len(vulberta_records)}")

    # æ£€æŸ¥VulBERTaçš„æ€§èƒ½å­—æ®µ
    if len(vulberta_records) > 0:
        sample_row = vulberta_records[0]
        mode = get_mode(sample_row)

        print(f"\nç¤ºä¾‹è®°å½•çš„æ‰€æœ‰æ€§èƒ½å­—æ®µå€¼:")
        print(f"æ¨¡å¼: {mode}")

        if mode == 'parallel':
            perf_fields = ['fg_perf_accuracy', 'fg_perf_test_accuracy', 'fg_perf_map',
                          'fg_perf_precision', 'fg_perf_recall', 'fg_perf_best_val_accuracy',
                          'fg_perf_test_loss']
        else:
            perf_fields = ['perf_accuracy', 'perf_test_accuracy', 'perf_map',
                          'perf_precision', 'perf_recall', 'perf_best_val_accuracy',
                          'perf_test_loss', 'perf_eval_loss', 'perf_final_training_loss']

        for field in perf_fields:
            val = sample_row.get(field, '')
            print(f"  {field}: {val if val else '(ç©º)'}")

    # ===== 5. æ€»ç»“ =====
    print("\n" + "=" * 100)
    print("ğŸ“Š ä¸å¯ç”¨æ•°æ®åŸå› æ€»ç»“")
    print("=" * 100)

    print(f"\n1. æ€§èƒ½æŒ‡æ ‡ç¼ºå¤± ({len(perf_missing_records)} æ¡, {len(perf_missing_records)*100/total_rows:.1f}%):")
    print(f"   ä¸»è¦å½±å“æ¨¡å‹:")
    for model_key in sorted(perf_missing_by_model.keys(), key=lambda x: perf_missing_by_model[x]['count'], reverse=True)[:3]:
        stats = perf_missing_by_model[model_key]
        print(f"   - {model_key}: {stats['count']} æ¡")
        print(f"     * è®­ç»ƒæˆåŠŸä½†æ— æ€§èƒ½æŒ‡æ ‡: {stats['training_success']} æ¡")
        print(f"     * è®­ç»ƒå¤±è´¥: {stats['training_failed']} æ¡")

    print(f"\n2. è®­ç»ƒå¤±è´¥ ({len(training_failed_records)} æ¡, {len(training_failed_records)*100/total_rows:.1f}%):")
    print(f"   ä¸»è¦å½±å“æ¨¡å‹:")
    for model_key in sorted(failed_by_model.keys(), key=lambda x: failed_by_model[x], reverse=True)[:3]:
        count = failed_by_model[model_key]
        print(f"   - {model_key}: {count} æ¡")

    print(f"\n3. èƒ½è€—æ•°æ®ç¼ºå¤± ({len(energy_missing_records)} æ¡, {len(energy_missing_records)*100/total_rows:.1f}%):")
    print(f"   ä¸»è¦å½±å“æ¨¡å‹:")
    for model_key in sorted(energy_missing_by_model.keys(), key=lambda x: energy_missing_by_model[x]['count'], reverse=True)[:3]:
        stats = energy_missing_by_model[model_key]
        print(f"   - {model_key}: {stats['count']} æ¡")
        print(f"     * è®­ç»ƒæˆåŠŸä½†æ— èƒ½è€—: {stats['training_success']} æ¡")
        print(f"     * è®­ç»ƒå¤±è´¥: {stats['training_failed']} æ¡")

    print("\nâœ… åˆ†æå®Œæˆ!")

if __name__ == "__main__":
    main()

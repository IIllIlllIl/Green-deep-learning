#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å®‰å…¨ä¿®å¤ç¼ºå¤±çš„èƒ½è€—æ•°æ®

åŠŸèƒ½:
- ä» recoverable_energy_data.json è¯»å–å¯æ¢å¤çš„æ•°æ®
- éªŒè¯æ¯ä¸ªæ•°æ®çš„æ¥æºæ–‡ä»¶
- å®‰å…¨åœ°æ›´æ–° raw_data.csv
- åˆ›å»ºå¤‡ä»½å¹¶è®°å½•æ‰€æœ‰ä¿®æ”¹

å®‰å…¨æªæ–½:
- è‡ªåŠ¨åˆ›å»ºå¤‡ä»½
- éªŒè¯æ•°æ®æ¥æº
- è®°å½•æ‰€æœ‰ä¿®æ”¹çš„è¯¦ç»†æ—¥å¿—
- Dry-run æ¨¡å¼ä¾›é¢„è§ˆ
"""

import csv
import json
import shutil
from pathlib import Path
from datetime import datetime

def create_backup(file_path):
    """åˆ›å»ºæ–‡ä»¶å¤‡ä»½"""
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    backup_path = file_path.parent / f"{file_path.name}.backup_{timestamp}"
    shutil.copy2(file_path, backup_path)
    return backup_path

def main():
    base_dir = Path(__file__).parent.parent
    raw_data_csv = base_dir / "results" / "raw_data.csv"
    recoverable_data_json = base_dir / "results" / "recoverable_energy_data.json"
    log_file = base_dir / "results" / f"data_repair_log_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"

    print("=" * 80)
    print("ğŸ”§ å®‰å…¨ä¿®å¤ç¼ºå¤±çš„èƒ½è€—æ•°æ®")
    print("=" * 80)

    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    if not recoverable_data_json.exists():
        print(f"\nâŒ é”™è¯¯: æœªæ‰¾åˆ° {recoverable_data_json}")
        print("   è¯·å…ˆè¿è¡Œ verify_recoverable_data.py ç”Ÿæˆå¯æ¢å¤æ•°æ®åˆ—è¡¨")
        return

    if not raw_data_csv.exists():
        print(f"\nâŒ é”™è¯¯: æœªæ‰¾åˆ° {raw_data_csv}")
        return

    # 1. è¯»å–å¯æ¢å¤çš„æ•°æ®
    print("\n[1/6] è¯»å–å¯æ¢å¤çš„æ•°æ®åˆ—è¡¨...")
    with open(recoverable_data_json, 'r', encoding='utf-8') as f:
        recoverable_data = json.load(f)

    total_recoverable = recoverable_data['summary']['recoverable']
    print(f"   å¯æ¢å¤çš„å®éªŒæ•°: {total_recoverable}")

    # 2. è¯»å– CSV æ•°æ®
    print("\n[2/6] è¯»å– raw_data.csv...")
    with open(raw_data_csv, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        fieldnames = reader.fieldnames
        rows = list(reader)

    print(f"   CSV æ€»è¡Œæ•°: {len(rows)}")
    print(f"   CSV åˆ—æ•°: {len(fieldnames)}")

    # 3. åˆ›å»ºå¤‡ä»½
    print("\n[3/6] åˆ›å»ºå¤‡ä»½...")
    backup_path = create_backup(raw_data_csv)
    print(f"   å¤‡ä»½å·²åˆ›å»º: {backup_path}")

    # 4. æ›´æ–°æ•°æ®
    print("\n[4/6] æ›´æ–°æ•°æ®...")

    log_entries = []
    updated_count = 0
    error_count = 0

    # åˆ›å»ºå®éªŒIDåˆ°è¡Œç´¢å¼•çš„æ˜ å°„
    exp_id_to_index = {}
    for i, row in enumerate(rows):
        exp_id = row.get('experiment_id', '')
        if exp_id:
            exp_id_to_index[exp_id] = i

    # æ›´æ–°æ¯ä¸ªå¯æ¢å¤çš„å®éªŒ
    for i, exp_data in enumerate(recoverable_data['recoverable_experiments'], 1):
        exp_id = exp_data['experiment_id']
        source_file = exp_data['source_file']
        data_to_update = exp_data['data']

        if i <= 5 or i % 50 == 0:
            print(f"   æ›´æ–° {i}/{total_recoverable}: {exp_id}")

        # æŸ¥æ‰¾å¯¹åº”çš„ CSV è¡Œ
        if exp_id not in exp_id_to_index:
            log_entry = f"ERROR: {exp_id} - åœ¨CSVä¸­æœªæ‰¾åˆ°å¯¹åº”è¡Œ"
            log_entries.append(log_entry)
            error_count += 1
            continue

        row_index = exp_id_to_index[exp_id]
        row = rows[row_index]

        # è®°å½•æ›´æ–°å‰çš„å€¼
        old_values = {}
        for field, new_value in data_to_update.items():
            if field in fieldnames:
                old_values[field] = row.get(field, '')

        # æ›´æ–°æ•°æ®
        updated_fields = []
        for field, new_value in data_to_update.items():
            if field in fieldnames:
                row[field] = str(new_value) if new_value is not None else ''
                updated_fields.append(field)
            else:
                # å­—æ®µä¸åœ¨ CSV ä¸­ï¼Œè®°å½•è­¦å‘Š
                log_entry = f"WARNING: {exp_id} - å­—æ®µ {field} ä¸åœ¨CSVä¸­ï¼Œè·³è¿‡"
                log_entries.append(log_entry)

        # è®°å½•æ—¥å¿—
        log_entry = [
            f"UPDATED: {exp_id}",
            f"  Source: {source_file}",
            f"  Fields updated: {len(updated_fields)}",
            f"  Fields: {', '.join(updated_fields)}"
        ]

        # è®°å½•å…³é”®èƒ½è€—å€¼çš„å˜åŒ–
        key_fields = [
            'energy_cpu_total_joules', 'energy_gpu_total_joules',
            'fg_energy_cpu_total_joules', 'fg_energy_gpu_total_joules'
        ]

        for field in key_fields:
            if field in data_to_update:
                old_val = old_values.get(field, '(empty)')
                new_val = data_to_update[field]
                log_entry.append(f"    {field}: {old_val} -> {new_val}")

        log_entries.append('\n'.join(log_entry))
        updated_count += 1

    print(f"\n   æ›´æ–°å®Œæˆ: {updated_count} ä¸ªå®éªŒ")
    if error_count > 0:
        print(f"   é”™è¯¯æ•°: {error_count}")

    # 5. å†™å…¥æ›´æ–°åçš„ CSV
    print("\n[5/6] å†™å…¥æ›´æ–°åçš„æ•°æ®...")

    with open(raw_data_csv, 'w', encoding='utf-8', newline='') as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        writer.writeheader()
        writer.writerows(rows)

    print(f"   å·²å†™å…¥: {raw_data_csv}")

    # 6. ä¿å­˜æ—¥å¿—
    print("\n[6/6] ä¿å­˜ä¿®å¤æ—¥å¿—...")

    log_content = [
        "=" * 80,
        "æ•°æ®ä¿®å¤æ—¥å¿—",
        "=" * 80,
        f"æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
        f"åŸå§‹æ–‡ä»¶: {raw_data_csv}",
        f"å¤‡ä»½æ–‡ä»¶: {backup_path}",
        f"æ•°æ®æ¥æº: {recoverable_data_json}",
        "",
        f"æ€»è®¡å¯æ¢å¤: {total_recoverable}",
        f"æˆåŠŸæ›´æ–°: {updated_count}",
        f"é”™è¯¯æ•°: {error_count}",
        "",
        "=" * 80,
        "è¯¦ç»†æ›´æ–°è®°å½•",
        "=" * 80,
        "",
    ]

    log_content.extend(log_entries)

    with open(log_file, 'w', encoding='utf-8') as f:
        f.write('\n'.join(log_content))

    print(f"   æ—¥å¿—å·²ä¿å­˜: {log_file}")

    # 7. éªŒè¯ç»“æœ
    print("\n" + "=" * 80)
    print("ğŸ“Š ä¿®å¤ç»“æœéªŒè¯")
    print("=" * 80)

    # é‡æ–°ç»Ÿè®¡æ•°æ®å®Œæ•´æ€§
    with open(raw_data_csv, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        updated_rows = list(reader)

    non_parallel_with_energy = 0
    parallel_with_energy = 0
    non_parallel_total = 0
    parallel_total = 0

    for row in updated_rows:
        mode = row.get('mode', '')

        if mode == 'parallel':
            parallel_total += 1
            if row.get('fg_energy_cpu_total_joules', '').strip():
                parallel_with_energy += 1
        else:
            non_parallel_total += 1
            if row.get('energy_cpu_total_joules', '').strip():
                non_parallel_with_energy += 1

    total_with_energy = non_parallel_with_energy + parallel_with_energy
    total_experiments = len(updated_rows)

    print(f"\nä¿®å¤å‰æ•°æ®å®Œæ•´æ€§: 583/836 (69.7%)")
    print(f"ä¿®å¤åæ•°æ®å®Œæ•´æ€§: {total_with_energy}/{total_experiments} ({total_with_energy*100/total_experiments:.1f}%)")
    print(f"\næŒ‰æ¨¡å¼åˆ†ç±»:")
    print(f"  éå¹¶è¡Œ: {non_parallel_with_energy}/{non_parallel_total} ({non_parallel_with_energy*100/non_parallel_total:.1f}%)")
    print(f"  å¹¶è¡Œ: {parallel_with_energy}/{parallel_total} ({parallel_with_energy*100/parallel_total:.1f}%)")

    # 8. æ€»ç»“
    print("\n" + "=" * 80)
    print("ğŸ“ˆ æ€»ç»“")
    print("=" * 80)

    print(f"\nâœ… æ•°æ®ä¿®å¤å®Œæˆ!")
    print(f"\nä¿®å¤ç»Ÿè®¡:")
    print(f"  - æ›´æ–°å®éªŒæ•°: {updated_count}")
    print(f"  - æ•°æ®å®Œæ•´æ€§æå‡: {total_with_energy - 583} ä¸ªå®éªŒ")
    print(f"  - å®Œæ•´æ€§æ¯”ä¾‹: {69.7:.1f}% -> {total_with_energy*100/total_experiments:.1f}%")

    print(f"\næ–‡ä»¶ä½ç½®:")
    print(f"  - åŸå§‹æ–‡ä»¶: {raw_data_csv}")
    print(f"  - å¤‡ä»½æ–‡ä»¶: {backup_path}")
    print(f"  - ä¿®å¤æ—¥å¿—: {log_file}")

    print(f"\næ•°æ®æ¥æº:")
    print(f"  - æ‰€æœ‰ä¿®å¤çš„æ•°æ®éƒ½æ¥è‡ªåŸå§‹ experiment.json æ–‡ä»¶")
    print(f"  - æ¯ä¸ªä¿®å¤éƒ½æœ‰æ˜ç¡®çš„æ–‡ä»¶æ¥æºè®°å½•")
    print(f"  - è¯¦ç»†æ¥æºä¿¡æ¯è¯·æŸ¥çœ‹: {recoverable_data_json}")

    print(f"\nå®‰å…¨æªæ–½:")
    print(f"  âœ… å·²åˆ›å»ºåŸå§‹æ–‡ä»¶å¤‡ä»½")
    print(f"  âœ… æ‰€æœ‰ä¿®æ”¹éƒ½æœ‰è¯¦ç»†æ—¥å¿—")
    print(f"  âœ… æ‰€æœ‰æ•°æ®éƒ½æœ‰æ˜ç¡®çš„æ–‡ä»¶æ¥æº")
    print(f"  âœ… å¦‚éœ€å›æ»šï¼Œå¯ä½¿ç”¨å¤‡ä»½æ–‡ä»¶æ¢å¤")

    print("\nâœ… ä¿®å¤å®Œæˆ!")

if __name__ == "__main__":
    main()

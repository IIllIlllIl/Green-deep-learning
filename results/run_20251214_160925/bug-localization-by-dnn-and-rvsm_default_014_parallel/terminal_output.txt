================================================================================
STDOUT:
================================================================================
[Train Wrapper] Repository: repos/bug-localization-by-dnn-and-rvsm
[Train Wrapper] Training script: ./train.sh
[Train Wrapper] Log file: results/run_20251214_160925/bug-localization-by-dnn-and-rvsm_default_014_parallel/training.log
[Train Wrapper] Energy directory: results/run_20251214_160925/bug-localization-by-dnn-and-rvsm_default_014_parallel/energy
[Train Wrapper] Arguments: --max_iter 2553
[Train Wrapper] Changed to directory: /home/green/energy_dl/nightly/repos/bug-localization-by-dnn-and-rvsm
[Train Wrapper] Starting GPU monitoring...
[Train Wrapper] GPU monitoring PID: 3075766
[Train Wrapper] Starting training with integrated energy monitoring...
[Train Wrapper] Command: ./train.sh --max_iter 2553
========================================
========================================
Bug Localization Training Configuration
========================================
Model: dnn
Python: /home/green/miniconda3/envs/dnn_rvsm/bin/python
Working directory: /home/green/energy_dl/nightly/repos/bug-localization-by-dnn-and-rvsm
K-fold: 10
Hidden sizes: 300
Alpha: 1e-5
Max iterations: 2553
Early stopping: 30
Solver: sgd
Parallel jobs: -2
Random seed: Not set (original non-deterministic behavior)
========================================

================================================================================
Bug Localization Model Training - DNN
================================================================================
Start time: 2025-12-15 07:04:01

DNN Hyperparameters:
  - K-fold: 10
  - Hidden layer sizes: (300,)
  - Alpha (L2 penalty): 1e-05
  - Max iterations: 2553
  - Early stopping patience: 30
  - Solver: sgd
  - Parallel jobs: -2
  - Random seed: Not set (original non-deterministic behavior)

Training DNN model with k-fold cross-validation...
--------------------------------------------------------------------------------
/home/green/miniconda3/envs/dnn_rvsm/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  "timeout or by a memory leak.", UserWarning
Fold: 1 / 10
Fold: 5 / 10
Training completed successfully!

================================================================================
TRAINING REPORT
================================================================================
Model: DNN
Start time: 2025-12-15 07:04:01
End time: 2025-12-15 07:20:21
Total duration: 979.85 seconds (16.33 minutes)

MODEL PERFORMANCE (Top-k Accuracy):
--------------------------------------------------------------------------------
  Top- 1 Accuracy: 0.378 (37.8%)
  Top- 5 Accuracy: 0.626 (62.6%)
  Top-10 Accuracy: 0.738 (73.8%)
  Top-20 Accuracy: 0.826 (82.6%)

Detailed Results (All k values):
  Top- 1: 0.378
  Top- 2: 0.477
  Top- 3: 0.547
  Top- 4: 0.592
  Top- 5: 0.626
  Top- 6: 0.653
  Top- 7: 0.680
  Top- 8: 0.700
  Top- 9: 0.723
  Top-10: 0.738
  Top-11: 0.750
  Top-12: 0.762
  Top-13: 0.774
  Top-14: 0.785
  Top-15: 0.793
  Top-16: 0.802
  Top-17: 0.809
  Top-18: 0.815
  Top-19: 0.820
  Top-20: 0.826
================================================================================
Fold: 6 / 10
Fold: 7 / 10
Fold: 2 / 10
Fold: 8 / 10
Fold: 3 / 10
Fold: 9 / 10
Fold: 4 / 10
Fold: 10 / 10
Training completed successfully!
========================================
[Train Wrapper] Training finished with exit code: 0
[Train Wrapper] Stopping GPU monitoring...
[Train Wrapper] Processing CPU energy data...
[Train Wrapper] CPU energy saved to: /home/green/energy_dl/nightly/results/run_20251214_160925/bug-localization-by-dnn-and-rvsm_default_014_parallel/energy/cpu_energy.txt
[Train Wrapper] GPU monitoring data saved to: /home/green/energy_dl/nightly/results/run_20251214_160925/bug-localization-by-dnn-and-rvsm_default_014_parallel/energy
[Train Wrapper] Energy monitoring completed

================================================================================
STDERR:
================================================================================
(empty)

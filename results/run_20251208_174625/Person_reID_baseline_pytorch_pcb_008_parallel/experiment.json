{
  "experiment_id": "Person_reID_baseline_pytorch_pcb_008_parallel",
  "timestamp": "2025-12-09T11:33:54.189417",
  "mode": "parallel",
  "foreground": {
    "repository": "Person_reID_baseline_pytorch",
    "model": "pcb",
    "hyperparameters": {
      "seed": 7980
    },
    "duration_seconds": 8616.426119089127,
    "energy_metrics": {
      "cpu_energy_pkg_joules": 327556.66,
      "cpu_energy_ram_joules": 23075.76,
      "cpu_energy_total_joules": 350632.42,
      "gpu_power_avg_watts": 221.18518942101483,
      "gpu_power_max_watts": 315.31,
      "gpu_power_min_watts": 149.88,
      "gpu_energy_total_joules": 1856628.4799999984,
      "gpu_temp_avg_celsius": 78.74005241839409,
      "gpu_temp_max_celsius": 85.0,
      "gpu_util_avg_percent": 99.67357636406958,
      "gpu_util_max_percent": 100.0
    },
    "performance_metrics": {
      "rank1": 0.929929,
      "rank5": 0.976247,
      "map": 0.777297
    },
    "training_success": true,
    "retries": 0,
    "error_message": "Training completed successfully"
  },
  "background": {
    "repository": "Person_reID_baseline_pytorch",
    "model": "densenet121",
    "hyperparameters": {},
    "log_directory": "/home/green/energy_dl/nightly/results/run_20251208_174625/Person_reID_baseline_pytorch_pcb_008_parallel/background_logs",
    "note": "Background training served as GPU load only (not monitored)"
  }
}
{
  "experiment_id": "examples_siamese_045_parallel",
  "timestamp": "2025-11-23T02:20:33.021874",
  "mode": "parallel",
  "foreground": {
    "repository": "examples",
    "model": "siamese",
    "hyperparameters": {
      "learning_rate": 0.017659375308617237
    },
    "duration_seconds": 968.7151687145233,
    "energy_metrics": {
      "cpu_energy_pkg_joules": 64791.58,
      "cpu_energy_ram_joules": 4738.59,
      "cpu_energy_total_joules": 69530.17,
      "gpu_power_avg_watts": 190.72289389067535,
      "gpu_power_max_watts": 318.62,
      "gpu_power_min_watts": 120.1,
      "gpu_energy_total_joules": 177944.4600000001,
      "gpu_temp_avg_celsius": 69.30975348338693,
      "gpu_temp_max_celsius": 76.0,
      "gpu_util_avg_percent": 99.73633440514469,
      "gpu_util_max_percent": 100.0
    },
    "performance_metrics": {
      "test_accuracy": 99.0,
      "test_loss": 0.0
    },
    "training_success": true,
    "retries": 0,
    "error_message": "Training completed successfully"
  },
  "background": {
    "repository": "Person_reID_baseline_pytorch",
    "model": "pcb",
    "hyperparameters": {
      "epochs": 60,
      "learning_rate": 0.05,
      "dropout": 0.5,
      "seed": 1334
    },
    "log_directory": "/home/green/energy_dl/nightly/results/run_20251122_175401/examples_siamese_045_parallel/background_logs",
    "note": "Background training served as GPU load only (not monitored)"
  }
}
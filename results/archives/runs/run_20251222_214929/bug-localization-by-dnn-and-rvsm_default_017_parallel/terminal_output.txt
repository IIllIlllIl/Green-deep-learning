================================================================================
STDOUT:
================================================================================
[Train Wrapper] Repository: repos/bug-localization-by-dnn-and-rvsm
[Train Wrapper] Training script: ./train.sh
[Train Wrapper] Log file: results/run_20251222_214929/bug-localization-by-dnn-and-rvsm_default_017_parallel/training.log
[Train Wrapper] Energy directory: results/run_20251222_214929/bug-localization-by-dnn-and-rvsm_default_017_parallel/energy
[Train Wrapper] Arguments: --kfold 7
[Train Wrapper] Changed to directory: /home/green/energy_dl/nightly/repos/bug-localization-by-dnn-and-rvsm
[Train Wrapper] Starting GPU monitoring...
[Train Wrapper] GPU monitoring PID: 1637636
[Train Wrapper] Starting training with integrated energy monitoring...
[Train Wrapper] Command: ./train.sh --kfold 7
========================================
========================================
Bug Localization Training Configuration
========================================
Model: dnn
Python: /home/green/miniconda3/envs/dnn_rvsm/bin/python
Working directory: /home/green/energy_dl/nightly/repos/bug-localization-by-dnn-and-rvsm
K-fold: 7
Hidden sizes: 300
Alpha: 1e-5
Max iterations: 10000
Early stopping: 30
Solver: sgd
Parallel jobs: -2
Random seed: Not set (original non-deterministic behavior)
========================================

================================================================================
Bug Localization Model Training - DNN
================================================================================
Start time: 2025-12-23 01:39:37

DNN Hyperparameters:
  - K-fold: 7
  - Hidden layer sizes: (300,)
  - Alpha (L2 penalty): 1e-05
  - Max iterations: 10000
  - Early stopping patience: 30
  - Solver: sgd
  - Parallel jobs: -2
  - Random seed: Not set (original non-deterministic behavior)

Training DNN model with k-fold cross-validation...
--------------------------------------------------------------------------------
/home/green/miniconda3/envs/dnn_rvsm/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  "timeout or by a memory leak.", UserWarning

Training completed successfully!

================================================================================
TRAINING REPORT
================================================================================
Model: DNN
Start time: 2025-12-23 01:39:37
End time: 2025-12-23 01:50:36
Total duration: 659.69 seconds (10.99 minutes)

MODEL PERFORMANCE (Top-k Accuracy):
--------------------------------------------------------------------------------
  Top- 1 Accuracy: 0.377 (37.7%)
  Top- 5 Accuracy: 0.624 (62.4%)
  Top-10 Accuracy: 0.734 (73.4%)
  Top-20 Accuracy: 0.823 (82.3%)

Detailed Results (All k values):
  Top- 1: 0.377
  Top- 2: 0.473
  Top- 3: 0.544
  Top- 4: 0.589
  Top- 5: 0.624
  Top- 6: 0.649
  Top- 7: 0.676
  Top- 8: 0.696
  Top- 9: 0.720
  Top-10: 0.734
  Top-11: 0.745
  Top-12: 0.758
  Top-13: 0.770
  Top-14: 0.781
  Top-15: 0.789
  Top-16: 0.798
  Top-17: 0.805
  Top-18: 0.812
  Top-19: 0.817
  Top-20: 0.823
================================================================================
Fold: 3 / 7
Fold: 4 / 7
Fold: 1 / 7
Fold: 5 / 7
Fold: 2 / 7
Fold: 6 / 7
Fold: 7 / 7
Training completed successfully!
========================================
[Train Wrapper] Training finished with exit code: 0
[Train Wrapper] Stopping GPU monitoring...
[Train Wrapper] Processing CPU energy data...
[Train Wrapper] CPU energy saved to: /home/green/energy_dl/nightly/results/run_20251222_214929/bug-localization-by-dnn-and-rvsm_default_017_parallel/energy/cpu_energy.txt
[Train Wrapper] GPU monitoring data saved to: /home/green/energy_dl/nightly/results/run_20251222_214929/bug-localization-by-dnn-and-rvsm_default_017_parallel/energy
[Train Wrapper] Energy monitoring completed

================================================================================
STDERR:
================================================================================
(empty)

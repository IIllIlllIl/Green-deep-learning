================================================================================
STDOUT:
================================================================================
[Train Wrapper] Repository: repos/bug-localization-by-dnn-and-rvsm
[Train Wrapper] Training script: ./train.sh
[Train Wrapper] Log file: results/run_20251217_211341/bug-localization-by-dnn-and-rvsm_default_046_parallel/training.log
[Train Wrapper] Energy directory: results/run_20251217_211341/bug-localization-by-dnn-and-rvsm_default_046_parallel/energy
[Train Wrapper] Arguments: --kfold 5
[Train Wrapper] Changed to directory: /home/green/energy_dl/nightly/repos/bug-localization-by-dnn-and-rvsm
[Train Wrapper] Starting GPU monitoring...
[Train Wrapper] GPU monitoring PID: 1186507
[Train Wrapper] Starting training with integrated energy monitoring...
[Train Wrapper] Command: ./train.sh --kfold 5
========================================
========================================
Bug Localization Training Configuration
========================================
Model: dnn
Python: /home/green/miniconda3/envs/dnn_rvsm/bin/python
Working directory: /home/green/energy_dl/nightly/repos/bug-localization-by-dnn-and-rvsm
K-fold: 5
Hidden sizes: 300
Alpha: 1e-5
Max iterations: 10000
Early stopping: 30
Solver: sgd
Parallel jobs: -2
Random seed: Not set (original non-deterministic behavior)
========================================

================================================================================
Bug Localization Model Training - DNN
================================================================================
Start time: 2025-12-18 23:21:23

DNN Hyperparameters:
  - K-fold: 5
  - Hidden layer sizes: (300,)
  - Alpha (L2 penalty): 1e-05
  - Max iterations: 10000
  - Early stopping patience: 30
  - Solver: sgd
  - Parallel jobs: -2
  - Random seed: Not set (original non-deterministic behavior)

Training DNN model with k-fold cross-validation...
--------------------------------------------------------------------------------
/home/green/miniconda3/envs/dnn_rvsm/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  "timeout or by a memory leak.", UserWarning

Training completed successfully!

================================================================================
TRAINING REPORT
================================================================================
Model: DNN
Start time: 2025-12-18 23:21:23
End time: 2025-12-18 23:31:34
Total duration: 611.09 seconds (10.18 minutes)

MODEL PERFORMANCE (Top-k Accuracy):
--------------------------------------------------------------------------------
  Top- 1 Accuracy: 0.380 (38.0%)
  Top- 5 Accuracy: 0.625 (62.5%)
  Top-10 Accuracy: 0.739 (73.9%)
  Top-20 Accuracy: 0.825 (82.5%)

Detailed Results (All k values):
  Top- 1: 0.380
  Top- 2: 0.478
  Top- 3: 0.548
  Top- 4: 0.591
  Top- 5: 0.625
  Top- 6: 0.651
  Top- 7: 0.677
  Top- 8: 0.699
  Top- 9: 0.723
  Top-10: 0.739
  Top-11: 0.749
  Top-12: 0.761
  Top-13: 0.774
  Top-14: 0.784
  Top-15: 0.791
  Top-16: 0.801
  Top-17: 0.808
  Top-18: 0.814
  Top-19: 0.819
  Top-20: 0.825
================================================================================
Fold: 1 / 5
Fold: 2 / 5
Fold: 3 / 5
Fold: 4 / 5
Fold: 5 / 5
Training completed successfully!
========================================
[Train Wrapper] Training finished with exit code: 0
[Train Wrapper] Stopping GPU monitoring...
[Train Wrapper] Processing CPU energy data...
[Train Wrapper] CPU energy saved to: /home/green/energy_dl/nightly/results/run_20251217_211341/bug-localization-by-dnn-and-rvsm_default_046_parallel/energy/cpu_energy.txt
[Train Wrapper] GPU monitoring data saved to: /home/green/energy_dl/nightly/results/run_20251217_211341/bug-localization-by-dnn-and-rvsm_default_046_parallel/energy
[Train Wrapper] Energy monitoring completed

================================================================================
STDERR:
================================================================================
(empty)
